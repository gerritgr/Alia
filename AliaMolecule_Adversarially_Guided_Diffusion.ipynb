{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/Alia/blob/main/AliaMolecule_Adversarially_Guided_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VWSEj4zWH9P"
      },
      "source": [
        "# AliaMolecule - Adversarially Guided Probabilistic Diffusion\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFu0doC8D-UW"
      },
      "source": [
        "## Todo\n",
        "- DEVICE\n",
        "- positional encoding\n",
        "- resnet units\n",
        "- save loss list\n",
        "- cosine schedule\n",
        "- predict endpoint and not noise\n",
        "- why is batch wrong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAao3t3nPHHQ"
      },
      "source": [
        "Molecules:\n",
        "- remove hydrogen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqaO-iDsNHDS"
      },
      "source": [
        "- $t=0$ is original image.  => ($i=999$)\n",
        "- $t=1$ means one noise addition was made.  => ($i=T-t=999-t$)\n",
        "- $t=T=999$ is maximal addition. => ($i=0$)\n",
        "- $T = TIMESTEPS-1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmgsr5qYDymy"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yGSIj3enuyM6"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"AliaMolecule\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qfPpruBP7wod"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  !pip install torch_geometric\n",
        "  # Optional dependencies:\n",
        "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "  !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu102.html --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2nNF8e3Hgiej"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  !pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-leX8Lpch0-s"
      },
      "outputs": [],
      "source": [
        "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu102.html --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E7HLKq3WKG_b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if USE_COLAB and not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM0dnwkxLhm_",
        "outputId": "d0286fe4-fd1a-4cc9-c29a-2357c766a9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/AliaMolecule\n"
          ]
        }
      ],
      "source": [
        "if USE_COLAB:\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCUaC9ZqwH9E"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wtZm7FbVwJGx"
      },
      "outputs": [],
      "source": [
        "#!rm -rf Alia && git clone https://github.com/gerritgr/Alia.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIZNe0X4Z-f7"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xQTCAyyHjLjW"
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
        "from PIL import Image # We use PIL to load images\n",
        "import seaborn as sns\n",
        "import imageio # to generate .gifs\n",
        "import networkx as nx\n",
        "\n",
        "# always good to have\n",
        "import glob, random, os, traceback, time, copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Linear as Lin\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_4brRkfG9Za"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX33f9FYG9gL",
        "outputId": "02e08163-626c-4bf3-d0ae-ba59919d3623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Mol Gen\n",
        "NUM_SAMPLES = 500 # how many samples to generate for the trainings set\n",
        "NUM_GRAPHS_TO_GENERATE = 10 # during inference\n",
        "TRAIN_TEST_SPLIT = 0.8\n",
        "\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5 # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False]*5 + [True] * 5\n",
        "NON_EDGES = [True] + [True]*5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1\n",
        "\n",
        "\n",
        "\n",
        "# General\n",
        "EPOCHS = 100000\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_ROUNDS = 10\n",
        "BASE_MODEL_EPOCHS = 20000\n",
        "EPOCHS_DISC_MODEL = 101\n",
        "EPOCHS_GUIDE_MODEL = 201\n",
        "GUIDE_FRACTION = 20   # only apply guidacne in the last 1/4 of the process\n",
        "\n",
        "\n",
        "# Diffusion\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#DEVICE = torch.device('cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkf85cyRvGiT"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eSYvg6xIw-vV"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, graph_loss_list, loss_list, epoch_i):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"aliamol_model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'graph_loss_list': graph_loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "\n",
        "def load_latest_checkpoint(model, optimizer, graph_loss_list, loss_list, epoch_i):\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(\"aliamolmodel_epoch_*.pth\"))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, graph_loss_list, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    graph_loss_list = checkpoint['graph_loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, graph_loss_list, loss_list, epoch_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZSk-qMNvj6Q"
      },
      "source": [
        "## Build Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d8D6H1LGMp15"
      },
      "outputs": [],
      "source": [
        "# each node represents atom or bond\n",
        "# thus, each row of data.x has the form TAAAAABBBBB\n",
        "# T is 1 (atom) or -1 (bond). AAAAA is one-hot encoding of element (the five in qm9);\n",
        "# BBBBB is one hot encoding of bond type, single, double, triple, ring,\n",
        "# if a node is an atom then BBBBB is all -1, if it is a bond AAAAA is all -1\n",
        "# The diffusion only happens on either AAAAA or BBBBB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PnY-HyQyiYp1"
      },
      "outputs": [],
      "source": [
        "#!cd Alia/smiles_to_pyg/ && mv molecule_load_and_convert2.py  molecule_load_and_convert3.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gq5S0kudvD8T"
      },
      "outputs": [],
      "source": [
        "def build_dataset(seed=1234):\n",
        "  from Alia.smiles_to_pyg.molecule_load_and_convert3 import read_qm9\n",
        "  dataset = read_qm9()\n",
        "  dataset = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset)*TRAIN_TEST_SPLIT + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0,:].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  return dataset_train, dataset_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxwETR7mPq1b"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6K-jxdBPt5Z"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ybvf4HoWPtH2"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "    \"\"\"\n",
        "    Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "    Args:\n",
        "    start (float): The starting value for the beta values. Default is START.\n",
        "    end (float): The ending value for the beta values. Default is END.\n",
        "    timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "    cumulative alpha values (alpha bars).\n",
        "    \"\"\"\n",
        "    betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "    #alphas = 1.0 - betas\n",
        "    #alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "    assert(betas.numel() == TIMESTEPS)\n",
        "    return betas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCrL8EfP2tM"
      },
      "source": [
        "## Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zpJn8TzvD-5",
        "outputId": "3d30d559-a322-47f2-f632-1630e8f78aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([[0.9916],\n",
              "          [1.9964],\n",
              "          [0.1035]], device='cuda:0'),\n",
              "  tensor([[-0.8316],\n",
              "          [-0.3454],\n",
              "          [ 0.0360]], device='cuda:0')),\n",
              " None,\n",
              " (tensor([[ 0.5758],\n",
              "          [-0.6691],\n",
              "          [-2.2151]], device='cuda:0'),\n",
              "  tensor([[ 0.5535],\n",
              "          [-0.7142],\n",
              "          [-2.2832]], device='cuda:0')))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # column-wise multiplication, now matrix\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) #this is a col vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) #this is a matrix\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXDf7AsfW_PE"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QScWK9RzI0c"
      },
      "source": [
        "### Model Spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l1VOml_vvEBQ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM+ TIME_FEATURE_DIM #INDICATOR_FEATURE_DIM entries are noise free\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    t = t.view(-1,TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "\n",
        "    #node_indicator = x_in[:,0] > 0\n",
        "    #node_indicator = x_in[:,0] < 0\n",
        "    #x[node_indicator, NON_NODES] = x_in[node_indicator, NON_NODES]\n",
        "    #x[edge_indicator, NON_EDGES] = x_in[edge_indicator, NON_EDGES]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SKlGT9rzFXU"
      },
      "source": [
        "### Train Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AfRQ1DBvvEIT"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer):\n",
        "  \"\"\"\n",
        "  Trains a denoising model for one epoch using a given data loader and optimization algorithm.\n",
        "\n",
        "  Args:\n",
        "  model: The denoising model.\n",
        "  dataloader: The data loader for the training data.\n",
        "  optimizer: The torch optimizer.\n",
        "\n",
        "  Returns:\n",
        "  float: The average loss for the epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "\n",
        "  for g in tqdm(dataloader): #todo batches deactivated\n",
        "    if g.x.shape[0] < 2:\n",
        "      continue\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    g.to(DEVICE)\n",
        "    num_graphs_in_batch = 1\n",
        "    #num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.tensor([0]*g.x.shape[0], device=DEVICE)# torch.gather(future_t_select, 0, g.batch)\n",
        "    assert(future_t.numel() == g.x.shape[0])\n",
        "\n",
        "    mask = torch.concat((torch.tensor([False]*g.x.shape[0], device=DEVICE).view(-1,1), g.x[:,1:]>-0.5), dim=1) #this only works on original values\n",
        "    x = g.x[mask].view(g.x.shape[0], FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x, future_t)\n",
        "\n",
        "    x_in = g.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    noise_pred = model(x_in, future_t, g.edge_index)\n",
        "\n",
        "    loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return float(np.mean(loss_list)), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_ryCoO5wOoG",
        "outputId": "92e81293-7124-4731-9f6b-b10488e0d1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 61.41it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0211095273494721, 0.3293795585632324)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "def train_epoch_test():\n",
        "  dataset_train, dataset_test = build_dataset()\n",
        "  data = dataset_train[0]\n",
        "  model_base = PNAnet(dataset_train[:20]).to(DEVICE) #20 should be enough to estimate statistics\n",
        "\n",
        "  t = torch.tensor([1.0]).repeat(data.x.shape[0])\n",
        "  t = t.to(DEVICE)\n",
        "  model_base(data.x, t, data.edge_index)\n",
        "  dataloader = DataLoader(dataset_train[:20], batch_size=1, shuffle=True)\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "  return train_epoch(model_base, dataloader, optimizer)\n",
        "\n",
        "train_epoch_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV_QpxiPwpY1"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_list(xy_data, filename, title=\"\", xlabel=\"\", ylabel=\"\"):\n",
        "  plt.clf()\n",
        "  plt.plot([x for x, y in xy_data], [y for x, y in xy_data])\n",
        "  plt.title(title)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.savefig(filename)\n",
        "\n",
        "  with open(filename+\".pickle\", 'wb') as f:\n",
        "    pickle.dump(xy_data, f)"
      ],
      "metadata": {
        "id": "BtCkdi6M77nG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "R6N8YD6rvERr"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=None):\n",
        "  print(\"train base model\")\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "\n",
        "  lr = LEARNING_RATE\n",
        "  if BATCH_SIZE > 1:\n",
        "    lr = lr/100.0\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE)\n",
        "  loss_list = list()\n",
        "  graph_loss_list = list()\n",
        "  model_base, optimizer, graph_loss_list, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, graph_loss_list, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_num = epoch_num if epoch_num is not None else EPOCHS\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    try:\n",
        "      loss, time_elapsed = train_epoch(model_base, train_loader, optimizer)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      if epoch_i % 1 == 0 or epoch_i == epoch_num - 1:\n",
        "        plot_list(loss_list, \"train_base.png\", title=\"train loss base model\", xlabel='epoch', ylabel='loss')\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {np.mean([y for x,y in loss_list] + [loss]):05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "\n",
        "      if (epoch_i % 10 == 0 and epoch_i > 100) or epoch_i == epoch_num - 1:\n",
        "        #graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "        #graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "        #print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "        #plot_base(graph_loss_list, loss_list)\n",
        "        save_model(model_base, optimizer, graph_loss_list, loss_list, epoch_i+1)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dO7VLZT5vEUD",
        "outputId": "a1c84b82-049d-4ecb-dd2e-f689c49d229a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train base model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 63.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000000 is: 1.0306 with mean loss 1.0306 with runtime 0.3208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 62.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000001 is: 0.9780 with mean loss 0.9955 with runtime 0.3265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 64.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000002 is: 1.0340 with mean loss 1.0192 with runtime 0.3154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 64.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000003 is: 0.9960 with mean loss 1.0069 with runtime 0.3163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 61.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000004 is: 1.0057 with mean loss 1.0083 with runtime 0.3324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 64.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000005 is: 0.9770 with mean loss 0.9997 with runtime 0.3150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 62.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000006 is: 0.9757 with mean loss 0.9966 with runtime 0.3241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000007 is: 1.0039 with mean loss 1.0005 with runtime 0.3112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000008 is: 0.9745 with mean loss 0.9950 with runtime 0.3097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 61.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000009 is: 1.0288 with mean loss 1.0030 with runtime 0.3297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 66.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000010 is: 0.9883 with mean loss 0.9984 with runtime 0.3062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000011 is: 0.9742 with mean loss 0.9955 with runtime 0.3076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 66.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000012 is: 1.0016 with mean loss 0.9979 with runtime 0.3071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000013 is: 1.0114 with mean loss 0.9994 with runtime 0.3098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 67.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000014 is: 0.9584 with mean loss 0.9935 with runtime 0.3034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 58.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000015 is: 0.9804 with mean loss 0.9941 with runtime 0.3468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 62.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000016 is: 1.0179 with mean loss 0.9975 with runtime 0.3292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 52.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000017 is: 0.9904 with mean loss 0.9956 with runtime 0.3840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 62.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000018 is: 1.0351 with mean loss 0.9999 with runtime 0.3244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 59.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000019 is: 1.0157 with mean loss 0.9997 with runtime 0.3426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 61.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000020 is: 1.0389 with mean loss 1.0025 with runtime 0.3278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000021 is: 0.9710 with mean loss 0.9982 with runtime 0.3115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 68.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000022 is: 1.0059 with mean loss 1.0000 with runtime 0.3003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 66.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000023 is: 0.9883 with mean loss 0.9988 with runtime 0.3057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000024 is: 0.9655 with mean loss 0.9966 with runtime 0.3073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 67.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000025 is: 1.0370 with mean loss 1.0008 with runtime 0.3021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000026 is: 0.9663 with mean loss 0.9970 with runtime 0.3093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 66.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000027 is: 1.0039 with mean loss 0.9986 with runtime 0.3040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 65.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000028 is: 0.9602 with mean loss 0.9958 with runtime 0.3088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 58.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000029 is: 0.9873 with mean loss 0.9964 with runtime 0.3452\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def train_base_model_test():\n",
        "  dataset_train, dataset_test = build_dataset()\n",
        "  dataloader = DataLoader(dataset_train[:20], batch_size=1, shuffle=True)\n",
        "\n",
        "  train_base_model(dataloader, epoch_num=30)\n",
        "#train_base_model_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AZEeax7AvEWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2a082c-f544-45e4-a118-be328ce2eb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alia  train_base.png  train_base.png.pickle\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting Everything Together"
      ],
      "metadata": {
        "id": "FlxLHZN16p_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_base, dataset_base_test = build_dataset()\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "model_cassandra = None\n",
        "# TODO test set train\n",
        "\n",
        "for round_i in range(NUM_ROUNDS):\n",
        "  model_base = train_base_model(dataloader_base)\n",
        "\n",
        "  #samples = sample_base_model(model_base, round_i, model_guide=model_cassandra, num=NUM_SAMPLES)  #TODO\n",
        "  #plot_samples(samples, model_disc=None, round_i=round_i)\n",
        "  #dataloader_disc = get_merged_dataloader(samples[:num_samples_train], dataset_base)\n",
        "  #dataloader_disc_test = get_merged_dataloader(samples[num_samples_train:], dataset_base_test)\n",
        "  #model_cassandra = train_cassandra_model(dataloader_disc, dataloader_disc_test, round_i)\n",
        "  #new_epoch_num = BASE_MODEL_EPOCHS + (round_i+1)*int(BASE_MODEL_EPOCHS*0.2)\n",
        "  #model_base = train_base_model(dataloader_base, epoch_num = new_epoch_num)\n",
        "\n",
        "#samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_cassandra, num=NUM_SAMPLES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVvB3KCd6f7f",
        "outputId": "fdbc3d11-c0c7-429e-c84c-6970c0664e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train base model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 76078/107105 [25:51<10:43, 48.23it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = z/0"
      ],
      "metadata": {
        "id": "XLUFMZn2Juma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkiNNy7W6f-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cC16z0va6gAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PJNvLD86gC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iXbodabU6gFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQVPgLM5vEYb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nSj0xibvEh1"
      },
      "source": [
        "# Old"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxPXpSLLaAdP"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BouSF2CGWIFI"
      },
      "outputs": [],
      "source": [
        "G = nx.star_graph(10)\n",
        "\n",
        "nx.draw(G, with_labels=True, node_color='lightblue', node_size=800, font_weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8mltcfQ1oyq"
      },
      "outputs": [],
      "source": [
        "def get_weights(g):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1]\n",
        "  return edge_weights[edge_indices]\n",
        "\n",
        "def set_weights(g, w):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  g.x[edge_indices,1] = w\n",
        "  return g\n",
        "\n",
        "def get_edge_index(g):\n",
        "  return g.x[:,0] < 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYttUAarWIbf"
      },
      "outputs": [],
      "source": [
        "def transform_graph(graph, make_complete=False):\n",
        "  # create graph where each edge becomes a node with weight 1\n",
        "  # if make_complete, each non-egde becomes node with weight -1\n",
        "\n",
        "  graph = nx.convert_node_labels_to_integers(graph, ordering=\"sorted\")\n",
        "\n",
        "  transformed_graph = nx.Graph()\n",
        "\n",
        "  for u, v in graph.edges():\n",
        "    new_node = (u+v)*1000000+100*(min(u,v)+1)+10000000000*max(u,v)\n",
        "    transformed_graph.add_edge(u, new_node)\n",
        "    transformed_graph.add_edge(new_node, v)\n",
        "    transformed_graph.nodes[u]['is_real'] = 1\n",
        "    transformed_graph.nodes[v]['is_real'] = 1\n",
        "    transformed_graph.nodes[new_node]['is_real'] = 0\n",
        "    transformed_graph.nodes[u]['weight'] = 0.0\n",
        "    transformed_graph.nodes[v]['weight'] = 0.0\n",
        "    transformed_graph.nodes[new_node]['weight'] = EDGE_INDICATOR\n",
        "\n",
        "\n",
        "  if make_complete:\n",
        "    for u in graph.nodes():\n",
        "      for v in graph.nodes():\n",
        "        if u > v and not graph.has_edge(u, v) and not graph.has_edge(v, u):\n",
        "          new_node = (u+v)*1000000+100*(min(u,v)+1)+10000000000*max(u,v)+10\n",
        "          transformed_graph.add_edge(u, new_node)\n",
        "          transformed_graph.add_edge(new_node, v)\n",
        "          transformed_graph.nodes[u]['is_real'] = 1\n",
        "          transformed_graph.nodes[v]['is_real'] = 1\n",
        "          transformed_graph.nodes[new_node]['is_real'] = 0\n",
        "          transformed_graph.nodes[new_node]['weight'] = NO_EDGE_INDICATOR\n",
        "\n",
        "  transformed_graph = nx.convert_node_labels_to_integers(transformed_graph, ordering=\"sorted\")\n",
        "  return transformed_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdUpdWYpM99N"
      },
      "outputs": [],
      "source": [
        "def transform_to_complete_graph(graph):\n",
        "  global EDGE_INDEX_STORAGE\n",
        "  # create graph where each edge becomes a node with weight 1\n",
        "  # if make_complete, each non-egde becomes node with weight -1\n",
        "\n",
        "  graph_node_num = graph.number_of_nodes()\n",
        "  number_nodes_in_transformed_graph = graph_node_num*(graph_node_num+1)/2 #+ graph_node_num\n",
        "  graph = nx.convert_node_labels_to_integers(graph, ordering=\"sorted\")\n",
        "\n",
        "  transformed_graph = nx.Graph()\n",
        "  nodes = range(graph_node_num)\n",
        "\n",
        "  for u in nodes:\n",
        "    for v in nodes:\n",
        "      if u>=v:\n",
        "        continue\n",
        "      new_node = (u+v+1)*1000000+100*(min(u,v)+1)+10000000000*max(u,v)+10+u+20*(v+1)\n",
        "      transformed_graph.add_edge(u, new_node)\n",
        "      transformed_graph.add_edge(new_node, v)\n",
        "      transformed_graph.nodes[u]['is_real'] = 1\n",
        "      transformed_graph.nodes[v]['is_real'] = 1\n",
        "      transformed_graph.nodes[new_node]['is_real'] = 0\n",
        "\n",
        "      transformed_graph.nodes[u]['weight'] = 0.0\n",
        "      transformed_graph.nodes[v]['weight'] = 0.0\n",
        "      if graph.has_edge(u, v) or graph.has_edge(v, u):\n",
        "        transformed_graph.nodes[new_node]['weight'] = EDGE_INDICATOR\n",
        "      else:\n",
        "        transformed_graph.nodes[new_node]['weight'] = NO_EDGE_INDICATOR\n",
        "\n",
        "  transformed_graph = nx.convert_node_labels_to_integers(transformed_graph, ordering=\"sorted\")\n",
        "  assert(number_nodes_in_transformed_graph == transformed_graph.number_of_nodes())\n",
        "  return transformed_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAoIITTOWhCp"
      },
      "outputs": [],
      "source": [
        "# Transform the graph\n",
        "transformed_G = transform_graph(G)\n",
        "\n",
        "# Visualize the transformed graph\n",
        "node_color = ['lightblue' if transformed_G.nodes[node]['is_real'] == 1 else 'gray' for node in transformed_G.nodes()]\n",
        "\n",
        "nx.draw(transformed_G, with_labels=True, node_size=800, font_weight='bold', node_color=node_color)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10mP4uXrWkU3"
      },
      "outputs": [],
      "source": [
        "G = nx.star_graph(3)\n",
        "\n",
        "\n",
        "# Transform the graph\n",
        "transformed_G  = transform_graph(G, make_complete=True)\n",
        "#transformed_G  = transform_to_complete_graph(G)\n",
        "\n",
        "# Visualize the transformed graph\n",
        "def get_node_color(g, v):\n",
        "  if g.nodes[v]['is_real'] == 1:\n",
        "    return \"lightblue\"\n",
        "  if g.nodes[v]['weight'] > 0.5:\n",
        "    return \"gray\"\n",
        "  return \"lightgray\"\n",
        "\n",
        "node_color = [get_node_color(transformed_G, node) for node in transformed_G.nodes()]\n",
        "\n",
        "nx.draw(transformed_G, with_labels=True, node_size=800, font_weight='bold', node_color=node_color)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uoDR578Yg4N"
      },
      "outputs": [],
      "source": [
        "G = nx.star_graph(3)\n",
        "transformed_G  = transform_graph(G, make_complete=True)\n",
        "transformed_G2 = transform_to_complete_graph(G)\n",
        "\n",
        "for v_i in transformed_G.nodes:\n",
        "  print(transformed_G.nodes(data=True)[v_i])\n",
        "  print(transformed_G2.nodes(data=True)[v_i])\n",
        "  print(\" \")\n",
        "\n",
        "#transformed_G.nodes(data=True), transformed_G2.nodes(data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFpC_zhrqtxf"
      },
      "outputs": [],
      "source": [
        "transformed_G.nodes(data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apjut4wbVfge"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIEZLYgUDQg"
      },
      "outputs": [],
      "source": [
        "g = from_networkx(transformed_G, group_node_attrs=[\"is_real\", \"weight\"])\n",
        "g, g.x, g.edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGLwThw_EMzU"
      },
      "outputs": [],
      "source": [
        "class ShuffleList:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        random.shuffle(self.data)\n",
        "        self.index = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index < len(self.data):\n",
        "            value = self.data[self.index]\n",
        "            self.index += 1\n",
        "            return value\n",
        "        else:\n",
        "            raise StopIteration\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RsTVhBtFMfG"
      },
      "source": [
        "#### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C828QNI-FN0j"
      },
      "outputs": [],
      "source": [
        "def remove_edges(graph, threshold = 0.0):\n",
        "    # Create a deep copy of the graph\n",
        "    new_graph = copy.deepcopy(graph)\n",
        "\n",
        "    # List to store edges to be removed\n",
        "    edges_to_remove = []\n",
        "\n",
        "    # Find edges with weight < 0.5\n",
        "    for u, v, data in new_graph.edges(data=True):\n",
        "        if 'weight' in data and data['weight'] < threshold:\n",
        "            edges_to_remove.append((u, v))\n",
        "\n",
        "    # Remove edges\n",
        "    for edge in edges_to_remove:\n",
        "        new_graph.remove_edge(*edge)\n",
        "\n",
        "    return new_graph\n",
        "\n",
        "def reduce_nx_graph(g_old):\n",
        "  g_new = nx.Graph()\n",
        "  for v_i in g_old.nodes():\n",
        "    if g_old.nodes[v_i]['x'][0] > 0.1:\n",
        "      g_new.add_node(v_i)\n",
        "      g_new.nodes[v_i]['x'] = g_old.nodes[v_i]['x']\n",
        "\n",
        "  for v_i in g_old.nodes():\n",
        "    if g_old.nodes[v_i]['x'][0] < 0.1:\n",
        "      neigh_list = list(g_old.neighbors(v_i))\n",
        "      if len(neigh_list) != 2:\n",
        "        print(neigh_list)\n",
        "      assert(len(neigh_list) == 2)\n",
        "      g_new.add_edge(neigh_list[0], neigh_list[1], weight = g_old.nodes[v_i]['x'][1])\n",
        "  return g_new\n",
        "\n",
        "def pyg_graph_to_nx(g_pyg, edge_weights):\n",
        "  g_pyg = g_pyg.clone()\n",
        "\n",
        "  edge_indices = g_pyg.x[:,0] < 0.1\n",
        "  g_pyg.x[edge_indices,1] = edge_weights\n",
        "\n",
        "  g_nx = to_networkx(g_pyg, node_attrs=['x'], to_undirected=True)\n",
        "  g_nx = reduce_nx_graph(g_nx)\n",
        "  return g_nx\n",
        "\n",
        "def pyg_to_sparsebinary_nx(g_pyg):\n",
        "  edge_indices = g_pyg.x[:,0] < 0.1\n",
        "  edge_weights = g_pyg.x[edge_indices,1]\n",
        "\n",
        "  # Assuming pyg_graph_to_nx and remove_edges are defined or imported correctly in your script\n",
        "  g_nx = pyg_graph_to_nx(g_pyg, edge_weights)\n",
        "  g_nx = remove_edges(g_nx, threshold = 0.0)\n",
        "\n",
        "  for edge in g_nx.edges:\n",
        "    del g_nx.edges[edge]['weight']\n",
        "  return g_nx\n",
        "\n",
        "\n",
        "def plot_weighted_graph(edge_weights, g_pyg, ax, pos=None, binarize=False):\n",
        "  if edge_weights is None:\n",
        "    edge_indices = g_pyg.x[:,0] < 0.1\n",
        "    edge_weights = g_pyg.x[edge_indices,1]\n",
        "\n",
        "  g_nx = pyg_graph_to_nx(g_pyg, edge_weights)\n",
        "\n",
        "  edge_weights = nx.get_edge_attributes(g_nx, 'weight')\n",
        "  edge_weights = [edge_weights[e] for e in g_nx.edges]\n",
        "\n",
        "  if binarize:\n",
        "    edge_weights = [1.0 if w>0.0 else -1.0 for w in edge_weights]\n",
        "    edge_weights_for_mean = [max(w,0.) for w in edge_weights]\n",
        "    print(\"Mean degree:\", 2*np.sum(edge_weights_for_mean)/g_nx.number_of_nodes())\n",
        "\n",
        "  if pos is None:\n",
        "    g_nx_sparse = remove_edges(g_nx)\n",
        "    pos = nx.spring_layout(g_nx_sparse)\n",
        "  edge_colors = [max(w, -1.) for w in edge_weights]\n",
        "  edge_colors = [min(w, 1.) for w in edge_colors]\n",
        "  edge_colors = [w/2.0+0.5 for w in edge_colors]\n",
        "\n",
        "  for i, e in enumerate(g_nx.edges):\n",
        "    nx.draw(g_nx, pos, edge_color=\"black\", edgelist = [e], ax=ax, alpha=edge_colors[i], nodelist=list())\n",
        "\n",
        "  nx.draw(g_nx, pos,\n",
        "          node_color='red', with_labels=False, ax=ax, alpha=0.5, node_size=4, edgelist=list())\n",
        "\n",
        "  if binarize:\n",
        "    return pos, g_nx_sparse\n",
        "  return pos, g_nx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxLa9eUNYWCg"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_-L-Pc3Y1Zp"
      },
      "outputs": [],
      "source": [
        "def lift_nx_to_pyg(g):\n",
        "  g = from_networkx(g, group_node_attrs=[\"is_real\", \"weight\"])\n",
        "  return g\n",
        "\n",
        "EDGE_INDEX_STORAGE = dict()\n",
        "def lift_nx_to_complete_pyg(g):\n",
        "  global EDGE_INDEX_STORAGE\n",
        "  #g = transform_to_complete_graph(g)\n",
        "  g = transform_graph(g, make_complete=True)\n",
        "  g = lift_nx_to_pyg(g)\n",
        "  node_num_lifted = g.x.shape[0]\n",
        "  if node_num_lifted not in EDGE_INDEX_STORAGE:\n",
        "    EDGE_INDEX_STORAGE[node_num_lifted] = g.edge_index\n",
        "  #assert(torch.all(EDGE_INDEX_STORAGE[node_num_lifted] == g.edge_index))\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TUFSCq4Ye2y"
      },
      "outputs": [],
      "source": [
        "def build_dataset(num_nodes=NUM_NODES, num_samples=NUM_SAMPLES, degree=DEGREE, seed=1234):\n",
        "  global EDGE_INDEX_STORAGE\n",
        "\n",
        "  try:\n",
        "    with open(f\"dataset_{NUM_NODES:07}_{NUM_SAMPLES:07}_{DEGREE:03}.pickle\", \"rb\") as f:\n",
        "      tain_set, test_set = pickle.load(f)\n",
        "      print(f\"found dataset: dataset_{NUM_NODES:07}_{NUM_SAMPLES:07}_{DEGREE:03}.pickle\")\n",
        "      return tain_set, test_set\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "  dataset = list()\n",
        "\n",
        "  for _ in range(num_samples):\n",
        "    while True:\n",
        "      seed += 1\n",
        "      graph = nx.random_regular_graph(d=degree, n=num_nodes, seed=seed)\n",
        "      if nx.is_connected(graph):\n",
        "        dataset.append(lift_nx_to_complete_pyg(graph))\n",
        "        break\n",
        "\n",
        "  dataset_train = dataset[:int(len(dataset)*TRAIN_TEST_SPLIT)]\n",
        "  dataset_test = dataset[int(len(dataset)*TRAIN_TEST_SPLIT):]\n",
        "  dataset_train = ShuffleList(dataset_train)\n",
        "  dataset_test = ShuffleList(dataset_test)\n",
        "\n",
        "  with open(f\"dataset_{NUM_NODES:07}_{NUM_SAMPLES:07}_{DEGREE:03}.pickle\", \"wb\") as f:\n",
        "    pickle.dump((dataset_train, dataset_test), f)\n",
        "  return dataset_train, dataset_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LpCfVUcP7Rq"
      },
      "outputs": [],
      "source": [
        "#!rm dataset_*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU0cHznL2bjQ"
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test  = build_dataset()\n",
        "g1 = dataset_train[0]\n",
        "g2 = dataset_train[1]\n",
        "g3 = dataset_train[2]\n",
        "print(g1.edge_index)\n",
        "print(g2.edge_index)\n",
        "print(g3.edge_index)\n",
        "#torch.all(g1.edge_index == g2.edge_index) and torch.all(g2.edge_index == g3.edge_index)\n",
        "# For this line \"g1.edge_index == g2.edge_index and g2.edge_index == g3.edge_index\", I get the error \"Boolean value of Tensor with more than one value is ambiguous\". Fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNhDqcUcYfKV"
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test  = build_dataset()\n",
        "data = dataset_train[0]\n",
        "data, data.x\n",
        "#data.edge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE8eu8YHxYSb"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5gRUpdExZnl"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 3\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "    return x\n",
        "\n",
        "\n",
        "model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyUalHA2Ehyn"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wmE0o9liKb8"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "    \"\"\"\n",
        "    Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "    Args:\n",
        "    start (float): The starting value for the beta values. Default is START.\n",
        "    end (float): The ending value for the beta values. Default is END.\n",
        "    timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "    cumulative alpha values (alpha bars).\n",
        "    \"\"\"\n",
        "    betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "    alphas = 1.0 - betas\n",
        "    alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "    assert(betas.numel() == TIMESTEPS)\n",
        "    return betas, alphas, alpha_bars\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZkmSsNfE41g"
      },
      "outputs": [],
      "source": [
        "def compute_generation_loss(graphs, train_loader):\n",
        "  #graphs = [remove_edges(g) for g in graphs]\n",
        "  loss_list = list()\n",
        "  for graph in graphs:\n",
        "    degree_list = [graph.degree(i) for i in graph.nodes()]\n",
        "    mean_degree = np.mean(degree_list)\n",
        "    var_degree = np.var(degree_list)\n",
        "    loss = (3.0-mean_degree)**2 + var_degree\n",
        "    loss_list.append(loss)\n",
        "  return np.mean(loss_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3CMj8TyDOGV"
      },
      "source": [
        "### Load checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPWqWq5oE9n5"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, graph_loss_list, loss_list, epoch_i):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'graph_loss_list': graph_loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "\n",
        "def load_latest_checkpoint(model, optimizer, graph_loss_list, loss_list, epoch_i):\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(\"model_epoch_*.pth\"))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, graph_loss_list, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    graph_loss_list = checkpoint['graph_loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, graph_loss_list, loss_list, epoch_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFOtSm7-qwBg"
      },
      "outputs": [],
      "source": [
        "#!ls\n",
        "#!ls ../Toad_relaxed_large5/model_epoch_*\n",
        "#!cp ../Toad_relaxed_large5/model_epoch_00020000.pth model_epoch_00020000.pth\n",
        "#!ls model_epoch_00020000*\n",
        "#!ls\n",
        "#!cp model_epoch_00020000.pth ../Alia1/model_epoch_00020000.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHMwkfUXEk3G"
      },
      "source": [
        "### Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPtXnyVpElAc"
      },
      "outputs": [],
      "source": [
        "def forward_diffusion(input_vec, future_t, betas):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an input image tensor.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  assert(input_vec.shape == future_t.shape)\n",
        "  #future_t = torch.tensor([future_t], dtype=torch.int64)\n",
        "\n",
        "  noise = torch.randn_like(input_vec, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t)\n",
        "\n",
        "  img_mean = torch.sqrt(alphabar_t) * input_vec\n",
        "  img_std = torch.sqrt(1.-alphabar_t)\n",
        "  noise_img = img_mean + img_std * noise\n",
        "\n",
        "  return noise_img, noise\n",
        "\n",
        "betas, alphas, alpha_bars = generate_schedule()\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE), torch.tensor([0,0,0], device=DEVICE), betas), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE), torch.tensor([999,999,999], device=DEVICE), betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6sk4-QGJAUX"
      },
      "outputs": [],
      "source": [
        "betas, alphas, alpha_bars = generate_schedule()\n",
        "plt.clf()\n",
        "plt.plot(betas.cpu(), label=\"betas\", alpha=0.7)\n",
        "plt.plot(alphas.cpu(), label=\"alphas\", alpha=0.7, ls='--')\n",
        "plt.plot(torch.sqrt(alphas.cpu()), label=\"sqrt(alphas)\", alpha=0.7, ls=':')\n",
        "plt.plot(alpha_bars.cpu(), label=\"alpha_bars\", alpha=0.7)\n",
        "plt.plot((1-alphas.cpu())/(torch.sqrt(1-alpha_bars.cpu())), label=\"1-alpha/(sqrt...)\", alpha=0.3, lw=4)\n",
        "plt.legend()\n",
        "plt.savefig(\"schedule.png\")\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9OLoSsXiYEZ"
      },
      "outputs": [],
      "source": [
        "def test_forward(num=1000000):\n",
        "  g = dataset_train[0]\n",
        "  try:\n",
        "      with open(\"edge_weights_simple_example.pickle\", \"rb\") as f:\n",
        "          edge_weights = pickle.load(f)\n",
        "  except:\n",
        "      edge_weights = torch.tensor([random.choice([NO_EDGE_INDICATOR, EDGE_INDICATOR]) for _ in range(num)])\n",
        "      with open(\"edge_weights_simple_example.pickle\", \"wb\") as f:\n",
        "          pickle.dump(edge_weights, f)\n",
        "\n",
        "  #print(edge_weights)\n",
        "  edge_weights = edge_weights.to(DEVICE)\n",
        "  #betas.to(DEVICE)\n",
        "  future_t = torch.tensor([999]*len(edge_weights), device=DEVICE)\n",
        "  edge_weights, noise_gt = forward_diffusion(edge_weights, future_t, betas)\n",
        "  edge_weights.tolist()\n",
        "\n",
        "  #print(edge_weights)\n",
        "  sns.kdeplot(edge_weights.cpu())\n",
        "\n",
        "\n",
        "  #Gaussian\n",
        "  from scipy.stats import norm\n",
        "  standard_normal_pdf = lambda x: norm(0, 1).pdf(x)\n",
        "  x_values = np.linspace(-4,4,100)\n",
        "  plt.scatter(x_values, [standard_normal_pdf(x) for x in x_values], c='black', alpha=0.5, marker='x', edgecolors=None, label='Gaussian')\n",
        "test_forward(num=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hzSAZK0h7q"
      },
      "source": [
        "### Train epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "QEN_3s2zlss7"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, schedule):\n",
        "  \"\"\"\n",
        "  Trains a denoising model for one epoch using a given data loader and optimization algorithm.\n",
        "\n",
        "  Args:\n",
        "  model: The denoising model.\n",
        "  dataloader: The data loader for the training data.\n",
        "  optimizer: The torch optimizer.\n",
        "  schedule (torch.Tensor): The schedule of beta values.\n",
        "\n",
        "  Returns:\n",
        "  float: The average loss for the epoch.\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list() #TODO differnt future_t for all graphs\n",
        "\n",
        "  for g in dataloader:\n",
        "    g.to(DEVICE)\n",
        "    #print(\"batch\", g.batch)\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.tensor([0]) #torch.gather(future_t_select, 0, g.batch)\n",
        "    #print(\"future_t\", future_t)\n",
        "    assert(future_t.numel() == g.x.shape[0])\n",
        "\n",
        "    #return 0/0\n",
        "    #future_t = torch.randint(0, TIMESTEPS, (1,), device = DEVICE)\n",
        "\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "    edge_weights[edge_indices] = edges_with_noise\n",
        "    #future_t_vec = future_t.repeat(edge_weights.numel())\n",
        "\n",
        "    #print(\"x in train \", g.x[:,0].shape, edge_weights.shape, future_t_vec.shape)\n",
        "    x_in = torch.concat((g.x[:,0].view(-1,1), edge_weights.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "    assert(x_in.shape[0] == g.x.shape[0])\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    noise_pred = model(x_in, g.edge_index)\n",
        "    noise_pred = noise_pred[edge_indices].flatten()\n",
        "\n",
        "\n",
        "    loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return np.mean(loss_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "7pld6IY2GK2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "bab850a0-3705-4d03-fcc1-9593a4005291"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab/AliaMolecule/Alia/smiles_to_pyg/qm9_as_graphs_from_0_to_-1.pickle not found. Creating it now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 39480/133884 [02:43<06:31, 241.16it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-e2f32b6d3dcf>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_bars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mvisualize_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-7f2d9364c5a7>\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mAlia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_to_pyg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecule_load_and_convert3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_qm9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_qm9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTRAIN_TEST_SPLIT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/colab/AliaMolecule/Alia/smiles_to_pyg/molecule_load_and_convert3.py\u001b[0m in \u001b[0;36mread_qm9\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0msmiles_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_canonical_smiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_to_pyg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/colab/AliaMolecule/Alia/smiles_to_pyg/molecule_load_and_convert3.py\u001b[0m in \u001b[0;36msmiles_to_pyg\u001b[0;34m(smiles_mol)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mpyg_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_node_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0mpyg_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyg_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyg_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/convert.py\u001b[0m in \u001b[0;36mfrom_networkx\u001b[0;34m(G, group_node_attrs, group_edge_attrs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_node_labels_to_integers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDiGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36mto_directed\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1699\u001b[0m         G.add_edges_from(\n\u001b[1;32m   1700\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_nodes_from\u001b[0;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \"\"\"\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_for_adding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0mnewnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1699\u001b[0m         G.add_edges_from(\n\u001b[1;32m   1700\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;31m# TODO: skipping storage copy is wrong for meta, as meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# does accurate alias tracking; however, the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \"\"\"\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def visualize_forward(schedule, g, steps=10):\n",
        "  plt.close()\n",
        "  future_t_index = np.linspace(0, TIMESTEPS-0.5, steps).astype(int)\n",
        "\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
        "  pos = None\n",
        "\n",
        "  for i, future_t in enumerate(future_t_index):\n",
        "    future_t = torch.tensor(future_t, device=DEVICE)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t.repeat(len(edge_weights[edge_indices])), schedule)\n",
        "    if i == 0:\n",
        "      edges_with_noise = edge_weights[edge_indices]\n",
        "    pos, g_nx = plot_weighted_graph(edges_with_noise, g, axes[i], pos=pos)\n",
        "    axes[i].axis('off')  # to hide the axis\n",
        "  plt.savefig(\"example_foward.png\")\n",
        "\n",
        "\n",
        "dataset_train, dataset_test = build_dataset()\n",
        "betas, alphas, alpha_bars = generate_schedule()\n",
        "visualize_forward(betas, dataset_train[0].to(DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZXAFwdYr--b"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suojddTWtx-8"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step(model, g, i, betas):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  t = TIMESTEPS - i - 1\n",
        "\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  t_tensor = torch.tensor([float(t)], device=DEVICE)\n",
        "\n",
        "  t_vec = t_tensor.repeat(g.x.shape[0],1)\n",
        "  x_in = torch.concat((g.x, t_vec), dim=1)\n",
        "  noise_pred = model(x_in, g.edge_index)\n",
        "  noise_pred = noise_pred[edge_indices].flatten()\n",
        "\n",
        "  # extract edge weights\n",
        "\n",
        "  values_in = g.x[edge_indices,1]\n",
        "\n",
        "  # actual denoising\n",
        "  model_mean = sqrt_recip_alphas_t * (values_in - beta_t * noise_pred / sqrt_one_minus_alphas_cumprod_t)\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "  posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # in the paper this is in 3.2. note that sigma^2 is variance, not std\n",
        "  posterior_variance_t = posterior_variance[t]\n",
        "  posterior_std_t = torch.sqrt(posterior_variance_t)\n",
        "\n",
        "  if t == 0:\n",
        "    return model_mean\n",
        "  else:\n",
        "    noise = torch.randn_like(values_in, device = DEVICE)\n",
        "    return model_mean + posterior_std_t * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm7itEUUJtNI"
      },
      "outputs": [],
      "source": [
        "def model_inference(model, g, t):\n",
        "  future_t = torch.tensor(t, device=DEVICE).repeat(g.x.shape[0])\n",
        "  x_in = torch.concat((g.x.view(-1,2), future_t.view(-1,1)), dim=1)\n",
        "\n",
        "  # prediction\n",
        "  try:\n",
        "    batch = g.batch\n",
        "  except:\n",
        "    batch = None #torch.zeros(g.x.shape[0], dtype=torch.long, device=D)\n",
        "  prediction = model(x_in, g.edge_index, batch=batch)\n",
        "  #print(g, prediction, batch)\n",
        "  if g.batch is None or torch.max(g.batch) > 0:\n",
        "    return prediction.cpu().numpy()\n",
        "  return prediction.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcuFV1JMFjFu"
      },
      "outputs": [],
      "source": [
        "def make_choice(choice_list, scores):\n",
        "    assert len(scores) == len(choice_list)\n",
        "\n",
        "    batches = choice_list[0].batch.tolist()\n",
        "    best_graph_for_batch = []\n",
        "\n",
        "    for b_i in batches:\n",
        "        s_i = [s[b_i] for s in scores]\n",
        "        best_graph_for_batch.append(np.argmax(s_i))\n",
        "\n",
        "    g1 = choice_list[0]\n",
        "\n",
        "    for i in range(g1.x.shape[0]):\n",
        "        batch_i = g1.batch[i]\n",
        "        best_graph_in_i = best_graph_for_batch[batch_i]\n",
        "        best_graph = choice_list[best_graph_in_i]\n",
        "        g1.x[i, :] = best_graph.x[i, :]#.clone()\n",
        "\n",
        "    return g1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktPawiOMvUS"
      },
      "outputs": [],
      "source": [
        "def make_choice_sparse(g, choice_list, scores):\n",
        "    assert len(scores) == len(choice_list)\n",
        "\n",
        "    batches = g.batch.tolist()\n",
        "    best_graph_for_batch = []\n",
        "\n",
        "    for b_i in batches:\n",
        "        s_i = [s[b_i].cpu() for s in scores]\n",
        "        best_graph_for_batch.append(np.argmax(s_i))\n",
        "\n",
        "    for i in range(g.x.shape[0]):\n",
        "        if g.x[i,0] > 0.1:\n",
        "          continue\n",
        "        batch_i = g.batch[i]\n",
        "        best_graph_in_i = best_graph_for_batch[batch_i]\n",
        "        best_weights = choice_list[best_graph_in_i]\n",
        "        g.x[i, 1] = best_weights[i]#.clone()\n",
        "\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxx6aU2UuvLa"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  #edge_weights = g.x[:,1]\n",
        "  #edges_without_noise = edge_weights[edge_indices]\n",
        "  g.x[edge_indices,1] = torch.randn_like(g.x[edge_indices,1], device=DEVICE)\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pda5tncJFKP"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples_batchedX(model, betas, dataset_train, model_guide, num=100, choices=2):\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  if model_guide is None:\n",
        "    choices=1\n",
        "  else:\n",
        "    model_guide = model_guide.to(DEVICE)\n",
        "    model_guide.eval()\n",
        "\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    g = overwrite_with_noise(g)\n",
        "    t_max = TIMESTEPS // GUIDE_FRACTION # where to start guideance  TODO\n",
        "\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if t <= t_max and model_guide is not None: # with guide\n",
        "\n",
        "        edges_with_less_noise1 = denoise_one_step(model, g, i, betas)\n",
        "        g_orig_w1 = g.x[:,1].clone().view(-1)\n",
        "        g_orig_w1[edge_indices] = edges_with_less_noise1\n",
        "\n",
        "        edges_with_less_noise2 = denoise_one_step(model, g, i, betas)\n",
        "        g_orig_w2 = g.x[:,1].clone().view(-1)\n",
        "        g_orig_w2[edge_indices] = edges_with_less_noise2\n",
        "\n",
        "        future_t = torch.tensor(t, device=DEVICE).repeat(g.x.shape[0])\n",
        "        x_in1 = torch.concat((g.x[:,0].view(-1,1), g_orig_w1.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "        x_in2 = torch.concat((g.x[:,0].view(-1,1), g_orig_w2.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "        scores1 = model_guide(x_in1, g.edge_index, batch=g.batch)\n",
        "        scores2 = model_guide(x_in2, g.edge_index, batch=g.batch)\n",
        "        g = make_choice_sparse(g, [g_orig_w1, g_orig_w2], [scores1, scores2])\n",
        "\n",
        "        if i == TIMESTEPS -1:\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "      else: #without guide\n",
        "        edges_with_less_noise = denoise_one_step(model, g, i, betas)\n",
        "        g.x[edge_indices,1] = edges_with_less_noise\n",
        "        if i == TIMESTEPS -1:\n",
        "          print(\"edges_denoised_binary\", edges_denoised_binary)\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    #break\n",
        "\n",
        "    print(\"generated graphs \", graph_list)\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTwsjZHvfXgj"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples_batched(model, betas, dataset_train, model_guide, num=100, choices=2):\n",
        "  print(\"generate samples batched\")\n",
        "\n",
        "  #model.eval()\n",
        "  assert(choices == 1 or choices == 2)\n",
        "  if model_guide is None:\n",
        "    choices=1\n",
        "  else:\n",
        "    model_guide = model_guide.to(DEVICE)\n",
        "    model_guide.eval()\n",
        "\n",
        "\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "  for g in dataloader:\n",
        "    print(\"load g\", g, g.batch)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    g = overwrite_with_noise(g)\n",
        "    t_max = TIMESTEPS // GUIDE_FRACTION # where to start guideance  TODO\n",
        "\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if t <= t_max and model_guide is not None: # with guide\n",
        "        choice_list = list()\n",
        "        for j in range(choices):\n",
        "          if j == choices-1:\n",
        "            g_alt = g\n",
        "          else:\n",
        "            g_alt = g.clone()\n",
        "          edges_with_less_noise = denoise_one_step(model, g_alt, i, betas)\n",
        "          g_alt.x[edge_indices,1] = edges_with_less_noise\n",
        "          choice_list.append(g_alt)\n",
        "        if choices == 1:\n",
        "          g = choice_list[0]\n",
        "        else:\n",
        "          scores = [model_inference(model_guide, g, t) for g in choice_list] # todo add batching\n",
        "          g = make_choice(choice_list, scores)\n",
        "        if i == TIMESTEPS -1:\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "      else: #without guide\n",
        "        edges_with_less_noise = denoise_one_step(model, g, i, betas)\n",
        "        g.x[edge_indices,1] = edges_with_less_noise\n",
        "        if i == TIMESTEPS -1:\n",
        "          #print(\"weights\",torch.mean(g.x[edge_indices,1]),g.x[edge_indices,1] )\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    #break\n",
        "\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuyPKETI9c-I"
      },
      "outputs": [],
      "source": [
        "def generate_examples_guided(model, betas, dataset_train, model_guide, num=100, choices=2):\n",
        "  print(\"generate samples with guidance\")\n",
        "  gen_set = list()\n",
        "  model_guide = model_guide.to(DEVICE)\n",
        "  tqdm_x = tqdm if num > 10 else lambda x: x\n",
        "  for i in tqdm_x(range(num)):\n",
        "    g = dataset_train[random.choice(range(len(dataset_train)))].clone().to(DEVICE)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_without_noise = edge_weights[edge_indices]\n",
        "    edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "    g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    t_max = TIMESTEPS // GUIDE_FRACTION\n",
        "\n",
        "    for i in range(TIMESTEPS):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if t <= t_max:\n",
        "        choice_list = list()\n",
        "        for j in range(choices):\n",
        "          g_alt = g.clone()\n",
        "          edges_with_noise = denoise_one_step(model, g_alt, i, betas)\n",
        "          g_alt.x[edge_indices,1] = edges_with_noise\n",
        "          choice_list.append(g_alt)\n",
        "        scores = [model_inference(model_guide, g, t) for g in choice_list]\n",
        "        g = choice_list[np.argmax(scores)]\n",
        "        edges_with_noise = g.x[edge_indices,1] # relevant for last step\n",
        "      else:\n",
        "        edges_with_noise = denoise_one_step(model, g, i, betas)\n",
        "        g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    edges_denoised_binary = torch.where(edges_with_noise > 0.0, 1., -1.)\n",
        "\n",
        "    g.x[edge_indices,1] = edges_denoised_binary\n",
        "    gen_set.append(g)\n",
        "\n",
        "  return gen_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO-QiVKxEmAb"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples_silent(model, betas, dataset_train, model_guide = None, num=100):\n",
        "  if model_guide is not None:\n",
        "    return generate_examples_guided(model, betas, dataset_train, model_guide, num=num)\n",
        "  print(\"generate samples without guidance\")\n",
        "  gen_set = list()\n",
        "  tqdm_x = tqdm if num > 10 else lambda x: x\n",
        "  for i in tqdm_x(range(num)):\n",
        "    g = dataset_train[random.choice(range(len(dataset_train)))].clone().to(DEVICE)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_without_noise = edge_weights[edge_indices]\n",
        "    edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "    g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    for i in range(TIMESTEPS):\n",
        "      edges_with_noise = denoise_one_step(model, g, i, betas)\n",
        "      g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    edges_denoised_binary = torch.where(edges_with_noise > 0.0, 1., -1.)\n",
        "\n",
        "    g.x[edge_indices,1] = edges_denoised_binary\n",
        "    gen_set.append(g)\n",
        "\n",
        "  return gen_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6OVKWQVp4lR"
      },
      "outputs": [],
      "source": [
        "#@torch.inference_mode()\n",
        "def generate_example(model, epoch_i, betas, dataset_train, steps=10, silent=False):\n",
        "  plt.close()\n",
        "  #model.eval()\n",
        "\n",
        "  g = dataset_train[random.choice(range(len(dataset_train)))].clone() # we sample to get a random number of node\n",
        "\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1].clone()\n",
        "  edges_without_noise = edge_weights[edge_indices]\n",
        "  edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "  g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "  future_t_index = list(np.linspace(0, TIMESTEPS-0.5, steps).astype(int))\n",
        "\n",
        "  if not silent:\n",
        "    fig, axes = plt.subplots(1, steps, figsize=(20, 2))\n",
        "  else:\n",
        "    axes = range(steps)\n",
        "  pos = None\n",
        "\n",
        "  graphs_to_plot = list()\n",
        "\n",
        "  ax_count = -1\n",
        "  for i in range(TIMESTEPS):\n",
        "    if i == future_t_index[0]:\n",
        "      ax_count += 1\n",
        "      binarize = len(future_t_index) == 1\n",
        "      graphs_to_plot.append((edges_with_noise,g.clone(),axes[ax_count],binarize))\n",
        "      future_t_index.pop(0)\n",
        "\n",
        "    g.x[edge_indices,1] = edges_with_noise\n",
        "    edges_with_noise = denoise_one_step(model, g, i, betas)\n",
        "\n",
        "  # we want that pos is computed based on the final graph\n",
        "  graph_to_return = None\n",
        "  for (edges_with_noise,g,ax,binarize) in graphs_to_plot[::-1]:\n",
        "    if not silent:\n",
        "      pos, g_nx = plot_weighted_graph(edges_with_noise, g, ax, pos=pos, binarize=binarize)\n",
        "      ax.axis('off')\n",
        "      if binarize:\n",
        "        graph_to_return = g_nx\n",
        "\n",
        "  if not silent:\n",
        "    plt.savefig(f\"reverse_process_reference_epoch_{str(epoch_i).zfill(6)}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    return graph_to_return\n",
        "\n",
        "  return graphs_to_plot[-1][1]\n",
        "  # save model\n",
        "\n",
        "\n",
        "\n",
        "def execute_function_times(function, num_executions, *args, **kwargs):\n",
        "  results = []\n",
        "  show = tqdm if num_executions>15 else lambda x:x\n",
        "  for _ in show(range(num_executions)):\n",
        "    result = function(*args, **kwargs)\n",
        "    results.append(result)\n",
        "  return results\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate_examples(model, epoch_i, betas, dataset_train, num_times=NUM_GRAPHS_TO_GENERATE, silent=False):\n",
        "  return execute_function_times(generate_example, num_times, model, epoch_i, betas, dataset_train, silent=silent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdPFgj3nEx9_"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftwezkN8f_sS"
      },
      "outputs": [],
      "source": [
        "##path = \"model_epoch_00019900.pth\"\n",
        "#checkpoint = torch.load(path)\n",
        "#checkpoint.keys()\n",
        "#checkpoint[\"graph_loss_list\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSgh0o0H3Tv5"
      },
      "outputs": [],
      "source": [
        "def plot_base(graph_loss_list, loss_list):\n",
        "  plt.clf()\n",
        "  plt.plot(graph_loss_list)\n",
        "  plt.title(\"graph_loss_list\")\n",
        "  plt.savefig(\"train_base_graph_loss.png\")\n",
        "  plt.clf()\n",
        "  plt.plot(loss_list)\n",
        "  plt.title(\"loss_list\")\n",
        "  plt.savefig(\"train_base_train_loss.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAmeusYrfwAb"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=None):\n",
        "  print(\"train base model\")\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "  lr = LEARNING_RATE\n",
        "  if BATCH_SIZE > 1:\n",
        "    lr = lr/100.0\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE)\n",
        "  loss_list = list()\n",
        "  graph_loss_list = list()\n",
        "  model_base, optimizer, graph_loss_list, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, graph_loss_list, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_num = epoch_num if epoch_num is not None else EPOCHS\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    if (epoch_i % 100 == 0 and epoch_i > 1000) or epoch_i == epoch_num - 1:\n",
        "      graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "      graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "      print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "      plot_base(graph_loss_list, loss_list)\n",
        "      save_model(model_base, optimizer, graph_loss_list, loss_list, epoch_i)\n",
        "      if epoch_i == epoch_num - 1:\n",
        "        break # dont train in final epoch so that saved model is final\n",
        "\n",
        "    try:\n",
        "      loss, time_elapsed = train_epoch(model_base, train_loader, optimizer, betas)\n",
        "      loss_list.append(loss.item())\n",
        "      if epoch_i % 10 == 0 or epoch_i == epoch_num - 1:\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss.item():05.4f} with mean loss {np.mean(loss_list + [loss.item()]):05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNFoBC6PNfkY"
      },
      "source": [
        "# Discriminative Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgtMvfeuRw7F"
      },
      "source": [
        "- sample 100 train and 100 test graphs from DM\n",
        "- sample 100 train and 100 test graphs from trainset\n",
        "- train discriminator on DM-train and DM-test, D: g -> [0,1]\n",
        "- evaluate discriminator on DM-test, D(g)\n",
        "- initialize predictor P: g' -> [0,1], where g' is a (diffused) graph\n",
        "- for each g in DM-test, do forward diffusion until random t to get g'\n",
        "- train P(g') to predict D(g)\n",
        "- To sample graph: do inference on DM with the guidance function P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PvBw1h-RPPi"
      },
      "source": [
        "### Gen Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Q8pRbdhXGY"
      },
      "outputs": [],
      "source": [
        "#!rm generated_samples.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2_K2CQgUAoI"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=16, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 1\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    if x.shape[1] == 2:\n",
        "      x = x[:,1].reshape(-1,1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    #x = self.final_mlp(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model_disc = PNAdisc(disc_train_set)\n",
        "#model_disc.to(DEVICE)\n",
        "#g = binary_graphs[0]\n",
        "#g.to(DEVICE)\n",
        "#print(g, g.x.shape, g.edge_index.shape)  #Data(x=[18, 1], edge_index=[2, 50], weight=[50], y=0) torch.Size([18, 1]) torch.Size([2, 50])\n",
        "#model_disc(g.x, g.edge_index, batch=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7iN9Tgcp4YB"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer, update_model=True):\n",
        "  if update_model:\n",
        "    model_disc.train()\n",
        "  else:\n",
        "    model_disc.eval()\n",
        "\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for g in dataloader:\n",
        "    g.to(DEVICE)\n",
        "    if update_model:\n",
        "     optimizer.zero_grad()\n",
        "    target = model_disc(g.x, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "    loss = ((target.view(-1) - g.y.view(-1)))**2\n",
        "    if update_model:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    loss = np.sqrt(loss.item())  # convert MSE to L1\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(0.0 if loss > 0.5 else 1.0)\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CWNQS7n9rzx"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader_disc_test):\n",
        "  return train_epoch_disc(model_disc, dataloader_disc_test, optimizer=None, update_model=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9FH4yvbnMAb"
      },
      "outputs": [],
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc)\n",
        "  weight_path = f\"discriminator_model_{round_i:03}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:04}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 0:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:01.3f}\")\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"discriminator_model_{round_i:03}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_disc.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isOhA5Kecd2U"
      },
      "outputs": [],
      "source": [
        "#train_loader_disc = DataLoader(binary_graphs, batch_size=1, shuffle=True)\n",
        "#train_loader_disc = DataLoader(disc_train_set, batch_size=1, shuffle=True)\n",
        "\n",
        "#model_disc = PNAdisc(train_loader_disc)\n",
        "#model_disc.to(DEVICE)\n",
        "\n",
        "#optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "\n",
        "#for epoch_i in range(100):\n",
        "#  loss, acc, t = train_epoch_disc(model_disc, train_loader_disc, optimizer_disc)\n",
        " # print(loss, acc, t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6SQ1V96LDpH"
      },
      "outputs": [],
      "source": [
        "def plot_graph_gen_loss(graph_gen_loss_list, round_i):\n",
        "  plt.clf()\n",
        "  plt.plot(graph_gen_loss_list)\n",
        "  plt.title(\"graph gen loss\")\n",
        "  plt.savefig(f\"graph_gen_loss_{round_i:03}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGbVSPgK_jlL"
      },
      "source": [
        "### Sample base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtAf3tRJlTJg"
      },
      "outputs": [],
      "source": [
        "def sample_base_model(model_base, round_i, model_guide=None, num=100):\n",
        "  try:\n",
        "    with open(f\"generated_samples_{round_i:03}.pickle\", \"rb\") as f:\n",
        "      generated_samples, generated_samples_nx, graph_gen_loss_list = pickle.load(f)\n",
        "      assert(len(generated_samples) == num)\n",
        "      print(f\"found generated samples in round {round_i:04}.\")\n",
        "      #graph_gen_loss = compute_generation_loss(generated_samples_nx, None)\n",
        "      print(f\"Generated {len(generated_samples_nx):05} graphs. Graph generation loss list is:\", graph_gen_loss_list)\n",
        "      #plot_graph_gen_loss(graph_gen_loss, round_i)\n",
        "      return generated_samples\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred during training: \\n\", str(e))\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "  graph_gen_loss_list = list()\n",
        "  try:\n",
        "    if len(graph_gen_loss_list) == 0 and round_i>0:\n",
        "      round_x = round_i-1\n",
        "      with open(f\"generated_samples_{round_x:03}.pickle\", \"rb\") as f:\n",
        "        _, _, graph_gen_loss_list = pickle.load(f)\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred during training: \\n\", str(e))\n",
        "    traceback.print_exc()\n",
        "\n",
        "  #generated_samples = generate_examples_silent(model_base, betas, dataset_train, num=num, model_guide=model_guide)\n",
        "  generated_samples = generate_examples_batched(model_base, betas, dataset_train, num=num, model_guide=model_guide)\n",
        "\n",
        "  #random.shuffle(generated_samples)\n",
        "  assert(len(generated_samples) > 0)\n",
        "\n",
        "  generated_samples_nx = [pyg_to_sparsebinary_nx(g) for g in generated_samples]\n",
        "  graph_gen_loss = compute_generation_loss(generated_samples_nx, None)\n",
        "  print(\"graph_gen_loss: \",graph_gen_loss)\n",
        "  graph_gen_loss_list.append(graph_gen_loss)\n",
        "  plot_graph_gen_loss(graph_gen_loss_list, round_i)\n",
        "\n",
        "  with open(f\"generated_samples_{round_i:03}.pickle\", \"wb\") as f:\n",
        "    pickle.dump((generated_samples, generated_samples_nx, graph_gen_loss_list), f)\n",
        "\n",
        "  return generated_samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7vBbaspAZRB"
      },
      "outputs": [],
      "source": [
        "def plot_samples(disc_train_set, model_disc=None, round_i=0):\n",
        "  if os.path.exists(f'grid_images_for_disc_pred_{round_i:04}.png'):\n",
        "    print(\"found\", f'grid_images_for_disc_pred_{round_i:04}.png')\n",
        "    return\n",
        "\n",
        "  fig, axs = plt.subplots(16, 10, figsize=(20, 32))\n",
        "  nx_list = list()\n",
        "  mean_degree_list = list()\n",
        "\n",
        "  random.shuffle(disc_train_set)\n",
        "\n",
        "  ix = -1\n",
        "  for i in tqdm(range(16)):\n",
        "    for j in range(10):\n",
        "      ix += 1\n",
        "      g = disc_train_set[ix]\n",
        "      ax = axs[i, j]\n",
        "      pos, g_nx = plot_weighted_graph(None, g, ax, pos=None, binarize=True)\n",
        "      pred = 0\n",
        "      if model_disc is not None:\n",
        "        pred = model_disc(g.x, g.edge_index, batch=None).item()\n",
        "      g.pred = pred\n",
        "      #print(pred)\n",
        "\n",
        "      edge_weights = nx.get_edge_attributes(g_nx, 'weight')\n",
        "      edge_weights = [edge_weights[e]/2.0+0.5 for e in g_nx.edges] #done in plot_weighted...\n",
        "      mean_degree = 2*np.sum(edge_weights)/g_nx.number_of_nodes()\n",
        "      mean_degree_list.append(mean_degree)\n",
        "\n",
        "      ax.set_title(f\"{pred:.4f} - {mean_degree:01.2f}\")\n",
        "      ax.axis('off')\n",
        "      nx_list.append(g_nx)\n",
        "\n",
        "  #with open(f'grid_images_for_disc_pred_{round_i:04}.pickle', \"wb\") as f:\n",
        "  #  pickle.dump(nx_list, f)\n",
        "\n",
        "  #plt.tight_layout()\n",
        "  plt.savefig(f'grid_images_for_disc_pred_{round_i:04}.png', dpi=300)\n",
        "  print(f\"mean degree is {np.mean(mean_degree_list):02.5f}\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZtmsTm3s5z9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pgjxArr_q_5"
      },
      "source": [
        "# Guidance Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUCpj81oDihD"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "class PNAguide(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=5, dropout=0.00, towers=3, normalization=True, pre_post_layers=1):\n",
        "    super(PNAguide, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 3\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = torch.sum(x, dim=1)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model_guide = PNAguide(train_loader_disc)\n",
        "#model_guide.to(DEVICE)\n",
        "#g = train_loader_disc.dataset[0]\n",
        "#g.to(DEVICE)\n",
        "#print(g, g.x.shape, g.edge_index.shape)  #Data(x=[18, 1], edge_index=[2, 50], weight=[50], y=0) torch.Size([18, 1]) torch.Size([2, 50])\n",
        "#node_nun = g.x.shape[0]\n",
        "#x_in = torch.randn([node_nun, 3])\n",
        "#model_guide(x_in, g.edge_index, batch=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlkD45LK_w-_"
      },
      "outputs": [],
      "source": [
        "def train_epoch_guide(model_guide, model_disc, dataloader, optimizer, schedule, update_model=True, epoch_i=1):\n",
        "  if update_model:\n",
        "    model_guide.train()\n",
        "  else:\n",
        "    model_guide.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "\n",
        "  for g in dataloader:\n",
        "    g.to(DEVICE)\n",
        "    if update_model:\n",
        "      optimizer.zero_grad()\n",
        "    target = model_disc(g.x, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "\n",
        "    # comupte t vec\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    t_max = TIMESTEPS\n",
        "    #t_max = min(epoch_i+1, t_max // 3) # todo\n",
        "    #t_min = t_max - t_max // GUIDE_FRACTION\n",
        "    t_max=TIMESTEPS// GUIDE_FRACTION\n",
        "    future_t_select = torch.randint(0, t_max, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, g.batch)\n",
        "\n",
        "    # compute noisy edge weights\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "    edge_weights[edge_indices] = edges_with_noise\n",
        "    x_in = torch.concat((g.x[:,0].view(-1,1), edge_weights.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "\n",
        "    # prediction\n",
        "    prediction = model_guide(x_in, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "    loss = ((target.view(-1) - prediction.view(-1)))**2\n",
        "    if update_model:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    loss = np.sqrt(loss.item())  # convert MSE to L1\n",
        "    loss_list.append(loss)\n",
        "\n",
        "  return np.mean(loss_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgL1i5cOBwRT"
      },
      "outputs": [],
      "source": [
        "def test_guide(model_guide, model_disc, train_loader_disc_test, schedule, epoch_i):\n",
        "  return train_epoch_guide(model_guide, model_disc, dataloader=train_loader_disc_test, optimizer=None, schedule=schedule, update_model=False, epoch_i=epoch_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD2wR_7zGEO7"
      },
      "outputs": [],
      "source": [
        "def get_merged_dataloader(generated_samples, dataset):\n",
        "\n",
        "  #random.shuffle(dataset_train) # not needed because shuffle list\n",
        "  random.shuffle(generated_samples) # also prob not needed\n",
        "\n",
        "  num_elem = min(len(generated_samples), len(dataset))\n",
        "  disc_set = list()\n",
        "\n",
        "  for fake_graph in generated_samples[:num_elem]:\n",
        "    fake_graph = fake_graph.clone()\n",
        "    fake_graph.y =  0.0\n",
        "    disc_set.append(fake_graph)\n",
        "\n",
        "  for real_graph in dataset[:num_elem]:\n",
        "    real_graph = real_graph.clone()\n",
        "    real_graph.y = 1.0\n",
        "    disc_set.append(real_graph)\n",
        "\n",
        "  dataloader_disc = DataLoader(disc_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  return dataloader_disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntRL02_Jxbss"
      },
      "outputs": [],
      "source": [
        "def train_guide_model(model_disc, train_loader_disc, train_loader_disc_test, round_i):\n",
        "  model_guide = PNAguide(train_loader_disc)\n",
        "\n",
        "  weight_path = f\"guide_model_{round_i:03}.pth\"\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_guide.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found guide model in round {round_i:04}\")\n",
        "    return model_guide\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "  model_guide = model_guide.to(DEVICE)\n",
        "  optimizer_guide = Adam(model_guide.parameters(), lr = 0.0001)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  for epoch_i in range(EPOCHS_GUIDE_MODEL):\n",
        "    loss_train, t_train = train_epoch_guide(model_guide, model_disc, train_loader_disc, optimizer_guide, schedule=betas, epoch_i=epoch_i)\n",
        "    if epoch_i % 10 == 0:\n",
        "      loss_test, t_test = test_guide(model_guide, model_disc, train_loader_disc_test, betas, epoch_i=epoch_i)\n",
        "      print(f\"train guide: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, time: {t_train:02.3f}\")\n",
        "\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"guide_model_{round_i:03}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_guide.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_guide\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9P2NDVv_GGG"
      },
      "source": [
        "# Putting thinigs together I - Classical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YBTkSsL_HTT"
      },
      "outputs": [],
      "source": [
        "#dataset_base, dataset_base_test = build_dataset()\n",
        "#dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "#num_samples_train = int(NUM_SAMPLES*TRAIN_TEST_SPLIT)\n",
        "#num_samples_test = NUM_SAMPLES - num_samples_train\n",
        "#model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "#model_guide = None\n",
        "\n",
        "#for round_i in range(NUM_ROUNDS):\n",
        "#  samples = sample_base_model(model_base, round_i, model_guide=model_guide, num=NUM_SAMPLES)\n",
        "#  dataloader_disc = get_merged_dataloader(samples[:num_samples_train], dataset_base)\n",
        "#  dataloader_disc_test = get_merged_dataloader(samples[num_samples_train:], dataset_base_test)\n",
        "#  model_disc = train_disc_model(dataloader_disc, dataloader_disc_test, round_i)\n",
        "#  plot_samples(dataloader_disc.dataset, model_disc, round_i)\n",
        "#  model_guide = train_guide_model(model_disc, dataloader_disc, dataloader_disc_test, round_i)\n",
        "\n",
        "#  #new_epoch_num = BASE_MODEL_EPOCHS + (round_i+1)*int(BASE_MODEL_EPOCHS*0.2)\n",
        "#  #model_base = train_base_model(dataloader_base, epoch_num = new_epoch_num)\n",
        "\n",
        "#samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_guide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVfF7ZyuR4sC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDhvDZK_YPhu"
      },
      "source": [
        "# Putting thinigs together II - Single Disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olNy5xb9ZEcI"
      },
      "outputs": [],
      "source": [
        "def train_epoch_cassandra(model_cassandra, dataloader, optimizer, schedule, update_model=True, epoch_i=1):\n",
        "  if update_model:\n",
        "    model_cassandra.train()\n",
        "  else:\n",
        "    model_cassandra.eval()\n",
        "  model_cassandra = model_cassandra.to(DEVICE)\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    if update_model:\n",
        "      optimizer.zero_grad()\n",
        "    target = g.y\n",
        "\n",
        "    # comupte t vec\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    t_max = TIMESTEPS\n",
        "    #t_max = min(epoch_i+1, t_max // 3) # todo\n",
        "    #t_min = t_max - t_max // GUIDE_FRACTION\n",
        "    t_max=TIMESTEPS// GUIDE_FRACTION\n",
        "    future_t_select = torch.randint(0, t_max, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, g.batch)\n",
        "\n",
        "    # compute noisy edge weights\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "    edge_weights[edge_indices] = edges_with_noise\n",
        "    x_in = torch.concat((g.x[:,0].view(-1,1), edge_weights.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "\n",
        "    # prediction\n",
        "    prediction = model_cassandra(x_in, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "    loss = ((target.view(-1) - prediction.view(-1)))**2\n",
        "    if update_model:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    loss = np.sqrt(loss.item())  # convert MSE to L1\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(0.0 if loss > 0.5 else 1.0)\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J465bmjZXPl"
      },
      "outputs": [],
      "source": [
        "def test_cassandra(model_cassandra, train_loader_disc_test, schedule, epoch_i):\n",
        "  return train_epoch_cassandra(model_cassandra, dataloader=train_loader_disc_test, optimizer=None, schedule=schedule, update_model=False, epoch_i=epoch_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AO4cFiNYhbm"
      },
      "outputs": [],
      "source": [
        "def train_cassandra_model(train_loader_disc, train_loader_disc_test, round_i):\n",
        "  model_cassandra = PNAguide(train_loader_disc)\n",
        "\n",
        "\n",
        "  weight_path = f\"cassandra_model_{round_i:03}.pth\"\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_cassandra.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found cassandra model in round {round_i:04}\")\n",
        "    return model_cassandra\n",
        "  except:\n",
        "    print(weight_path, \"not found\")\n",
        "\n",
        "  model_cassandra = model_cassandra.to(DEVICE)\n",
        "  optimizer_cassandra = Adam(model_cassandra.parameters(), lr = 0.0001)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  for epoch_i in range(EPOCHS_GUIDE_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_cassandra(model_cassandra, train_loader_disc, optimizer_cassandra, schedule=betas, epoch_i=epoch_i)\n",
        "    if epoch_i % 10 == 0:\n",
        "      loss_test, acc_test, t_test = test_cassandra(model_cassandra, train_loader_disc_test, betas, epoch_i=epoch_i)\n",
        "      print(f\"train cassandra: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f},  acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:02.3f}\")\n",
        "\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"cassandra_model_{round_i:03}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_cassandra.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_cassandra\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2bmaEFZYR0n"
      },
      "outputs": [],
      "source": [
        "dataset_base, dataset_base_test = build_dataset()\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "num_samples_train = int(NUM_SAMPLES*TRAIN_TEST_SPLIT)\n",
        "num_samples_test = NUM_SAMPLES - num_samples_train\n",
        "model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "model_cassandra = None\n",
        "\n",
        "for round_i in range(NUM_ROUNDS):\n",
        "  samples = sample_base_model(model_base, round_i, model_guide=model_cassandra, num=NUM_SAMPLES)  #TODO\n",
        "  plot_samples(samples, model_disc=None, round_i=round_i)\n",
        "  dataloader_disc = get_merged_dataloader(samples[:num_samples_train], dataset_base)\n",
        "  dataloader_disc_test = get_merged_dataloader(samples[num_samples_train:], dataset_base_test)\n",
        "  model_cassandra = train_cassandra_model(dataloader_disc, dataloader_disc_test, round_i)\n",
        "  #new_epoch_num = BASE_MODEL_EPOCHS + (round_i+1)*int(BASE_MODEL_EPOCHS*0.2)\n",
        "  #model_base = train_base_model(dataloader_base, epoch_num = new_epoch_num)\n",
        "\n",
        "samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_cassandra, num=NUM_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC5nnw3GDaAN"
      },
      "outputs": [],
      "source": [
        "#!rm cassandra_model_*.pth\tgenerated_samples_001.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kvYvQ509ckB"
      },
      "outputs": [],
      "source": [
        "#!rm generated_samples_002.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egG7sdK6RFms"
      },
      "outputs": [],
      "source": [
        " z=z/0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QnaWzDLyBzn"
      },
      "outputs": [],
      "source": [
        "s1 = [pyg_to_sparsebinary_nx(s) for s in samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-rzR_kPyTMF"
      },
      "outputs": [],
      "source": [
        "samples[0].x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEVedU6KGDxZ"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuMUNIAbz2rE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_geometric.data as data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Define the adjacency matrices of the graphs\n",
        "adj_matrix1 = torch.tensor([[0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0]])\n",
        "adj_matrix2 = torch.tensor([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
        "\n",
        "# Create the GraphData objects for each graph\n",
        "graph1 = data.Data(x=torch.randn(4, 3), edge_index=adj_matrix1.nonzero().t())\n",
        "graph2 = data.Data(x=torch.randn(3, 3), edge_index=adj_matrix2.nonzero().t())\n",
        "\n",
        "# Create a list of the graphs\n",
        "graph_list = [graph1, graph2]\n",
        "\n",
        "# Create the DataLoader with batch size 2\n",
        "batch_size = 2\n",
        "dataloader = DataLoader(graph_list, batch_size=batch_size)\n",
        "\n",
        "# Iterate over the DataLoader\n",
        "for batch in dataloader:\n",
        "    # Unpack the batch into individual graphs\n",
        "    graphs = batch.to_data_list()\n",
        "    print(batch)\n",
        "    print(batch.x)\n",
        "    batch.x = torch.zeros_like(batch.x, device=DEVICE)\n",
        "    for g in batch.to_data_list():\n",
        "      print(g.x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJD24ijLswiu"
      },
      "outputs": [],
      "source": [
        "samples = sample_base_model(model_base, 0, model_guide=None, num=NUM_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irKpz9IIs0xb"
      },
      "outputs": [],
      "source": [
        "samples\n",
        "generated_samples_nx = [pyg_to_sparsebinary_nx(g) for g in samples]\n",
        "graph_gen_loss = compute_generation_loss(generated_samples_nx, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvzA0zejtMLy"
      },
      "outputs": [],
      "source": [
        "#g = generated_samples_nx[0]\n",
        "dlist = list()\n",
        "for g in generated_samples_nx:\n",
        "  for v_i in g.nodes():\n",
        "    dlist.append(g.degree(v_i))\n",
        "print(dlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMJa5xi3_Nyo"
      },
      "outputs": [],
      "source": [
        "#!rm *cassandra*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXprq5xuhzsI"
      },
      "outputs": [],
      "source": [
        "#ä!rm generated_samples_001.pickle generated_samples_002.pickle generated_samples_003.pickle generated_samples_004.pickle generated_samples_005.pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QB8C63TdYwO"
      },
      "source": [
        "# Putting Things Together III - Oracle Guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4zr1nyRmF0c"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "class PNAoracle(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAoracle, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 3\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9kiTfBAlDwb"
      },
      "outputs": [],
      "source": [
        "def test_oracle(model_oracle, g, t, return_float=False):\n",
        "  if model_oracle is None:\n",
        "    # here we also return float\n",
        "    return 0.0\n",
        "\n",
        "  future_t = torch.tensor(t).repeat(g.x.shape[0])\n",
        "  x_in = torch.concat((g.x.reshape(-1,2), future_t.reshape(-1,1)), dim=1)\n",
        "\n",
        "  # prediction\n",
        "  prediction = model_oracle(x_in, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "  if return_float:\n",
        "    return prediction.item()\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpu-_HU7gvol"
      },
      "outputs": [],
      "source": [
        "def forward_diffusion_until(g, t, schedule):\n",
        "  g = g.clone()\n",
        "\n",
        "  future_t = torch.tensor([int(t)]).repeat(g.x.shape[0])\n",
        "  assert(future_t.numel() == g.x.shape[0])\n",
        "\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1]\n",
        "  edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "  g.x[edge_indices,1] = edges_with_noise\n",
        "  return g\n",
        "\n",
        "@torch.inference_mode()\n",
        "def graph_inference_until(g, model, compare_times, schedule, oracle_old=None, choice_num=2):\n",
        "  g = g.clone().to(DEVICE)\n",
        "  compare_times = list(compare_times)\n",
        "  assert(\"int\" in str(type(compare_times[0])))\n",
        "\n",
        "  generated_graphs = list()\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1]\n",
        "  edges_without_noise = edge_weights[edge_indices]\n",
        "  edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "  g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "  for i in range(TIMESTEPS):\n",
        "    t = TIMESTEPS - i - 1\n",
        "    if len(compare_times) == 0:\n",
        "      break\n",
        "    if t == compare_times[-1]:\n",
        "      compare_times.pop()\n",
        "      generated_graphs.append((g, t)) # clone necessary?\n",
        "\n",
        "    choice_list = list()\n",
        "    if oracle_old is None:\n",
        "      choice_num = 1\n",
        "    for j in range(choice_num):\n",
        "      g_alt = g.clone()\n",
        "      edges_with_noise = denoise_one_step(model, g_alt, i, schedule)\n",
        "      g_alt.x[edge_indices,1] = edges_with_noise\n",
        "      choice_list.append(g_alt)\n",
        "    scores = [test_oracle(oracle_old, g, t, return_float=True) for g in choice_list]\n",
        "    g = choice_list[np.argmax(scores)]\n",
        "\n",
        "  return generated_graphs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEHhF2iSgD5a"
      },
      "outputs": [],
      "source": [
        "def train_epoch_oracle(dataloader, model_oracle, model_base, oracle_old, optimizer_oracle, schedule, epoch_i):\n",
        "  # 1 is real, 0 is fake\n",
        "  model_oracle.train()\n",
        "  if oracle_old is not None:\n",
        "    oracle_old.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  comparisons_per_graph = 10\n",
        "\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    optimizer_oracle.zero_grad()\n",
        "    compare_times = torch.randint(0, TIMESTEPS, (comparisons_per_graph,), device = DEVICE) #t=0 is original image\n",
        "    compare_times = sorted(compare_times.tolist())\n",
        "\n",
        "    g_fake_list = graph_inference_until(g, model_base, compare_times, schedule, oracle_old)\n",
        "    for i, (g_fake, t) in enumerate(g_fake_list):\n",
        "      g_fake = g_fake.clone()  #this is somehow necessary\n",
        "      #t = compare_times[i]\n",
        "      g_real = forward_diffusion_until(g, t, schedule)\n",
        "      loss = (test_oracle(model_oracle, g_fake, t) - 0.0)**2\n",
        "      loss = loss + (test_oracle(model_oracle, g_real, t) - 1.0)**2\n",
        "      loss.backward()\n",
        "      optimizer_oracle.step()\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), time.time() - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2Www9EjfaZN"
      },
      "outputs": [],
      "source": [
        "def train_oracle_model(dataloader_base, model_base, round_i, oracle_old=None):\n",
        "  model_oracle = PNAoracle(dataloader_base)\n",
        "\n",
        "  weight_path = f\"oracle_model_{round_i:03}.pth\"\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_oracle.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found oracle model in round {round_i:04}\")\n",
        "    return model_oracle\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  model_oracle.to(DEVICE)\n",
        "  optimizer_oracle = Adam(model_oracle.parameters(), lr = 0.0001)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "\n",
        "  for epoch_i in range(EPOCHS_GUIDE_MODEL):\n",
        "    loss, t = train_epoch_oracle(dataloader_base, model_oracle, model_base, oracle_old, optimizer_oracle, schedule=betas, epoch_i=epoch_i)\n",
        "    print(f\"train oracle: epoch: {epoch_i:05}, loss: {loss:02.4f}, time: {t:02.3f}\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_oracle.state_dict()}, weight_path)\n",
        "  return model_oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEeM26UqjO4e"
      },
      "outputs": [],
      "source": [
        "def get_last(elem_list):\n",
        "  return None if len(elem_list) == 0 else elem_list[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU8Og9XIda_P"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_base, dataset_test = build_dataset()\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "print(\"finished training base model\")\n",
        "#generate_examples(model_base, BASE_MODEL_EPOCHS+1, generate_schedule()[0], dataset_base, num_times=30)\n",
        "\n",
        "\n",
        "model_oracle_old = list()\n",
        "\n",
        "\n",
        "for round_i in range(NUM_ROUNDS):\n",
        "  model_base.eval()\n",
        "  samples = sample_base_model(model_base, round_i, model_guide=model_oracle_old, num=len(dataset_base))\n",
        "  #plot_samples(dataloader_base.dataset, model_disc, round_i)\n",
        "  model_oracle = train_oracle_model(dataloader_base, model_base, round_i, oracle_old=model_oracle_old)\n",
        "  model_oracle.eval()\n",
        "  model_oracle_old = model_oracle\n",
        "\n",
        "samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_oracle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmAvO2-kuzWC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1d7uhXgyzzsVVb0WVyh7vHRMFHIymHs8f",
      "authorship_tag": "ABX9TyOS2ReOsk3eRIsWGV+w4BPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}