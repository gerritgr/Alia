{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/Alia/blob/main/AliaMolecule_Adversarially_Guided_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VWSEj4zWH9P"
      },
      "source": [
        "# AliaMolecule - Adversarially Guided Probabilistic Diffusion\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFu0doC8D-UW"
      },
      "source": [
        "## Todo\n",
        "- DEVICE\n",
        "- positional encoding\n",
        "- resnet units\n",
        "- save loss list\n",
        "- cosine schedule\n",
        "- predict endpoint and not noise\n",
        "- why is batch wrong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAao3t3nPHHQ"
      },
      "source": [
        "Molecules:\n",
        "- remove hydrogen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqaO-iDsNHDS"
      },
      "source": [
        "- $t=0$ is original image.  => ($i=999$)\n",
        "- $t=1$ means one noise addition was made.  => ($i=T-t=999-t$)\n",
        "- $t=T=999$ is maximal addition. => ($i=0$)\n",
        "- $T = TIMESTEPS-1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmgsr5qYDymy"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yGSIj3enuyM6"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"AliaMolecule\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qfPpruBP7wod"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  os.system(\"pip install torch_geometric\")\n",
        "  # Optional dependencies:\n",
        "  os.system(\"pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\")\n",
        "  os.system(\"pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu102.html --force-reinstall\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2nNF8e3Hgiej"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  os.system(\"pip install rdkit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-leX8Lpch0-s"
      },
      "outputs": [],
      "source": [
        "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu102.html --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E7HLKq3WKG_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85984a87-726c-4e35-e4b5-9ac6c745d804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if USE_COLAB and not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM0dnwkxLhm_",
        "outputId": "9015c0d2-12c4-4da8-d4c2-769411cc769b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/AliaMolecule\n"
          ]
        }
      ],
      "source": [
        "if USE_COLAB:\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCUaC9ZqwH9E"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/gerritgr/Alia.git"
      ],
      "metadata": {
        "id": "L-UoRWI8IKHH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wtZm7FbVwJGx"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"Alia\"):\n",
        "  os.system(\"git clone https://github.com/gerritgr/Alia.git\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIZNe0X4Z-f7"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xQTCAyyHjLjW"
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
        "from PIL import Image # We use PIL to load images\n",
        "import seaborn as sns\n",
        "import imageio # to generate .gifs\n",
        "import networkx as nx\n",
        "\n",
        "# always good to have\n",
        "import glob, random, os, traceback, time, copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Linear as Lin\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_4brRkfG9Za"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX33f9FYG9gL",
        "outputId": "55f6fee8-c0c4-4da2-f5cb-6e1633bab9b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Mol Gen\n",
        "NUM_SAMPLES = 500 # how many samples to generate for the trainings set\n",
        "NUM_GRAPHS_TO_GENERATE = 10 # during inference\n",
        "TRAIN_TEST_SPLIT = 0.8\n",
        "\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5 # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False]*5 + [True] * 5\n",
        "NON_EDGES = [True] + [True]*5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1\n",
        "\n",
        "\n",
        "\n",
        "# General\n",
        "EPOCHS = 1500\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_ROUNDS = 2\n",
        "BASE_MODEL_EPOCHS = 20000\n",
        "EPOCHS_DISC_MODEL = 101\n",
        "EPOCHS_GUIDE_MODEL = 201\n",
        "GUIDE_FRACTION = 20   # only apply guidacne in the last 1/4 of the process\n",
        "\n",
        "\n",
        "# Diffusion\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#DEVICE = torch.device('cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkf85cyRvGiT"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "eSYvg6xIw-vV"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, loss_list, epoch_i):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"aliamol_model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "\n",
        "def load_latest_checkpoint(model, optimizer, loss_list, epoch_i):\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(\"aliamol_model_epoch_*.pth\"))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    loss_list = checkpoint['loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, loss_list, epoch_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZSk-qMNvj6Q"
      },
      "source": [
        "## Build Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "d8D6H1LGMp15"
      },
      "outputs": [],
      "source": [
        "# each node represents atom or bond\n",
        "# thus, each row of data.x has the form TAAAAABBBBB\n",
        "# T is 1 (atom) or -1 (bond). AAAAA is one-hot encoding of element (the five in qm9);\n",
        "# BBBBB is one hot encoding of bond type, single, double, triple, ring,\n",
        "# if a node is an atom then BBBBB is all -1, if it is a bond AAAAA is all -1\n",
        "# The diffusion only happens on either AAAAA or BBBBB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "gq5S0kudvD8T"
      },
      "outputs": [],
      "source": [
        "def build_dataset(seed=1234):\n",
        "  from Alia.smiles_to_pyg.molecule_load_and_convert import read_qm9\n",
        "  dataset = read_qm9()\n",
        "  dataset = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset)*TRAIN_TEST_SPLIT + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0,:].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  return dataset_train, dataset_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxwETR7mPq1b"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6K-jxdBPt5Z"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Ybvf4HoWPtH2"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "    \"\"\"\n",
        "    Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "    Args:\n",
        "    start (float): The starting value for the beta values. Default is START.\n",
        "    end (float): The ending value for the beta values. Default is END.\n",
        "    timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "    cumulative alpha values (alpha bars).\n",
        "    \"\"\"\n",
        "    betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "    #alphas = 1.0 - betas\n",
        "    #alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "    assert(betas.numel() == TIMESTEPS)\n",
        "    return betas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCrL8EfP2tM"
      },
      "source": [
        "## Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zpJn8TzvD-5",
        "outputId": "0b9a8b95-0e1b-4435-c35b-d544a391a826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([[ 1.0026],\n",
              "          [ 2.0045],\n",
              "          [-0.2055]], device='cuda:0'),\n",
              "  tensor([[ 0.2608],\n",
              "          [ 0.4637],\n",
              "          [-0.2731]], device='cuda:0')),\n",
              " None,\n",
              " (tensor([[-0.6931],\n",
              "          [ 1.7434],\n",
              "          [ 2.0490]], device='cuda:0'),\n",
              "  tensor([[-0.7158],\n",
              "          [ 1.6988],\n",
              "          [ 1.9820]], device='cuda:0')))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # column-wise multiplication, now matrix\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) #this is a col vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) #this is a matrix\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXDf7AsfW_PE"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QScWK9RzI0c"
      },
      "source": [
        "### Model Spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "l1VOml_vvEBQ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM+ TIME_FEATURE_DIM #INDICATOR_FEATURE_DIM entries are noise free\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    t = t.view(-1,TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "\n",
        "    #node_indicator = x_in[:,0] > 0\n",
        "    #node_indicator = x_in[:,0] < 0\n",
        "    #x[node_indicator, NON_NODES] = x_in[node_indicator, NON_NODES]\n",
        "    #x[edge_indicator, NON_EDGES] = x_in[edge_indicator, NON_EDGES]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SKlGT9rzFXU"
      },
      "source": [
        "### Train Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "AfRQ1DBvvEIT"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer):\n",
        "  \"\"\"\n",
        "  Trains a denoising model for one epoch using a given data loader and optimization algorithm.\n",
        "\n",
        "  Args:\n",
        "  model: The denoising model.\n",
        "  dataloader: The data loader for the training data.\n",
        "  optimizer: The torch optimizer.\n",
        "\n",
        "  Returns:\n",
        "  float: The average loss for the epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "\n",
        "  for g in tqdm(dataloader): #todo batches deactivated\n",
        "    if g.x.shape[0] < 2:\n",
        "      continue\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    g.to(DEVICE)\n",
        "    #num_graphs_in_batch = 1\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    #future_t = torch.tensor([0]*g.x.shape[0], device=DEVICE)#\n",
        "    future_t = torch.gather(future_t_select, 0, g.batch)\n",
        "    assert(future_t.numel() == g.x.shape[0])\n",
        "\n",
        "    mask = torch.concat((torch.tensor([False]*g.x.shape[0], device=DEVICE).view(-1,1), g.x[:,1:]>-0.5), dim=1) #this only works on original values\n",
        "    x = g.x[mask].view(g.x.shape[0], FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x, future_t)\n",
        "\n",
        "    x_in = g.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    noise_pred = model(x_in, future_t, g.edge_index)\n",
        "\n",
        "    loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return float(np.mean(loss_list)), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "G_ryCoO5wOoG"
      },
      "outputs": [],
      "source": [
        "def train_epoch_test():\n",
        "  dataset_train, dataset_test = build_dataset()\n",
        "  data = dataset_train[0]\n",
        "  model_base = PNAnet(dataset_train[:20]).to(DEVICE) #20 should be enough to estimate statistics\n",
        "\n",
        "  t = torch.tensor([1.0]).repeat(data.x.shape[0])\n",
        "  t = t.to(DEVICE)\n",
        "  model_base(data.x, t, data.edge_index)\n",
        "  dataloader = DataLoader(dataset_train[:20], batch_size=1, shuffle=True)\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "  return train_epoch(model_base, dataloader, optimizer)\n",
        "\n",
        "#train_epoch_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV_QpxiPwpY1"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "BtCkdi6M77nG"
      },
      "outputs": [],
      "source": [
        "def plot_list(xy_data, filename, title=\"\", xlabel=\"\", ylabel=\"\"):\n",
        "  plt.clf()\n",
        "  plt.plot([x for x, y in xy_data], [y for x, y in xy_data])\n",
        "  plt.title(title)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.savefig(filename)\n",
        "\n",
        "  with open(filename+\".pickle\", 'wb') as f:\n",
        "    pickle.dump(xy_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "R6N8YD6rvERr"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=None):\n",
        "  print(\"train base model\")\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "\n",
        "  lr = LEARNING_RATE\n",
        "  lr = lr/100.0 #todo fix in hyperparams\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE)\n",
        "  loss_list = list()\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_num = epoch_num if epoch_num is not None else EPOCHS\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "  print(\"from\", epoch_start, \"to\", epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    try:\n",
        "      loss, time_elapsed = train_epoch(model_base, train_loader, optimizer)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      if epoch_i % 1 == 0 or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        plot_list(loss_list, \"train_base.png\", title=\"train loss base model\", xlabel='epoch', ylabel='loss')\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {np.mean([y for x,y in loss_list] + [loss]):05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "\n",
        "      if (epoch_i % 10 == 0 and epoch_i >= 30) or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "        #graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "        #print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "        #plot_base(graph_loss_list, loss_list)\n",
        "        save_model(model_base, optimizer, loss_list, epoch_i+1) #todo really +1?\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "dO7VLZT5vEUD"
      },
      "outputs": [],
      "source": [
        "def train_base_model_test():\n",
        "  dataset_train, dataset_test = build_dataset()\n",
        "  dataloader = DataLoader(dataset_train[:20], batch_size=1, shuffle=True)\n",
        "\n",
        "  train_base_model(dataloader, epoch_num=30)\n",
        "#train_base_model_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlxLHZN16p_C"
      },
      "source": [
        "## Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVvB3KCd6f7f"
      },
      "outputs": [],
      "source": [
        "dataset_base, dataset_base_test = build_dataset()\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "#model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "model_cassandra = None\n",
        "# TODO test set train\n",
        "\n",
        "\n",
        "model_base = train_base_model(dataloader_base, epoch_num=2000)\n",
        "print(\"now change batch size to 1\")\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS *= 2\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "model_base = train_base_model(dataloader_base, epoch_num=2*2000)\n",
        "\n",
        "  #samples = sample_base_model(model_base, round_i, model_guide=model_cassandra, num=NUM_SAMPLES)  #TODO\n",
        "  #plot_samples(samples, model_disc=None, round_i=round_i)\n",
        "  #dataloader_disc = get_merged_dataloader(samples[:num_samples_train], dataset_base)\n",
        "  #dataloader_disc_test = get_merged_dataloader(samples[num_samples_train:], dataset_base_test)\n",
        "  #model_cassandra = train_cassandra_model(dataloader_disc, dataloader_disc_test, round_i)\n",
        "  #new_epoch_num = BASE_MODEL_EPOCHS + (round_i+1)*int(BASE_MODEL_EPOCHS*0.2)\n",
        "  #model_base = train_base_model(dataloader_base, epoch_num = new_epoch_num)\n",
        "\n",
        "#samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_cassandra, num=NUM_SAMPLES)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "5yW-RNpkJj8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_one_step(model, g, i):\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "  #print(\"in\", future_t.shape, g.x.shape)\n",
        "  noise_pred = model(g.x, future_t, g.edge_index)\n",
        "  values_now = g.x[mask]\n",
        "  values_endpoint = noise_pred.flatten() #[mask] network only prdicts noise\n",
        "  #print(values_now.shape, values_endpoint.shape)\n",
        "  assert(values_now.shape == values_endpoint.shape)\n",
        "\n",
        "  # now compute values_one_step_denoised\n",
        "  model_mean = sqrt_recip_alphas_t * (values_now - beta_t * values_endpoint / sqrt_one_minus_alphas_cumprod_t)\n",
        "  values_one_step_denoised = model_mean # if t == 0\n",
        "  if t != 0:\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # in the paper this is in 3.2. note that sigma^2 is variance, not std\n",
        "    posterior_std_t = torch.sqrt(posterior_variance[t])\n",
        "    noise = torch.randn_like(values_now, device = DEVICE)\n",
        "    values_one_step_denoised = model_mean + posterior_std_t * noise\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  denoised_x[mask] = values_one_step_denoised\n",
        "  return denoised_x\n",
        ""
      ],
      "metadata": {
        "id": "oax8YVw-JjM6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overwrite_with_noise(g):\n",
        "  g.x_old = g.x.clone()\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  g.x[mask] = torch.randn_like(g.x[mask])\n",
        "  return g\n",
        ""
      ],
      "metadata": {
        "id": "QMBWKmq9JjY6"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples(model, dataset_train, num=100):\n",
        "  # Setup\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "    g = dataset_train_start[-1]\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "\n",
        "  # Inference\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    g = overwrite_with_noise(g)\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      x_with_less_noise = denoise_one_step(model, g, i)\n",
        "      g.x = x_with_less_noise\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "\n",
        "    print(\"generated graphs \", graph_list)\n",
        "    return graph_list\n"
      ],
      "metadata": {
        "id": "W8tPL8o0Jjbe"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphs = generate_examples(model_base, dataset_base, num=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4_7XLdDJq1b",
        "outputId": "c2bd9e22-535b-4144-cd94-4bf046f5c4a6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 13548], x=[4259, 11], batch=[4259], ptr=[101]) tensor([ 0,  0,  0,  ..., 99, 99, 99], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:09<00:00, 106.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphs[6]\n",
        "g.x\n",
        "\n",
        "from Alia.smiles_to_pyg.molecule_load_and_convert import *\n",
        "\n",
        "g_nx = pyg_to_reduced_nx(g)\n",
        "print(g_nx, g_nx.nodes(data=True), '\\n',g_nx.edges(data=True))\n",
        "draw_nx_graph(g_nx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "iecwynIDKlW9",
        "outputId": "60a270c4-ce32-464a-a942-632db4a08734"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 9 nodes and 8 edges [(0, {'elem': 2}), (1, {'elem': 0}), (2, {'elem': 3}), (3, {'elem': 2}), (4, {'elem': 0}), (5, {'elem': 0}), (6, {'elem': 0}), (7, {'elem': 0}), (8, {'elem': 0})] \n",
            " [(0, 5, {'bond_type': 3}), (1, 2, {'bond_type': 2}), (1, 6, {'bond_type': 1}), (3, 6, {'bond_type': 1}), (4, 7, {'bond_type': 1}), (4, 8, {'bond_type': 1}), (5, 6, {'bond_type': 1}), (6, 8, {'bond_type': 1})]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "smiles_list = list()\n",
        "for g in graphs:\n",
        "  smiles = pyg_to_smiles(g)\n",
        "  if smiles is not None:\n",
        "    correct += 1\n",
        "    smiles_list.append(smiles)\n",
        "\n",
        "correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8Zm6-oiLkCe",
        "outputId": "5ad4f29e-9993-4e67-a2c8-8f7ef3be7fbe"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:13] Explicit valence for atom # 4 O, 3, is greater than permitted\n",
            "[13:01:13] non-ring atom 0 marked aromatic\n",
            "[13:01:13] Explicit valence for atom # 6 O, 3, is greater than permitted\n",
            "[13:01:13] Explicit valence for atom # 5 O, 3, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:13] Explicit valence for atom # 4 O, 3, is greater than permitted\n",
            "[13:01:13] non-ring atom 4 marked aromatic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:13] non-ring atom 0 marked aromatic\n",
            "[13:01:13] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
            "[13:01:13] Explicit valence for atom # 3 C, 5, is greater than permitted\n",
            "[13:01:13] Explicit valence for atom # 2 C, 5, is greater than permitted\n",
            "[13:01:13] Explicit valence for atom # 1 O, 3, is greater than permitted\n",
            "[13:01:13] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:13] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
            "[13:01:14] Can't kekulize mol.  Unkekulized atoms: 6\n",
            "[13:01:14] Can't kekulize mol.  Unkekulized atoms: 1 3\n",
            "[13:01:14] non-ring atom 0 marked aromatic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:14] Can't kekulize mol.  Unkekulized atoms: 2\n",
            "[13:01:14] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
            "[13:01:14] Explicit valence for atom # 6 O, 3, is greater than permitted\n",
            "[13:01:14] Explicit valence for atom # 5 C, 6, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:14] non-ring atom 1 marked aromatic\n",
            "[13:01:14] Explicit valence for atom # 5 O, 4, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:14] Explicit valence for atom # 3 F, 3, is greater than permitted\n",
            "[13:01:14] Explicit valence for atom # 1 O, 3, is greater than permitted\n",
            "[13:01:14] Explicit valence for atom # 2 C, 5, is greater than permitted\n",
            "[13:01:14] non-ring atom 0 marked aromatic\n",
            "[13:01:14] non-ring atom 0 marked aromatic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:14] Explicit valence for atom # 1 C, 6, is greater than permitted\n",
            "[13:01:14] Explicit valence for atom # 1 O, 3, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:15] non-ring atom 4 marked aromatic\n",
            "[13:01:15] non-ring atom 0 marked aromatic\n",
            "[13:01:15] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
            "[13:01:15] Explicit valence for atom # 7 N, 4, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:15] Can't kekulize mol.  Unkekulized atoms: 0 1 2 3 4\n",
            "[13:01:15] Explicit valence for atom # 4 O, 4, is greater than permitted\n",
            "[13:01:15] Can't kekulize mol.  Unkekulized atoms: 5\n",
            "[13:01:15] non-ring atom 3 marked aromatic\n",
            "[13:01:15] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
            "[13:01:15] non-ring atom 2 marked aromatic\n",
            "[13:01:15] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
            "[13:01:15] Explicit valence for atom # 2 O, 3, is greater than permitted\n",
            "[13:01:15] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n",
            "An error occurred: SMILES string could not be converted to a molecule.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[13:01:15] Can't kekulize mol.  Unkekulized atoms: 2 4 6\n",
            "[13:01:15] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N94nsT8wLn6w",
        "outputId": "9ce0d2cb-8907-4210-ebf5-eedee0650023"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CC1C2C=CC1OCC2',\n",
              " 'CC1C2N3C4C5C24CC153',\n",
              " 'CCN1C(C)C2OCC21',\n",
              " 'CCCC(CC)COF',\n",
              " 'COCC(C)CCCO',\n",
              " 'CCC.CCC(C)CC',\n",
              " 'CC(C)C(C)C(N)O.O',\n",
              " 'OC12CCCCC(C1)N2',\n",
              " 'CCCC1(CO)C=CC1',\n",
              " 'CCC=CC1CC1C.O',\n",
              " 'CCC1CC(N)C1C=O',\n",
              " 'CC1=CC2C(C)=C2NC1',\n",
              " 'CC1CC2CCCC2O1',\n",
              " 'CC.CC1=CC2=C=C21',\n",
              " 'CCCC.CN',\n",
              " 'COC(C=O)CC(C)C',\n",
              " 'CC12CCC3CC1CC32',\n",
              " 'CC12CNC13C1CC13C2',\n",
              " 'CC(C)C1OC2CC=C21',\n",
              " 'CNC1CC2(N)NC12',\n",
              " 'CCC.CN.O=c1c#c1',\n",
              " 'CC1=CCCN1C#CO',\n",
              " 'C.CCC(C)CO.N',\n",
              " 'COCC1CCC2C=C21',\n",
              " 'CC1CC12CC1CC12C',\n",
              " 'CCCCCC(C)CC',\n",
              " 'CC.CC1OC(N)C1C',\n",
              " 'CCOOC1=CC(C)C1',\n",
              " 'CC1C(=O)CC1O.O',\n",
              " 'C1CC23CCC1C2NC3',\n",
              " 'CCC1(C)CC(N)C1=O',\n",
              " 'C=C(CC)CO.N',\n",
              " 'C=C(CO)CCC.CO',\n",
              " 'CCC.CCCN(C)N',\n",
              " 'CCC(OC)C(O)CO',\n",
              " 'CC1CC2C3NC=CC123',\n",
              " 'CCC1(C(C)C)CC1',\n",
              " 'OCCC=CC1CCN1',\n",
              " 'CC(C)C12CCC1CC2',\n",
              " 'C=O.CNC1(C)CN1',\n",
              " 'CC1(O)C2C=CCC21.O',\n",
              " 'C.C#CC1NC1C(C)C',\n",
              " 'C=CCC(C)O.COC',\n",
              " 'COC1CC2(CCC2)C1',\n",
              " 'C#C.CCN1CNC1',\n",
              " 'C1CC2(N1)NO2.N.O',\n",
              " 'CCC1=CCC(C)C1',\n",
              " 'CC(O)C1N=CCCN1',\n",
              " 'C1CNC1.CC=N.N',\n",
              " 'CC.CC(C)C',\n",
              " 'CC1C2CC2OC1(C)C',\n",
              " 'C1CC23CC1CC2C3',\n",
              " 'CC(N)O.NC1CC1',\n",
              " 'OCCC1CN=COC1',\n",
              " 'CO.OCOCC1=CO1',\n",
              " 'CCNC1NCCC1C']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLUFMZn2Juma"
      },
      "outputs": [],
      "source": [
        "z = z/0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkiNNy7W6f-V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC16z0va6gAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PJNvLD86gC-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXbodabU6gFl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQVPgLM5vEYb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nSj0xibvEh1"
      },
      "source": [
        "# Old"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxPXpSLLaAdP"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BouSF2CGWIFI"
      },
      "outputs": [],
      "source": [
        "G = nx.star_graph(10)\n",
        "\n",
        "nx.draw(G, with_labels=True, node_color='lightblue', node_size=800, font_weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8mltcfQ1oyq"
      },
      "outputs": [],
      "source": [
        "def get_weights(g):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1]\n",
        "  return edge_weights[edge_indices]\n",
        "\n",
        "def set_weights(g, w):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  g.x[edge_indices,1] = w\n",
        "  return g\n",
        "\n",
        "def get_edge_index(g):\n",
        "  return g.x[:,0] < 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYttUAarWIbf"
      },
      "outputs": [],
      "source": [
        "def transform_graph(graph, make_complete=False):\n",
        "  # create graph where each edge becomes a node with weight 1\n",
        "  # if make_complete, each non-egde becomes node with weight -1\n",
        "\n",
        "  graph = nx.convert_node_labels_to_integers(graph, ordering=\"sorted\")\n",
        "\n",
        "  transformed_graph = nx.Graph()\n",
        "\n",
        "  for u, v in graph.edges():\n",
        "    new_node = (u+v)*1000000+100*(min(u,v)+1)+10000000000*max(u,v)\n",
        "    transformed_graph.add_edge(u, new_node)\n",
        "    transformed_graph.add_edge(new_node, v)\n",
        "    transformed_graph.nodes[u]['is_real'] = 1\n",
        "    transformed_graph.nodes[v]['is_real'] = 1\n",
        "    transformed_graph.nodes[new_node]['is_real'] = 0\n",
        "    transformed_graph.nodes[u]['weight'] = 0.0\n",
        "    transformed_graph.nodes[v]['weight'] = 0.0\n",
        "    transformed_graph.nodes[new_node]['weight'] = EDGE_INDICATOR\n",
        "\n",
        "\n",
        "  if make_complete:\n",
        "    for u in graph.nodes():\n",
        "      for v in graph.nodes():\n",
        "        if u > v and not graph.has_edge(u, v) and not graph.has_edge(v, u):\n",
        "          new_node = (u+v)*1000000+100*(min(u,v)+1)+10000000000*max(u,v)+10\n",
        "          transformed_graph.add_edge(u, new_node)\n",
        "          transformed_graph.add_edge(new_node, v)\n",
        "          transformed_graph.nodes[u]['is_real'] = 1\n",
        "          transformed_graph.nodes[v]['is_real'] = 1\n",
        "          transformed_graph.nodes[new_node]['is_real'] = 0\n",
        "          transformed_graph.nodes[new_node]['weight'] = NO_EDGE_INDICATOR\n",
        "\n",
        "  transformed_graph = nx.convert_node_labels_to_integers(transformed_graph, ordering=\"sorted\")\n",
        "  return transformed_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdUpdWYpM99N"
      },
      "outputs": [],
      "source": [
        "def transform_to_complete_graph(graph):\n",
        "  global EDGE_INDEX_STORAGE\n",
        "  # create graph where each edge becomes a node with weight 1\n",
        "  # if make_complete, each non-egde becomes node with weight -1\n",
        "\n",
        "  graph_node_num = graph.number_of_nodes()\n",
        "  number_nodes_in_transformed_graph = graph_node_num*(graph_node_num+1)/2 #+ graph_node_num\n",
        "  graph = nx.convert_node_labels_to_integers(graph, ordering=\"sorted\")\n",
        "\n",
        "  transformed_graph = nx.Graph()\n",
        "  nodes = range(graph_node_num)\n",
        "\n",
        "  for u in nodes:\n",
        "    for v in nodes:\n",
        "      if u>=v:\n",
        "        continue\n",
        "      new_node = (u+v+1)*1000000+100*(min(u,v)+1)+10000000000*max(u,v)+10+u+20*(v+1)\n",
        "      transformed_graph.add_edge(u, new_node)\n",
        "      transformed_graph.add_edge(new_node, v)\n",
        "      transformed_graph.nodes[u]['is_real'] = 1\n",
        "      transformed_graph.nodes[v]['is_real'] = 1\n",
        "      transformed_graph.nodes[new_node]['is_real'] = 0\n",
        "\n",
        "      transformed_graph.nodes[u]['weight'] = 0.0\n",
        "      transformed_graph.nodes[v]['weight'] = 0.0\n",
        "      if graph.has_edge(u, v) or graph.has_edge(v, u):\n",
        "        transformed_graph.nodes[new_node]['weight'] = EDGE_INDICATOR\n",
        "      else:\n",
        "        transformed_graph.nodes[new_node]['weight'] = NO_EDGE_INDICATOR\n",
        "\n",
        "  transformed_graph = nx.convert_node_labels_to_integers(transformed_graph, ordering=\"sorted\")\n",
        "  assert(number_nodes_in_transformed_graph == transformed_graph.number_of_nodes())\n",
        "  return transformed_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAoIITTOWhCp"
      },
      "outputs": [],
      "source": [
        "# Transform the graph\n",
        "transformed_G = transform_graph(G)\n",
        "\n",
        "# Visualize the transformed graph\n",
        "node_color = ['lightblue' if transformed_G.nodes[node]['is_real'] == 1 else 'gray' for node in transformed_G.nodes()]\n",
        "\n",
        "nx.draw(transformed_G, with_labels=True, node_size=800, font_weight='bold', node_color=node_color)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10mP4uXrWkU3"
      },
      "outputs": [],
      "source": [
        "G = nx.star_graph(3)\n",
        "\n",
        "\n",
        "# Transform the graph\n",
        "transformed_G  = transform_graph(G, make_complete=True)\n",
        "#transformed_G  = transform_to_complete_graph(G)\n",
        "\n",
        "# Visualize the transformed graph\n",
        "def get_node_color(g, v):\n",
        "  if g.nodes[v]['is_real'] == 1:\n",
        "    return \"lightblue\"\n",
        "  if g.nodes[v]['weight'] > 0.5:\n",
        "    return \"gray\"\n",
        "  return \"lightgray\"\n",
        "\n",
        "node_color = [get_node_color(transformed_G, node) for node in transformed_G.nodes()]\n",
        "\n",
        "nx.draw(transformed_G, with_labels=True, node_size=800, font_weight='bold', node_color=node_color)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uoDR578Yg4N"
      },
      "outputs": [],
      "source": [
        "G = nx.star_graph(3)\n",
        "transformed_G  = transform_graph(G, make_complete=True)\n",
        "transformed_G2 = transform_to_complete_graph(G)\n",
        "\n",
        "for v_i in transformed_G.nodes:\n",
        "  print(transformed_G.nodes(data=True)[v_i])\n",
        "  print(transformed_G2.nodes(data=True)[v_i])\n",
        "  print(\" \")\n",
        "\n",
        "#transformed_G.nodes(data=True), transformed_G2.nodes(data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFpC_zhrqtxf"
      },
      "outputs": [],
      "source": [
        "transformed_G.nodes(data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apjut4wbVfge"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIEZLYgUDQg"
      },
      "outputs": [],
      "source": [
        "g = from_networkx(transformed_G, group_node_attrs=[\"is_real\", \"weight\"])\n",
        "g, g.x, g.edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGLwThw_EMzU"
      },
      "outputs": [],
      "source": [
        "class ShuffleList:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        random.shuffle(self.data)\n",
        "        self.index = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index < len(self.data):\n",
        "            value = self.data[self.index]\n",
        "            self.index += 1\n",
        "            return value\n",
        "        else:\n",
        "            raise StopIteration\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RsTVhBtFMfG"
      },
      "source": [
        "#### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C828QNI-FN0j"
      },
      "outputs": [],
      "source": [
        "def remove_edges(graph, threshold = 0.0):\n",
        "    # Create a deep copy of the graph\n",
        "    new_graph = copy.deepcopy(graph)\n",
        "\n",
        "    # List to store edges to be removed\n",
        "    edges_to_remove = []\n",
        "\n",
        "    # Find edges with weight < 0.5\n",
        "    for u, v, data in new_graph.edges(data=True):\n",
        "        if 'weight' in data and data['weight'] < threshold:\n",
        "            edges_to_remove.append((u, v))\n",
        "\n",
        "    # Remove edges\n",
        "    for edge in edges_to_remove:\n",
        "        new_graph.remove_edge(*edge)\n",
        "\n",
        "    return new_graph\n",
        "\n",
        "def reduce_nx_graph(g_old):\n",
        "  g_new = nx.Graph()\n",
        "  for v_i in g_old.nodes():\n",
        "    if g_old.nodes[v_i]['x'][0] > 0.1:\n",
        "      g_new.add_node(v_i)\n",
        "      g_new.nodes[v_i]['x'] = g_old.nodes[v_i]['x']\n",
        "\n",
        "  for v_i in g_old.nodes():\n",
        "    if g_old.nodes[v_i]['x'][0] < 0.1:\n",
        "      neigh_list = list(g_old.neighbors(v_i))\n",
        "      if len(neigh_list) != 2:\n",
        "        print(neigh_list)\n",
        "      assert(len(neigh_list) == 2)\n",
        "      g_new.add_edge(neigh_list[0], neigh_list[1], weight = g_old.nodes[v_i]['x'][1])\n",
        "  return g_new\n",
        "\n",
        "def pyg_graph_to_nx(g_pyg, edge_weights):\n",
        "  g_pyg = g_pyg.clone()\n",
        "\n",
        "  edge_indices = g_pyg.x[:,0] < 0.1\n",
        "  g_pyg.x[edge_indices,1] = edge_weights\n",
        "\n",
        "  g_nx = to_networkx(g_pyg, node_attrs=['x'], to_undirected=True)\n",
        "  g_nx = reduce_nx_graph(g_nx)\n",
        "  return g_nx\n",
        "\n",
        "def pyg_to_sparsebinary_nx(g_pyg):\n",
        "  edge_indices = g_pyg.x[:,0] < 0.1\n",
        "  edge_weights = g_pyg.x[edge_indices,1]\n",
        "\n",
        "  # Assuming pyg_graph_to_nx and remove_edges are defined or imported correctly in your script\n",
        "  g_nx = pyg_graph_to_nx(g_pyg, edge_weights)\n",
        "  g_nx = remove_edges(g_nx, threshold = 0.0)\n",
        "\n",
        "  for edge in g_nx.edges:\n",
        "    del g_nx.edges[edge]['weight']\n",
        "  return g_nx\n",
        "\n",
        "\n",
        "def plot_weighted_graph(edge_weights, g_pyg, ax, pos=None, binarize=False):\n",
        "  if edge_weights is None:\n",
        "    edge_indices = g_pyg.x[:,0] < 0.1\n",
        "    edge_weights = g_pyg.x[edge_indices,1]\n",
        "\n",
        "  g_nx = pyg_graph_to_nx(g_pyg, edge_weights)\n",
        "\n",
        "  edge_weights = nx.get_edge_attributes(g_nx, 'weight')\n",
        "  edge_weights = [edge_weights[e] for e in g_nx.edges]\n",
        "\n",
        "  if binarize:\n",
        "    edge_weights = [1.0 if w>0.0 else -1.0 for w in edge_weights]\n",
        "    edge_weights_for_mean = [max(w,0.) for w in edge_weights]\n",
        "    print(\"Mean degree:\", 2*np.sum(edge_weights_for_mean)/g_nx.number_of_nodes())\n",
        "\n",
        "  if pos is None:\n",
        "    g_nx_sparse = remove_edges(g_nx)\n",
        "    pos = nx.spring_layout(g_nx_sparse)\n",
        "  edge_colors = [max(w, -1.) for w in edge_weights]\n",
        "  edge_colors = [min(w, 1.) for w in edge_colors]\n",
        "  edge_colors = [w/2.0+0.5 for w in edge_colors]\n",
        "\n",
        "  for i, e in enumerate(g_nx.edges):\n",
        "    nx.draw(g_nx, pos, edge_color=\"black\", edgelist = [e], ax=ax, alpha=edge_colors[i], nodelist=list())\n",
        "\n",
        "  nx.draw(g_nx, pos,\n",
        "          node_color='red', with_labels=False, ax=ax, alpha=0.5, node_size=4, edgelist=list())\n",
        "\n",
        "  if binarize:\n",
        "    return pos, g_nx_sparse\n",
        "  return pos, g_nx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxLa9eUNYWCg"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_-L-Pc3Y1Zp"
      },
      "outputs": [],
      "source": [
        "def lift_nx_to_pyg(g):\n",
        "  g = from_networkx(g, group_node_attrs=[\"is_real\", \"weight\"])\n",
        "  return g\n",
        "\n",
        "EDGE_INDEX_STORAGE = dict()\n",
        "def lift_nx_to_complete_pyg(g):\n",
        "  global EDGE_INDEX_STORAGE\n",
        "  #g = transform_to_complete_graph(g)\n",
        "  g = transform_graph(g, make_complete=True)\n",
        "  g = lift_nx_to_pyg(g)\n",
        "  node_num_lifted = g.x.shape[0]\n",
        "  if node_num_lifted not in EDGE_INDEX_STORAGE:\n",
        "    EDGE_INDEX_STORAGE[node_num_lifted] = g.edge_index\n",
        "  #assert(torch.all(EDGE_INDEX_STORAGE[node_num_lifted] == g.edge_index))\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TUFSCq4Ye2y"
      },
      "outputs": [],
      "source": [
        "def build_dataset(num_nodes=NUM_NODES, num_samples=NUM_SAMPLES, degree=DEGREE, seed=1234):\n",
        "  global EDGE_INDEX_STORAGE\n",
        "\n",
        "  try:\n",
        "    with open(f\"dataset_{NUM_NODES:07}_{NUM_SAMPLES:07}_{DEGREE:03}.pickle\", \"rb\") as f:\n",
        "      tain_set, test_set = pickle.load(f)\n",
        "      print(f\"found dataset: dataset_{NUM_NODES:07}_{NUM_SAMPLES:07}_{DEGREE:03}.pickle\")\n",
        "      return tain_set, test_set\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "  dataset = list()\n",
        "\n",
        "  for _ in range(num_samples):\n",
        "    while True:\n",
        "      seed += 1\n",
        "      graph = nx.random_regular_graph(d=degree, n=num_nodes, seed=seed)\n",
        "      if nx.is_connected(graph):\n",
        "        dataset.append(lift_nx_to_complete_pyg(graph))\n",
        "        break\n",
        "\n",
        "  dataset_train = dataset[:int(len(dataset)*TRAIN_TEST_SPLIT)]\n",
        "  dataset_test = dataset[int(len(dataset)*TRAIN_TEST_SPLIT):]\n",
        "  dataset_train = ShuffleList(dataset_train)\n",
        "  dataset_test = ShuffleList(dataset_test)\n",
        "\n",
        "  with open(f\"dataset_{NUM_NODES:07}_{NUM_SAMPLES:07}_{DEGREE:03}.pickle\", \"wb\") as f:\n",
        "    pickle.dump((dataset_train, dataset_test), f)\n",
        "  return dataset_train, dataset_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LpCfVUcP7Rq"
      },
      "outputs": [],
      "source": [
        "#!rm dataset_*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU0cHznL2bjQ"
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test  = build_dataset()\n",
        "g1 = dataset_train[0]\n",
        "g2 = dataset_train[1]\n",
        "g3 = dataset_train[2]\n",
        "print(g1.edge_index)\n",
        "print(g2.edge_index)\n",
        "print(g3.edge_index)\n",
        "#torch.all(g1.edge_index == g2.edge_index) and torch.all(g2.edge_index == g3.edge_index)\n",
        "# For this line \"g1.edge_index == g2.edge_index and g2.edge_index == g3.edge_index\", I get the error \"Boolean value of Tensor with more than one value is ambiguous\". Fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNhDqcUcYfKV"
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test  = build_dataset()\n",
        "data = dataset_train[0]\n",
        "data, data.x\n",
        "#data.edge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE8eu8YHxYSb"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5gRUpdExZnl"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 3\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "    return x\n",
        "\n",
        "\n",
        "model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyUalHA2Ehyn"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wmE0o9liKb8"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "    \"\"\"\n",
        "    Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "    Args:\n",
        "    start (float): The starting value for the beta values. Default is START.\n",
        "    end (float): The ending value for the beta values. Default is END.\n",
        "    timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "    cumulative alpha values (alpha bars).\n",
        "    \"\"\"\n",
        "    betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "    alphas = 1.0 - betas\n",
        "    alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "    assert(betas.numel() == TIMESTEPS)\n",
        "    return betas, alphas, alpha_bars\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZkmSsNfE41g"
      },
      "outputs": [],
      "source": [
        "def compute_generation_loss(graphs, train_loader):\n",
        "  #graphs = [remove_edges(g) for g in graphs]\n",
        "  loss_list = list()\n",
        "  for graph in graphs:\n",
        "    degree_list = [graph.degree(i) for i in graph.nodes()]\n",
        "    mean_degree = np.mean(degree_list)\n",
        "    var_degree = np.var(degree_list)\n",
        "    loss = (3.0-mean_degree)**2 + var_degree\n",
        "    loss_list.append(loss)\n",
        "  return np.mean(loss_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3CMj8TyDOGV"
      },
      "source": [
        "### Load checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPWqWq5oE9n5"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, graph_loss_list, loss_list, epoch_i):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'graph_loss_list': graph_loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "\n",
        "def load_latest_checkpoint(model, optimizer, graph_loss_list, loss_list, epoch_i):\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(\"model_epoch_*.pth\"))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, graph_loss_list, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    graph_loss_list = checkpoint['graph_loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, graph_loss_list, loss_list, epoch_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFOtSm7-qwBg"
      },
      "outputs": [],
      "source": [
        "#!ls\n",
        "#!ls ../Toad_relaxed_large5/model_epoch_*\n",
        "#!cp ../Toad_relaxed_large5/model_epoch_00020000.pth model_epoch_00020000.pth\n",
        "#!ls model_epoch_00020000*\n",
        "#!ls\n",
        "#!cp model_epoch_00020000.pth ../Alia1/model_epoch_00020000.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHMwkfUXEk3G"
      },
      "source": [
        "### Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPtXnyVpElAc"
      },
      "outputs": [],
      "source": [
        "def forward_diffusion(input_vec, future_t, betas):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an input image tensor.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  assert(input_vec.shape == future_t.shape)\n",
        "  #future_t = torch.tensor([future_t], dtype=torch.int64)\n",
        "\n",
        "  noise = torch.randn_like(input_vec, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t)\n",
        "\n",
        "  img_mean = torch.sqrt(alphabar_t) * input_vec\n",
        "  img_std = torch.sqrt(1.-alphabar_t)\n",
        "  noise_img = img_mean + img_std * noise\n",
        "\n",
        "  return noise_img, noise\n",
        "\n",
        "betas, alphas, alpha_bars = generate_schedule()\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE), torch.tensor([0,0,0], device=DEVICE), betas), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE), torch.tensor([999,999,999], device=DEVICE), betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6sk4-QGJAUX"
      },
      "outputs": [],
      "source": [
        "betas, alphas, alpha_bars = generate_schedule()\n",
        "plt.clf()\n",
        "plt.plot(betas.cpu(), label=\"betas\", alpha=0.7)\n",
        "plt.plot(alphas.cpu(), label=\"alphas\", alpha=0.7, ls='--')\n",
        "plt.plot(torch.sqrt(alphas.cpu()), label=\"sqrt(alphas)\", alpha=0.7, ls=':')\n",
        "plt.plot(alpha_bars.cpu(), label=\"alpha_bars\", alpha=0.7)\n",
        "plt.plot((1-alphas.cpu())/(torch.sqrt(1-alpha_bars.cpu())), label=\"1-alpha/(sqrt...)\", alpha=0.3, lw=4)\n",
        "plt.legend()\n",
        "plt.savefig(\"schedule.png\")\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9OLoSsXiYEZ"
      },
      "outputs": [],
      "source": [
        "def test_forward(num=1000000):\n",
        "  g = dataset_train[0]\n",
        "  try:\n",
        "      with open(\"edge_weights_simple_example.pickle\", \"rb\") as f:\n",
        "          edge_weights = pickle.load(f)\n",
        "  except:\n",
        "      edge_weights = torch.tensor([random.choice([NO_EDGE_INDICATOR, EDGE_INDICATOR]) for _ in range(num)])\n",
        "      with open(\"edge_weights_simple_example.pickle\", \"wb\") as f:\n",
        "          pickle.dump(edge_weights, f)\n",
        "\n",
        "  #print(edge_weights)\n",
        "  edge_weights = edge_weights.to(DEVICE)\n",
        "  #betas.to(DEVICE)\n",
        "  future_t = torch.tensor([999]*len(edge_weights), device=DEVICE)\n",
        "  edge_weights, noise_gt = forward_diffusion(edge_weights, future_t, betas)\n",
        "  edge_weights.tolist()\n",
        "\n",
        "  #print(edge_weights)\n",
        "  sns.kdeplot(edge_weights.cpu())\n",
        "\n",
        "\n",
        "  #Gaussian\n",
        "  from scipy.stats import norm\n",
        "  standard_normal_pdf = lambda x: norm(0, 1).pdf(x)\n",
        "  x_values = np.linspace(-4,4,100)\n",
        "  plt.scatter(x_values, [standard_normal_pdf(x) for x in x_values], c='black', alpha=0.5, marker='x', edgecolors=None, label='Gaussian')\n",
        "test_forward(num=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hzSAZK0h7q"
      },
      "source": [
        "### Train epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEN_3s2zlss7"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, schedule):\n",
        "  \"\"\"\n",
        "  Trains a denoising model for one epoch using a given data loader and optimization algorithm.\n",
        "\n",
        "  Args:\n",
        "  model: The denoising model.\n",
        "  dataloader: The data loader for the training data.\n",
        "  optimizer: The torch optimizer.\n",
        "  schedule (torch.Tensor): The schedule of beta values.\n",
        "\n",
        "  Returns:\n",
        "  float: The average loss for the epoch.\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list() #TODO differnt future_t for all graphs\n",
        "\n",
        "  for g in dataloader:\n",
        "    g.to(DEVICE)\n",
        "    #print(\"batch\", g.batch)\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.tensor([0]) #torch.gather(future_t_select, 0, g.batch)\n",
        "    #print(\"future_t\", future_t)\n",
        "    assert(future_t.numel() == g.x.shape[0])\n",
        "\n",
        "    #return 0/0\n",
        "    #future_t = torch.randint(0, TIMESTEPS, (1,), device = DEVICE)\n",
        "\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "    edge_weights[edge_indices] = edges_with_noise\n",
        "    #future_t_vec = future_t.repeat(edge_weights.numel())\n",
        "\n",
        "    #print(\"x in train \", g.x[:,0].shape, edge_weights.shape, future_t_vec.shape)\n",
        "    x_in = torch.concat((g.x[:,0].view(-1,1), edge_weights.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "    assert(x_in.shape[0] == g.x.shape[0])\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    noise_pred = model(x_in, g.edge_index)\n",
        "    noise_pred = noise_pred[edge_indices].flatten()\n",
        "\n",
        "\n",
        "    loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return np.mean(loss_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pld6IY2GK2Z"
      },
      "outputs": [],
      "source": [
        "def visualize_forward(schedule, g, steps=10):\n",
        "  plt.close()\n",
        "  future_t_index = np.linspace(0, TIMESTEPS-0.5, steps).astype(int)\n",
        "\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
        "  pos = None\n",
        "\n",
        "  for i, future_t in enumerate(future_t_index):\n",
        "    future_t = torch.tensor(future_t, device=DEVICE)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t.repeat(len(edge_weights[edge_indices])), schedule)\n",
        "    if i == 0:\n",
        "      edges_with_noise = edge_weights[edge_indices]\n",
        "    pos, g_nx = plot_weighted_graph(edges_with_noise, g, axes[i], pos=pos)\n",
        "    axes[i].axis('off')  # to hide the axis\n",
        "  plt.savefig(\"example_foward.png\")\n",
        "\n",
        "\n",
        "dataset_train, dataset_test = build_dataset()\n",
        "betas, alphas, alpha_bars = generate_schedule()\n",
        "visualize_forward(betas, dataset_train[0].to(DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZXAFwdYr--b"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suojddTWtx-8"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step(model, g, i, betas):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  t = TIMESTEPS - i - 1\n",
        "\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  t_tensor = torch.tensor([float(t)], device=DEVICE)\n",
        "\n",
        "  t_vec = t_tensor.repeat(g.x.shape[0],1)\n",
        "  x_in = torch.concat((g.x, t_vec), dim=1)\n",
        "  noise_pred = model(x_in, g.edge_index)\n",
        "  noise_pred = noise_pred[edge_indices].flatten()\n",
        "\n",
        "  # extract edge weights\n",
        "\n",
        "  values_in = g.x[edge_indices,1]\n",
        "\n",
        "  # actual denoising\n",
        "  model_mean = sqrt_recip_alphas_t * (values_in - beta_t * noise_pred / sqrt_one_minus_alphas_cumprod_t)\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "  posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # in the paper this is in 3.2. note that sigma^2 is variance, not std\n",
        "  posterior_variance_t = posterior_variance[t]\n",
        "  posterior_std_t = torch.sqrt(posterior_variance_t)\n",
        "\n",
        "  if t == 0:\n",
        "    return model_mean\n",
        "  else:\n",
        "    noise = torch.randn_like(values_in, device = DEVICE)\n",
        "    return model_mean + posterior_std_t * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm7itEUUJtNI"
      },
      "outputs": [],
      "source": [
        "def model_inference(model, g, t):\n",
        "  future_t = torch.tensor(t, device=DEVICE).repeat(g.x.shape[0])\n",
        "  x_in = torch.concat((g.x.view(-1,2), future_t.view(-1,1)), dim=1)\n",
        "\n",
        "  # prediction\n",
        "  try:\n",
        "    batch = g.batch\n",
        "  except:\n",
        "    batch = None #torch.zeros(g.x.shape[0], dtype=torch.long, device=D)\n",
        "  prediction = model(x_in, g.edge_index, batch=batch)\n",
        "  #print(g, prediction, batch)\n",
        "  if g.batch is None or torch.max(g.batch) > 0:\n",
        "    return prediction.cpu().numpy()\n",
        "  return prediction.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcuFV1JMFjFu"
      },
      "outputs": [],
      "source": [
        "def make_choice(choice_list, scores):\n",
        "    assert len(scores) == len(choice_list)\n",
        "\n",
        "    batches = choice_list[0].batch.tolist()\n",
        "    best_graph_for_batch = []\n",
        "\n",
        "    for b_i in batches:\n",
        "        s_i = [s[b_i] for s in scores]\n",
        "        best_graph_for_batch.append(np.argmax(s_i))\n",
        "\n",
        "    g1 = choice_list[0]\n",
        "\n",
        "    for i in range(g1.x.shape[0]):\n",
        "        batch_i = g1.batch[i]\n",
        "        best_graph_in_i = best_graph_for_batch[batch_i]\n",
        "        best_graph = choice_list[best_graph_in_i]\n",
        "        g1.x[i, :] = best_graph.x[i, :]#.clone()\n",
        "\n",
        "    return g1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktPawiOMvUS"
      },
      "outputs": [],
      "source": [
        "def make_choice_sparse(g, choice_list, scores):\n",
        "    assert len(scores) == len(choice_list)\n",
        "\n",
        "    batches = g.batch.tolist()\n",
        "    best_graph_for_batch = []\n",
        "\n",
        "    for b_i in batches:\n",
        "        s_i = [s[b_i].cpu() for s in scores]\n",
        "        best_graph_for_batch.append(np.argmax(s_i))\n",
        "\n",
        "    for i in range(g.x.shape[0]):\n",
        "        if g.x[i,0] > 0.1:\n",
        "          continue\n",
        "        batch_i = g.batch[i]\n",
        "        best_graph_in_i = best_graph_for_batch[batch_i]\n",
        "        best_weights = choice_list[best_graph_in_i]\n",
        "        g.x[i, 1] = best_weights[i]#.clone()\n",
        "\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxx6aU2UuvLa"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  #edge_weights = g.x[:,1]\n",
        "  #edges_without_noise = edge_weights[edge_indices]\n",
        "  g.x[edge_indices,1] = torch.randn_like(g.x[edge_indices,1], device=DEVICE)\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pda5tncJFKP"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples_batchedX(model, betas, dataset_train, model_guide, num=100, choices=2):\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  if model_guide is None:\n",
        "    choices=1\n",
        "  else:\n",
        "    model_guide = model_guide.to(DEVICE)\n",
        "    model_guide.eval()\n",
        "\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    g = overwrite_with_noise(g)\n",
        "    t_max = TIMESTEPS // GUIDE_FRACTION # where to start guideance  TODO\n",
        "\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if t <= t_max and model_guide is not None: # with guide\n",
        "\n",
        "        edges_with_less_noise1 = denoise_one_step(model, g, i, betas)\n",
        "        g_orig_w1 = g.x[:,1].clone().view(-1)\n",
        "        g_orig_w1[edge_indices] = edges_with_less_noise1\n",
        "\n",
        "        edges_with_less_noise2 = denoise_one_step(model, g, i, betas)\n",
        "        g_orig_w2 = g.x[:,1].clone().view(-1)\n",
        "        g_orig_w2[edge_indices] = edges_with_less_noise2\n",
        "\n",
        "        future_t = torch.tensor(t, device=DEVICE).repeat(g.x.shape[0])\n",
        "        x_in1 = torch.concat((g.x[:,0].view(-1,1), g_orig_w1.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "        x_in2 = torch.concat((g.x[:,0].view(-1,1), g_orig_w2.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "        scores1 = model_guide(x_in1, g.edge_index, batch=g.batch)\n",
        "        scores2 = model_guide(x_in2, g.edge_index, batch=g.batch)\n",
        "        g = make_choice_sparse(g, [g_orig_w1, g_orig_w2], [scores1, scores2])\n",
        "\n",
        "        if i == TIMESTEPS -1:\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "      else: #without guide\n",
        "        edges_with_less_noise = denoise_one_step(model, g, i, betas)\n",
        "        g.x[edge_indices,1] = edges_with_less_noise\n",
        "        if i == TIMESTEPS -1:\n",
        "          print(\"edges_denoised_binary\", edges_denoised_binary)\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    #break\n",
        "\n",
        "    print(\"generated graphs \", graph_list)\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTwsjZHvfXgj"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples_batched(model, betas, dataset_train, model_guide, num=100, choices=2):\n",
        "  print(\"generate samples batched\")\n",
        "\n",
        "  #model.eval()\n",
        "  assert(choices == 1 or choices == 2)\n",
        "  if model_guide is None:\n",
        "    choices=1\n",
        "  else:\n",
        "    model_guide = model_guide.to(DEVICE)\n",
        "    model_guide.eval()\n",
        "\n",
        "\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "  for g in dataloader:\n",
        "    print(\"load g\", g, g.batch)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    g = overwrite_with_noise(g)\n",
        "    t_max = TIMESTEPS // GUIDE_FRACTION # where to start guideance  TODO\n",
        "\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if t <= t_max and model_guide is not None: # with guide\n",
        "        choice_list = list()\n",
        "        for j in range(choices):\n",
        "          if j == choices-1:\n",
        "            g_alt = g\n",
        "          else:\n",
        "            g_alt = g.clone()\n",
        "          edges_with_less_noise = denoise_one_step(model, g_alt, i, betas)\n",
        "          g_alt.x[edge_indices,1] = edges_with_less_noise\n",
        "          choice_list.append(g_alt)\n",
        "        if choices == 1:\n",
        "          g = choice_list[0]\n",
        "        else:\n",
        "          scores = [model_inference(model_guide, g, t) for g in choice_list] # todo add batching\n",
        "          g = make_choice(choice_list, scores)\n",
        "        if i == TIMESTEPS -1:\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "      else: #without guide\n",
        "        edges_with_less_noise = denoise_one_step(model, g, i, betas)\n",
        "        g.x[edge_indices,1] = edges_with_less_noise\n",
        "        if i == TIMESTEPS -1:\n",
        "          #print(\"weights\",torch.mean(g.x[edge_indices,1]),g.x[edge_indices,1] )\n",
        "          edges_denoised_binary = torch.where(g.x[edge_indices,1] > 0.0, 1., -1.)\n",
        "          g.x[edge_indices,1] = edges_denoised_binary\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    #break\n",
        "\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuyPKETI9c-I"
      },
      "outputs": [],
      "source": [
        "def generate_examples_guided(model, betas, dataset_train, model_guide, num=100, choices=2):\n",
        "  print(\"generate samples with guidance\")\n",
        "  gen_set = list()\n",
        "  model_guide = model_guide.to(DEVICE)\n",
        "  tqdm_x = tqdm if num > 10 else lambda x: x\n",
        "  for i in tqdm_x(range(num)):\n",
        "    g = dataset_train[random.choice(range(len(dataset_train)))].clone().to(DEVICE)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_without_noise = edge_weights[edge_indices]\n",
        "    edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "    g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    t_max = TIMESTEPS // GUIDE_FRACTION\n",
        "\n",
        "    for i in range(TIMESTEPS):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if t <= t_max:\n",
        "        choice_list = list()\n",
        "        for j in range(choices):\n",
        "          g_alt = g.clone()\n",
        "          edges_with_noise = denoise_one_step(model, g_alt, i, betas)\n",
        "          g_alt.x[edge_indices,1] = edges_with_noise\n",
        "          choice_list.append(g_alt)\n",
        "        scores = [model_inference(model_guide, g, t) for g in choice_list]\n",
        "        g = choice_list[np.argmax(scores)]\n",
        "        edges_with_noise = g.x[edge_indices,1] # relevant for last step\n",
        "      else:\n",
        "        edges_with_noise = denoise_one_step(model, g, i, betas)\n",
        "        g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    edges_denoised_binary = torch.where(edges_with_noise > 0.0, 1., -1.)\n",
        "\n",
        "    g.x[edge_indices,1] = edges_denoised_binary\n",
        "    gen_set.append(g)\n",
        "\n",
        "  return gen_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO-QiVKxEmAb"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples_silent(model, betas, dataset_train, model_guide = None, num=100):\n",
        "  if model_guide is not None:\n",
        "    return generate_examples_guided(model, betas, dataset_train, model_guide, num=num)\n",
        "  print(\"generate samples without guidance\")\n",
        "  gen_set = list()\n",
        "  tqdm_x = tqdm if num > 10 else lambda x: x\n",
        "  for i in tqdm_x(range(num)):\n",
        "    g = dataset_train[random.choice(range(len(dataset_train)))].clone().to(DEVICE)\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_without_noise = edge_weights[edge_indices]\n",
        "    edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "    g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    for i in range(TIMESTEPS):\n",
        "      edges_with_noise = denoise_one_step(model, g, i, betas)\n",
        "      g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "    edges_denoised_binary = torch.where(edges_with_noise > 0.0, 1., -1.)\n",
        "\n",
        "    g.x[edge_indices,1] = edges_denoised_binary\n",
        "    gen_set.append(g)\n",
        "\n",
        "  return gen_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6OVKWQVp4lR"
      },
      "outputs": [],
      "source": [
        "#@torch.inference_mode()\n",
        "def generate_example(model, epoch_i, betas, dataset_train, steps=10, silent=False):\n",
        "  plt.close()\n",
        "  #model.eval()\n",
        "\n",
        "  g = dataset_train[random.choice(range(len(dataset_train)))].clone() # we sample to get a random number of node\n",
        "\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1].clone()\n",
        "  edges_without_noise = edge_weights[edge_indices]\n",
        "  edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "  g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "  future_t_index = list(np.linspace(0, TIMESTEPS-0.5, steps).astype(int))\n",
        "\n",
        "  if not silent:\n",
        "    fig, axes = plt.subplots(1, steps, figsize=(20, 2))\n",
        "  else:\n",
        "    axes = range(steps)\n",
        "  pos = None\n",
        "\n",
        "  graphs_to_plot = list()\n",
        "\n",
        "  ax_count = -1\n",
        "  for i in range(TIMESTEPS):\n",
        "    if i == future_t_index[0]:\n",
        "      ax_count += 1\n",
        "      binarize = len(future_t_index) == 1\n",
        "      graphs_to_plot.append((edges_with_noise,g.clone(),axes[ax_count],binarize))\n",
        "      future_t_index.pop(0)\n",
        "\n",
        "    g.x[edge_indices,1] = edges_with_noise\n",
        "    edges_with_noise = denoise_one_step(model, g, i, betas)\n",
        "\n",
        "  # we want that pos is computed based on the final graph\n",
        "  graph_to_return = None\n",
        "  for (edges_with_noise,g,ax,binarize) in graphs_to_plot[::-1]:\n",
        "    if not silent:\n",
        "      pos, g_nx = plot_weighted_graph(edges_with_noise, g, ax, pos=pos, binarize=binarize)\n",
        "      ax.axis('off')\n",
        "      if binarize:\n",
        "        graph_to_return = g_nx\n",
        "\n",
        "  if not silent:\n",
        "    plt.savefig(f\"reverse_process_reference_epoch_{str(epoch_i).zfill(6)}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    return graph_to_return\n",
        "\n",
        "  return graphs_to_plot[-1][1]\n",
        "  # save model\n",
        "\n",
        "\n",
        "\n",
        "def execute_function_times(function, num_executions, *args, **kwargs):\n",
        "  results = []\n",
        "  show = tqdm if num_executions>15 else lambda x:x\n",
        "  for _ in show(range(num_executions)):\n",
        "    result = function(*args, **kwargs)\n",
        "    results.append(result)\n",
        "  return results\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate_examples(model, epoch_i, betas, dataset_train, num_times=NUM_GRAPHS_TO_GENERATE, silent=False):\n",
        "  return execute_function_times(generate_example, num_times, model, epoch_i, betas, dataset_train, silent=silent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdPFgj3nEx9_"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftwezkN8f_sS"
      },
      "outputs": [],
      "source": [
        "##path = \"model_epoch_00019900.pth\"\n",
        "#checkpoint = torch.load(path)\n",
        "#checkpoint.keys()\n",
        "#checkpoint[\"graph_loss_list\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSgh0o0H3Tv5"
      },
      "outputs": [],
      "source": [
        "def plot_base(graph_loss_list, loss_list):\n",
        "  plt.clf()\n",
        "  plt.plot(graph_loss_list)\n",
        "  plt.title(\"graph_loss_list\")\n",
        "  plt.savefig(\"train_base_graph_loss.png\")\n",
        "  plt.clf()\n",
        "  plt.plot(loss_list)\n",
        "  plt.title(\"loss_list\")\n",
        "  plt.savefig(\"train_base_train_loss.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAmeusYrfwAb"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=None):\n",
        "  print(\"train base model\")\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "  lr = LEARNING_RATE\n",
        "  if BATCH_SIZE > 1:\n",
        "    lr = lr/100.0\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE)\n",
        "  loss_list = list()\n",
        "  graph_loss_list = list()\n",
        "  model_base, optimizer, graph_loss_list, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, graph_loss_list, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_num = epoch_num if epoch_num is not None else EPOCHS\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    if (epoch_i % 100 == 0 and epoch_i > 1000) or epoch_i == epoch_num - 1:\n",
        "      graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "      graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "      print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "      plot_base(graph_loss_list, loss_list)\n",
        "      save_model(model_base, optimizer, graph_loss_list, loss_list, epoch_i)\n",
        "      if epoch_i == epoch_num - 1:\n",
        "        break # dont train in final epoch so that saved model is final\n",
        "\n",
        "    try:\n",
        "      loss, time_elapsed = train_epoch(model_base, train_loader, optimizer, betas)\n",
        "      loss_list.append(loss.item())\n",
        "      if epoch_i % 10 == 0 or epoch_i == epoch_num - 1:\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss.item():05.4f} with mean loss {np.mean(loss_list + [loss.item()]):05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNFoBC6PNfkY"
      },
      "source": [
        "# Discriminative Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgtMvfeuRw7F"
      },
      "source": [
        "- sample 100 train and 100 test graphs from DM\n",
        "- sample 100 train and 100 test graphs from trainset\n",
        "- train discriminator on DM-train and DM-test, D: g -> [0,1]\n",
        "- evaluate discriminator on DM-test, D(g)\n",
        "- initialize predictor P: g' -> [0,1], where g' is a (diffused) graph\n",
        "- for each g in DM-test, do forward diffusion until random t to get g'\n",
        "- train P(g') to predict D(g)\n",
        "- To sample graph: do inference on DM with the guidance function P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PvBw1h-RPPi"
      },
      "source": [
        "### Gen Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Q8pRbdhXGY"
      },
      "outputs": [],
      "source": [
        "#!rm generated_samples.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2_K2CQgUAoI"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=16, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 1\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    if x.shape[1] == 2:\n",
        "      x = x[:,1].reshape(-1,1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    #x = self.final_mlp(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model_disc = PNAdisc(disc_train_set)\n",
        "#model_disc.to(DEVICE)\n",
        "#g = binary_graphs[0]\n",
        "#g.to(DEVICE)\n",
        "#print(g, g.x.shape, g.edge_index.shape)  #Data(x=[18, 1], edge_index=[2, 50], weight=[50], y=0) torch.Size([18, 1]) torch.Size([2, 50])\n",
        "#model_disc(g.x, g.edge_index, batch=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7iN9Tgcp4YB"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer, update_model=True):\n",
        "  if update_model:\n",
        "    model_disc.train()\n",
        "  else:\n",
        "    model_disc.eval()\n",
        "\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for g in dataloader:\n",
        "    g.to(DEVICE)\n",
        "    if update_model:\n",
        "     optimizer.zero_grad()\n",
        "    target = model_disc(g.x, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "    loss = ((target.view(-1) - g.y.view(-1)))**2\n",
        "    if update_model:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    loss = np.sqrt(loss.item())  # convert MSE to L1\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(0.0 if loss > 0.5 else 1.0)\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CWNQS7n9rzx"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader_disc_test):\n",
        "  return train_epoch_disc(model_disc, dataloader_disc_test, optimizer=None, update_model=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9FH4yvbnMAb"
      },
      "outputs": [],
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc)\n",
        "  weight_path = f\"discriminator_model_{round_i:03}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:04}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 0:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:01.3f}\")\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"discriminator_model_{round_i:03}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_disc.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isOhA5Kecd2U"
      },
      "outputs": [],
      "source": [
        "#train_loader_disc = DataLoader(binary_graphs, batch_size=1, shuffle=True)\n",
        "#train_loader_disc = DataLoader(disc_train_set, batch_size=1, shuffle=True)\n",
        "\n",
        "#model_disc = PNAdisc(train_loader_disc)\n",
        "#model_disc.to(DEVICE)\n",
        "\n",
        "#optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "\n",
        "#for epoch_i in range(100):\n",
        "#  loss, acc, t = train_epoch_disc(model_disc, train_loader_disc, optimizer_disc)\n",
        " # print(loss, acc, t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6SQ1V96LDpH"
      },
      "outputs": [],
      "source": [
        "def plot_graph_gen_loss(graph_gen_loss_list, round_i):\n",
        "  plt.clf()\n",
        "  plt.plot(graph_gen_loss_list)\n",
        "  plt.title(\"graph gen loss\")\n",
        "  plt.savefig(f\"graph_gen_loss_{round_i:03}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGbVSPgK_jlL"
      },
      "source": [
        "### Sample base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtAf3tRJlTJg"
      },
      "outputs": [],
      "source": [
        "def sample_base_model(model_base, round_i, model_guide=None, num=100):\n",
        "  try:\n",
        "    with open(f\"generated_samples_{round_i:03}.pickle\", \"rb\") as f:\n",
        "      generated_samples, generated_samples_nx, graph_gen_loss_list = pickle.load(f)\n",
        "      assert(len(generated_samples) == num)\n",
        "      print(f\"found generated samples in round {round_i:04}.\")\n",
        "      #graph_gen_loss = compute_generation_loss(generated_samples_nx, None)\n",
        "      print(f\"Generated {len(generated_samples_nx):05} graphs. Graph generation loss list is:\", graph_gen_loss_list)\n",
        "      #plot_graph_gen_loss(graph_gen_loss, round_i)\n",
        "      return generated_samples\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred during training: \\n\", str(e))\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "  graph_gen_loss_list = list()\n",
        "  try:\n",
        "    if len(graph_gen_loss_list) == 0 and round_i>0:\n",
        "      round_x = round_i-1\n",
        "      with open(f\"generated_samples_{round_x:03}.pickle\", \"rb\") as f:\n",
        "        _, _, graph_gen_loss_list = pickle.load(f)\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred during training: \\n\", str(e))\n",
        "    traceback.print_exc()\n",
        "\n",
        "  #generated_samples = generate_examples_silent(model_base, betas, dataset_train, num=num, model_guide=model_guide)\n",
        "  generated_samples = generate_examples_batched(model_base, betas, dataset_train, num=num, model_guide=model_guide)\n",
        "\n",
        "  #random.shuffle(generated_samples)\n",
        "  assert(len(generated_samples) > 0)\n",
        "\n",
        "  generated_samples_nx = [pyg_to_sparsebinary_nx(g) for g in generated_samples]\n",
        "  graph_gen_loss = compute_generation_loss(generated_samples_nx, None)\n",
        "  print(\"graph_gen_loss: \",graph_gen_loss)\n",
        "  graph_gen_loss_list.append(graph_gen_loss)\n",
        "  plot_graph_gen_loss(graph_gen_loss_list, round_i)\n",
        "\n",
        "  with open(f\"generated_samples_{round_i:03}.pickle\", \"wb\") as f:\n",
        "    pickle.dump((generated_samples, generated_samples_nx, graph_gen_loss_list), f)\n",
        "\n",
        "  return generated_samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7vBbaspAZRB"
      },
      "outputs": [],
      "source": [
        "def plot_samples(disc_train_set, model_disc=None, round_i=0):\n",
        "  if os.path.exists(f'grid_images_for_disc_pred_{round_i:04}.png'):\n",
        "    print(\"found\", f'grid_images_for_disc_pred_{round_i:04}.png')\n",
        "    return\n",
        "\n",
        "  fig, axs = plt.subplots(16, 10, figsize=(20, 32))\n",
        "  nx_list = list()\n",
        "  mean_degree_list = list()\n",
        "\n",
        "  random.shuffle(disc_train_set)\n",
        "\n",
        "  ix = -1\n",
        "  for i in tqdm(range(16)):\n",
        "    for j in range(10):\n",
        "      ix += 1\n",
        "      g = disc_train_set[ix]\n",
        "      ax = axs[i, j]\n",
        "      pos, g_nx = plot_weighted_graph(None, g, ax, pos=None, binarize=True)\n",
        "      pred = 0\n",
        "      if model_disc is not None:\n",
        "        pred = model_disc(g.x, g.edge_index, batch=None).item()\n",
        "      g.pred = pred\n",
        "      #print(pred)\n",
        "\n",
        "      edge_weights = nx.get_edge_attributes(g_nx, 'weight')\n",
        "      edge_weights = [edge_weights[e]/2.0+0.5 for e in g_nx.edges] #done in plot_weighted...\n",
        "      mean_degree = 2*np.sum(edge_weights)/g_nx.number_of_nodes()\n",
        "      mean_degree_list.append(mean_degree)\n",
        "\n",
        "      ax.set_title(f\"{pred:.4f} - {mean_degree:01.2f}\")\n",
        "      ax.axis('off')\n",
        "      nx_list.append(g_nx)\n",
        "\n",
        "  #with open(f'grid_images_for_disc_pred_{round_i:04}.pickle', \"wb\") as f:\n",
        "  #  pickle.dump(nx_list, f)\n",
        "\n",
        "  #plt.tight_layout()\n",
        "  plt.savefig(f'grid_images_for_disc_pred_{round_i:04}.png', dpi=300)\n",
        "  print(f\"mean degree is {np.mean(mean_degree_list):02.5f}\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZtmsTm3s5z9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pgjxArr_q_5"
      },
      "source": [
        "# Guidance Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUCpj81oDihD"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "class PNAguide(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=5, dropout=0.00, towers=3, normalization=True, pre_post_layers=1):\n",
        "    super(PNAguide, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 3\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = torch.sum(x, dim=1)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model_guide = PNAguide(train_loader_disc)\n",
        "#model_guide.to(DEVICE)\n",
        "#g = train_loader_disc.dataset[0]\n",
        "#g.to(DEVICE)\n",
        "#print(g, g.x.shape, g.edge_index.shape)  #Data(x=[18, 1], edge_index=[2, 50], weight=[50], y=0) torch.Size([18, 1]) torch.Size([2, 50])\n",
        "#node_nun = g.x.shape[0]\n",
        "#x_in = torch.randn([node_nun, 3])\n",
        "#model_guide(x_in, g.edge_index, batch=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlkD45LK_w-_"
      },
      "outputs": [],
      "source": [
        "def train_epoch_guide(model_guide, model_disc, dataloader, optimizer, schedule, update_model=True, epoch_i=1):\n",
        "  if update_model:\n",
        "    model_guide.train()\n",
        "  else:\n",
        "    model_guide.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "\n",
        "  for g in dataloader:\n",
        "    g.to(DEVICE)\n",
        "    if update_model:\n",
        "      optimizer.zero_grad()\n",
        "    target = model_disc(g.x, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "\n",
        "    # comupte t vec\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    t_max = TIMESTEPS\n",
        "    #t_max = min(epoch_i+1, t_max // 3) # todo\n",
        "    #t_min = t_max - t_max // GUIDE_FRACTION\n",
        "    t_max=TIMESTEPS// GUIDE_FRACTION\n",
        "    future_t_select = torch.randint(0, t_max, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, g.batch)\n",
        "\n",
        "    # compute noisy edge weights\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "    edge_weights[edge_indices] = edges_with_noise\n",
        "    x_in = torch.concat((g.x[:,0].view(-1,1), edge_weights.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "\n",
        "    # prediction\n",
        "    prediction = model_guide(x_in, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "    loss = ((target.view(-1) - prediction.view(-1)))**2\n",
        "    if update_model:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    loss = np.sqrt(loss.item())  # convert MSE to L1\n",
        "    loss_list.append(loss)\n",
        "\n",
        "  return np.mean(loss_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgL1i5cOBwRT"
      },
      "outputs": [],
      "source": [
        "def test_guide(model_guide, model_disc, train_loader_disc_test, schedule, epoch_i):\n",
        "  return train_epoch_guide(model_guide, model_disc, dataloader=train_loader_disc_test, optimizer=None, schedule=schedule, update_model=False, epoch_i=epoch_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD2wR_7zGEO7"
      },
      "outputs": [],
      "source": [
        "def get_merged_dataloader(generated_samples, dataset):\n",
        "\n",
        "  #random.shuffle(dataset_train) # not needed because shuffle list\n",
        "  random.shuffle(generated_samples) # also prob not needed\n",
        "\n",
        "  num_elem = min(len(generated_samples), len(dataset))\n",
        "  disc_set = list()\n",
        "\n",
        "  for fake_graph in generated_samples[:num_elem]:\n",
        "    fake_graph = fake_graph.clone()\n",
        "    fake_graph.y =  0.0\n",
        "    disc_set.append(fake_graph)\n",
        "\n",
        "  for real_graph in dataset[:num_elem]:\n",
        "    real_graph = real_graph.clone()\n",
        "    real_graph.y = 1.0\n",
        "    disc_set.append(real_graph)\n",
        "\n",
        "  dataloader_disc = DataLoader(disc_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  return dataloader_disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntRL02_Jxbss"
      },
      "outputs": [],
      "source": [
        "def train_guide_model(model_disc, train_loader_disc, train_loader_disc_test, round_i):\n",
        "  model_guide = PNAguide(train_loader_disc)\n",
        "\n",
        "  weight_path = f\"guide_model_{round_i:03}.pth\"\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_guide.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found guide model in round {round_i:04}\")\n",
        "    return model_guide\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "  model_guide = model_guide.to(DEVICE)\n",
        "  optimizer_guide = Adam(model_guide.parameters(), lr = 0.0001)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  for epoch_i in range(EPOCHS_GUIDE_MODEL):\n",
        "    loss_train, t_train = train_epoch_guide(model_guide, model_disc, train_loader_disc, optimizer_guide, schedule=betas, epoch_i=epoch_i)\n",
        "    if epoch_i % 10 == 0:\n",
        "      loss_test, t_test = test_guide(model_guide, model_disc, train_loader_disc_test, betas, epoch_i=epoch_i)\n",
        "      print(f\"train guide: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, time: {t_train:02.3f}\")\n",
        "\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"guide_model_{round_i:03}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_guide.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_guide\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9P2NDVv_GGG"
      },
      "source": [
        "# Putting thinigs together I - Classical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YBTkSsL_HTT"
      },
      "outputs": [],
      "source": [
        "#dataset_base, dataset_base_test = build_dataset()\n",
        "#dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "#num_samples_train = int(NUM_SAMPLES*TRAIN_TEST_SPLIT)\n",
        "#num_samples_test = NUM_SAMPLES - num_samples_train\n",
        "#model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "#model_guide = None\n",
        "\n",
        "#for round_i in range(NUM_ROUNDS):\n",
        "#  samples = sample_base_model(model_base, round_i, model_guide=model_guide, num=NUM_SAMPLES)\n",
        "#  dataloader_disc = get_merged_dataloader(samples[:num_samples_train], dataset_base)\n",
        "#  dataloader_disc_test = get_merged_dataloader(samples[num_samples_train:], dataset_base_test)\n",
        "#  model_disc = train_disc_model(dataloader_disc, dataloader_disc_test, round_i)\n",
        "#  plot_samples(dataloader_disc.dataset, model_disc, round_i)\n",
        "#  model_guide = train_guide_model(model_disc, dataloader_disc, dataloader_disc_test, round_i)\n",
        "\n",
        "#  #new_epoch_num = BASE_MODEL_EPOCHS + (round_i+1)*int(BASE_MODEL_EPOCHS*0.2)\n",
        "#  #model_base = train_base_model(dataloader_base, epoch_num = new_epoch_num)\n",
        "\n",
        "#samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_guide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVfF7ZyuR4sC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDhvDZK_YPhu"
      },
      "source": [
        "# Putting thinigs together II - Single Disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olNy5xb9ZEcI"
      },
      "outputs": [],
      "source": [
        "def train_epoch_cassandra(model_cassandra, dataloader, optimizer, schedule, update_model=True, epoch_i=1):\n",
        "  if update_model:\n",
        "    model_cassandra.train()\n",
        "  else:\n",
        "    model_cassandra.eval()\n",
        "  model_cassandra = model_cassandra.to(DEVICE)\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    if update_model:\n",
        "      optimizer.zero_grad()\n",
        "    target = g.y\n",
        "\n",
        "    # comupte t vec\n",
        "    num_graphs_in_batch = int(torch.max(g.batch).item()+1)\n",
        "    t_max = TIMESTEPS\n",
        "    #t_max = min(epoch_i+1, t_max // 3) # todo\n",
        "    #t_min = t_max - t_max // GUIDE_FRACTION\n",
        "    t_max=TIMESTEPS// GUIDE_FRACTION\n",
        "    future_t_select = torch.randint(0, t_max, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, g.batch)\n",
        "\n",
        "    # compute noisy edge weights\n",
        "    edge_indices = g.x[:,0] < 0.1\n",
        "    edge_weights = g.x[:,1].clone()\n",
        "    edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "    edge_weights[edge_indices] = edges_with_noise\n",
        "    x_in = torch.concat((g.x[:,0].view(-1,1), edge_weights.view(-1,1), future_t.view(-1,1)), dim=1)\n",
        "\n",
        "    # prediction\n",
        "    prediction = model_cassandra(x_in, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "    loss = ((target.view(-1) - prediction.view(-1)))**2\n",
        "    if update_model:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    loss = np.sqrt(loss.item())  # convert MSE to L1\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(0.0 if loss > 0.5 else 1.0)\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J465bmjZXPl"
      },
      "outputs": [],
      "source": [
        "def test_cassandra(model_cassandra, train_loader_disc_test, schedule, epoch_i):\n",
        "  return train_epoch_cassandra(model_cassandra, dataloader=train_loader_disc_test, optimizer=None, schedule=schedule, update_model=False, epoch_i=epoch_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AO4cFiNYhbm"
      },
      "outputs": [],
      "source": [
        "def train_cassandra_model(train_loader_disc, train_loader_disc_test, round_i):\n",
        "  model_cassandra = PNAguide(train_loader_disc)\n",
        "\n",
        "\n",
        "  weight_path = f\"cassandra_model_{round_i:03}.pth\"\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_cassandra.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found cassandra model in round {round_i:04}\")\n",
        "    return model_cassandra\n",
        "  except:\n",
        "    print(weight_path, \"not found\")\n",
        "\n",
        "  model_cassandra = model_cassandra.to(DEVICE)\n",
        "  optimizer_cassandra = Adam(model_cassandra.parameters(), lr = 0.0001)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  for epoch_i in range(EPOCHS_GUIDE_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_cassandra(model_cassandra, train_loader_disc, optimizer_cassandra, schedule=betas, epoch_i=epoch_i)\n",
        "    if epoch_i % 10 == 0:\n",
        "      loss_test, acc_test, t_test = test_cassandra(model_cassandra, train_loader_disc_test, betas, epoch_i=epoch_i)\n",
        "      print(f\"train cassandra: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f},  acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:02.3f}\")\n",
        "\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"cassandra_model_{round_i:03}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_cassandra.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_cassandra\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2bmaEFZYR0n"
      },
      "outputs": [],
      "source": [
        "dataset_base, dataset_base_test = build_dataset()\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "num_samples_train = int(NUM_SAMPLES*TRAIN_TEST_SPLIT)\n",
        "num_samples_test = NUM_SAMPLES - num_samples_train\n",
        "model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "model_cassandra = None\n",
        "\n",
        "for round_i in range(NUM_ROUNDS):\n",
        "  samples = sample_base_model(model_base, round_i, model_guide=model_cassandra, num=NUM_SAMPLES)  #TODO\n",
        "  plot_samples(samples, model_disc=None, round_i=round_i)\n",
        "  dataloader_disc = get_merged_dataloader(samples[:num_samples_train], dataset_base)\n",
        "  dataloader_disc_test = get_merged_dataloader(samples[num_samples_train:], dataset_base_test)\n",
        "  model_cassandra = train_cassandra_model(dataloader_disc, dataloader_disc_test, round_i)\n",
        "  #new_epoch_num = BASE_MODEL_EPOCHS + (round_i+1)*int(BASE_MODEL_EPOCHS*0.2)\n",
        "  #model_base = train_base_model(dataloader_base, epoch_num = new_epoch_num)\n",
        "\n",
        "samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_cassandra, num=NUM_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC5nnw3GDaAN"
      },
      "outputs": [],
      "source": [
        "#!rm cassandra_model_*.pth\tgenerated_samples_001.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kvYvQ509ckB"
      },
      "outputs": [],
      "source": [
        "#!rm generated_samples_002.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egG7sdK6RFms"
      },
      "outputs": [],
      "source": [
        " z=z/0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QnaWzDLyBzn"
      },
      "outputs": [],
      "source": [
        "s1 = [pyg_to_sparsebinary_nx(s) for s in samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-rzR_kPyTMF"
      },
      "outputs": [],
      "source": [
        "samples[0].x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuMUNIAbz2rE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_geometric.data as data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Define the adjacency matrices of the graphs\n",
        "adj_matrix1 = torch.tensor([[0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0]])\n",
        "adj_matrix2 = torch.tensor([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
        "\n",
        "# Create the GraphData objects for each graph\n",
        "graph1 = data.Data(x=torch.randn(4, 3), edge_index=adj_matrix1.nonzero().t())\n",
        "graph2 = data.Data(x=torch.randn(3, 3), edge_index=adj_matrix2.nonzero().t())\n",
        "\n",
        "# Create a list of the graphs\n",
        "graph_list = [graph1, graph2]\n",
        "\n",
        "# Create the DataLoader with batch size 2\n",
        "batch_size = 2\n",
        "dataloader = DataLoader(graph_list, batch_size=batch_size)\n",
        "\n",
        "# Iterate over the DataLoader\n",
        "for batch in dataloader:\n",
        "    # Unpack the batch into individual graphs\n",
        "    graphs = batch.to_data_list()\n",
        "    print(batch)\n",
        "    print(batch.x)\n",
        "    batch.x = torch.zeros_like(batch.x, device=DEVICE)\n",
        "    for g in batch.to_data_list():\n",
        "      print(g.x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJD24ijLswiu"
      },
      "outputs": [],
      "source": [
        "samples = sample_base_model(model_base, 0, model_guide=None, num=NUM_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irKpz9IIs0xb"
      },
      "outputs": [],
      "source": [
        "samples\n",
        "generated_samples_nx = [pyg_to_sparsebinary_nx(g) for g in samples]\n",
        "graph_gen_loss = compute_generation_loss(generated_samples_nx, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvzA0zejtMLy"
      },
      "outputs": [],
      "source": [
        "#g = generated_samples_nx[0]\n",
        "dlist = list()\n",
        "for g in generated_samples_nx:\n",
        "  for v_i in g.nodes():\n",
        "    dlist.append(g.degree(v_i))\n",
        "print(dlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMJa5xi3_Nyo"
      },
      "outputs": [],
      "source": [
        "#!rm *cassandra*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXprq5xuhzsI"
      },
      "outputs": [],
      "source": [
        "#ä!rm generated_samples_001.pickle generated_samples_002.pickle generated_samples_003.pickle generated_samples_004.pickle generated_samples_005.pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QB8C63TdYwO"
      },
      "source": [
        "# Putting Things Together III - Oracle Guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4zr1nyRmF0c"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "class PNAoracle(torch.nn.Module):\n",
        "  def __init__(self, train_dataset, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAoracle, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = 3\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9kiTfBAlDwb"
      },
      "outputs": [],
      "source": [
        "def test_oracle(model_oracle, g, t, return_float=False):\n",
        "  if model_oracle is None:\n",
        "    # here we also return float\n",
        "    return 0.0\n",
        "\n",
        "  future_t = torch.tensor(t).repeat(g.x.shape[0])\n",
        "  x_in = torch.concat((g.x.reshape(-1,2), future_t.reshape(-1,1)), dim=1)\n",
        "\n",
        "  # prediction\n",
        "  prediction = model_oracle(x_in, g.edge_index, batch=torch.zeros(g.x.shape[0], dtype=torch.long, device=DEVICE))\n",
        "  if return_float:\n",
        "    return prediction.item()\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpu-_HU7gvol"
      },
      "outputs": [],
      "source": [
        "def forward_diffusion_until(g, t, schedule):\n",
        "  g = g.clone()\n",
        "\n",
        "  future_t = torch.tensor([int(t)]).repeat(g.x.shape[0])\n",
        "  assert(future_t.numel() == g.x.shape[0])\n",
        "\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1]\n",
        "  edges_with_noise, noise_gt = forward_diffusion(edge_weights[edge_indices], future_t[edge_indices], schedule)\n",
        "  g.x[edge_indices,1] = edges_with_noise\n",
        "  return g\n",
        "\n",
        "@torch.inference_mode()\n",
        "def graph_inference_until(g, model, compare_times, schedule, oracle_old=None, choice_num=2):\n",
        "  g = g.clone().to(DEVICE)\n",
        "  compare_times = list(compare_times)\n",
        "  assert(\"int\" in str(type(compare_times[0])))\n",
        "\n",
        "  generated_graphs = list()\n",
        "  edge_indices = g.x[:,0] < 0.1\n",
        "  edge_weights = g.x[:,1]\n",
        "  edges_without_noise = edge_weights[edge_indices]\n",
        "  edges_with_noise = torch.randn_like(edges_without_noise, device=DEVICE)\n",
        "  g.x[edge_indices,1] = edges_with_noise\n",
        "\n",
        "  for i in range(TIMESTEPS):\n",
        "    t = TIMESTEPS - i - 1\n",
        "    if len(compare_times) == 0:\n",
        "      break\n",
        "    if t == compare_times[-1]:\n",
        "      compare_times.pop()\n",
        "      generated_graphs.append((g, t)) # clone necessary?\n",
        "\n",
        "    choice_list = list()\n",
        "    if oracle_old is None:\n",
        "      choice_num = 1\n",
        "    for j in range(choice_num):\n",
        "      g_alt = g.clone()\n",
        "      edges_with_noise = denoise_one_step(model, g_alt, i, schedule)\n",
        "      g_alt.x[edge_indices,1] = edges_with_noise\n",
        "      choice_list.append(g_alt)\n",
        "    scores = [test_oracle(oracle_old, g, t, return_float=True) for g in choice_list]\n",
        "    g = choice_list[np.argmax(scores)]\n",
        "\n",
        "  return generated_graphs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEHhF2iSgD5a"
      },
      "outputs": [],
      "source": [
        "def train_epoch_oracle(dataloader, model_oracle, model_base, oracle_old, optimizer_oracle, schedule, epoch_i):\n",
        "  # 1 is real, 0 is fake\n",
        "  model_oracle.train()\n",
        "  if oracle_old is not None:\n",
        "    oracle_old.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  comparisons_per_graph = 10\n",
        "\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    optimizer_oracle.zero_grad()\n",
        "    compare_times = torch.randint(0, TIMESTEPS, (comparisons_per_graph,), device = DEVICE) #t=0 is original image\n",
        "    compare_times = sorted(compare_times.tolist())\n",
        "\n",
        "    g_fake_list = graph_inference_until(g, model_base, compare_times, schedule, oracle_old)\n",
        "    for i, (g_fake, t) in enumerate(g_fake_list):\n",
        "      g_fake = g_fake.clone()  #this is somehow necessary\n",
        "      #t = compare_times[i]\n",
        "      g_real = forward_diffusion_until(g, t, schedule)\n",
        "      loss = (test_oracle(model_oracle, g_fake, t) - 0.0)**2\n",
        "      loss = loss + (test_oracle(model_oracle, g_real, t) - 1.0)**2\n",
        "      loss.backward()\n",
        "      optimizer_oracle.step()\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), time.time() - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2Www9EjfaZN"
      },
      "outputs": [],
      "source": [
        "def train_oracle_model(dataloader_base, model_base, round_i, oracle_old=None):\n",
        "  model_oracle = PNAoracle(dataloader_base)\n",
        "\n",
        "  weight_path = f\"oracle_model_{round_i:03}.pth\"\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_oracle.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found oracle model in round {round_i:04}\")\n",
        "    return model_oracle\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  model_oracle.to(DEVICE)\n",
        "  optimizer_oracle = Adam(model_oracle.parameters(), lr = 0.0001)\n",
        "  betas, alphas, alpha_bars = generate_schedule()\n",
        "\n",
        "  for epoch_i in range(EPOCHS_GUIDE_MODEL):\n",
        "    loss, t = train_epoch_oracle(dataloader_base, model_oracle, model_base, oracle_old, optimizer_oracle, schedule=betas, epoch_i=epoch_i)\n",
        "    print(f\"train oracle: epoch: {epoch_i:05}, loss: {loss:02.4f}, time: {t:02.3f}\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_oracle.state_dict()}, weight_path)\n",
        "  return model_oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEeM26UqjO4e"
      },
      "outputs": [],
      "source": [
        "def get_last(elem_list):\n",
        "  return None if len(elem_list) == 0 else elem_list[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU8Og9XIda_P"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_base, dataset_test = build_dataset()\n",
        "dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "model_base = train_base_model(dataloader_base, epoch_num = BASE_MODEL_EPOCHS)\n",
        "print(\"finished training base model\")\n",
        "#generate_examples(model_base, BASE_MODEL_EPOCHS+1, generate_schedule()[0], dataset_base, num_times=30)\n",
        "\n",
        "\n",
        "model_oracle_old = list()\n",
        "\n",
        "\n",
        "for round_i in range(NUM_ROUNDS):\n",
        "  model_base.eval()\n",
        "  samples = sample_base_model(model_base, round_i, model_guide=model_oracle_old, num=len(dataset_base))\n",
        "  #plot_samples(dataloader_base.dataset, model_disc, round_i)\n",
        "  model_oracle = train_oracle_model(dataloader_base, model_base, round_i, oracle_old=model_oracle_old)\n",
        "  model_oracle.eval()\n",
        "  model_oracle_old = model_oracle\n",
        "\n",
        "samples = sample_base_model(model_base, round_i=NUM_ROUNDS, model_guide=model_oracle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmAvO2-kuzWC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1d7uhXgyzzsVVb0WVyh7vHRMFHIymHs8f",
      "authorship_tag": "ABX9TyP8RyIJjmLkyq0TApp2VVy5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}