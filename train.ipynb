{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/Alia/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCMM1H64tA7p"
      },
      "source": [
        "# AliaMolecule Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5NrAGm7to1n"
      },
      "source": [
        "#### Project Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "833DrsZU2o7r"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCeS1g3btmT9"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"AliaMoleculeDeskI\"\n",
        "PATH_PATTERN_BASE = \"aliamol_paper\" #aliamol2 is trained on denoised image\n",
        "BASELINE = False\n",
        "\n",
        "\n",
        "DEBUG = False\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z7g6wEvtFrr"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9JUGxi3tEae",
        "outputId": "335d1e15-c932-4e8f-b19e-2e271ee84bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/AliaMoleculePaperColab5\n"
          ]
        }
      ],
      "source": [
        "# Load drive\n",
        "\n",
        "import os\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  import wandb # need to do this before chaning cwd\n",
        "except:\n",
        "  os.system(\"pip install wandb\")\n",
        "\n",
        "\n",
        "if USE_COLAB:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9oArycxtC6J"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "\n",
        "import os\n",
        "import torch\n",
        "torch_version = torch.__version__.split(\"+\")\n",
        "#os.environ[\"TORCH\"] = torch_version[0]\n",
        "#os.environ[\"CUDA\"] = torch_version[1]\n",
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  os.system(\"pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\")\n",
        "  os.system(\"pip install torch-geometric\")\n",
        "\n",
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  os.system(\"pip install rdkit\")\n",
        "\n",
        "PATH_PATTERN = PATH_PATTERN_BASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LU94GR6x1y-"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD1DOMjwx29q"
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
        "from PIL import Image # We use PIL to load images\n",
        "import seaborn as sns\n",
        "#import imageio # to generate .gifs\n",
        "import networkx as nx\n",
        "\n",
        "# always good to have\n",
        "import glob, random, os, traceback, time, copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Linear as Lin\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#DEVICE = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oscW9KW_NOTi"
      },
      "source": [
        "### Load External"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCNRU4kbNQAJ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"smiles_to_pyg\"):\n",
        "  os.system(\"git clone https://github.com/gerritgr/Alia.git && cp -R Alia/* .\")\n",
        "from smiles_to_pyg.molecule_load_and_convert import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef33eK-2yBVa"
      },
      "source": [
        "#### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3INYZ1OeyDZs"
      },
      "outputs": [],
      "source": [
        "##\n",
        "## Diffusion\n",
        "##\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 128*2\n",
        "GAMMA = 0.1\n",
        "\n",
        "##\n",
        "## Pred\n",
        "##\n",
        "LEARNING_RATE_GEN = 0.001\n",
        "EPOCHS_GEN = 100\n",
        "\n",
        "### PNA Pred\n",
        "DROPOUT_PRED = 0.05\n",
        "DEPTH_PRED = 4\n",
        "HIDDEN_CHANNELS_PRED = 32\n",
        "TOWERS_PRED = 1\n",
        "NORMALIZATION_PRED = True\n",
        "\n",
        "##\n",
        "## Disc\n",
        "##\n",
        "EPOCHS_DISC_MODEL = 70\n",
        "DISC_NOISE=0.3\n",
        "\n",
        "### PNA Disc\n",
        "HIDDEN_CHANNELS_DISC = 8\n",
        "DEPTH_DISC = 4\n",
        "DROPOUT_DISC = 0.05\n",
        "NORMALIZATION_DISC = True\n",
        "\n",
        "\n",
        "##\n",
        "## Molecule Encoding\n",
        "##\n",
        "\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5 # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False]*5 + [True] * 5\n",
        "NON_EDGES = [True] + [True]*5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUzkUbpyRAP"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0-ubb5pwu84"
      },
      "outputs": [],
      "source": [
        "def log(d):\n",
        "  try:\n",
        "    import wandb\n",
        "    wandb.log(d)\n",
        "  except:\n",
        "    print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isR2usjlQr0k"
      },
      "outputs": [],
      "source": [
        "def load_file(filepath):\n",
        "  print(\"try to read \", filepath)\n",
        "  try:\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {str(e)}\")\n",
        "      raise\n",
        "\n",
        "def write_file(filepath, data):\n",
        "  try:\n",
        "    data = data.cpu()\n",
        "  except:\n",
        "    pass\n",
        "  print(\"try to write \", filepath)\n",
        "  with gzip.open(filepath, 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pb4cD9fMxkl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_dataset(seed=1234):\n",
        "  try:\n",
        "    dataset_train, dataset_test = load_file('dataset.pickle')\n",
        "    if DEBUG:\n",
        "      return dataset_train[:len(dataset_train)//10], dataset_test[:len(dataset_test)//10]\n",
        "    return dataset_train, dataset_test\n",
        "  except Exception as e:\n",
        "    print(f\"Could not load dataset due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  dataset = read_qm9()\n",
        "  dataset_all = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  dataset = list()\n",
        "  for g in tqdm(dataset_all):\n",
        "    try:\n",
        "      assert \"None\" not in str(pyg_to_smiles(g))\n",
        "      dataset.append(g)\n",
        "    except:\n",
        "      pass\n",
        "  print(\"Built and clean dataset, length is \", len(dataset), \"old length was\", len(dataset_all))\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset)*0.8 + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0,:].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  write_file(\"dataset.pickle\", (dataset_train, dataset_test))\n",
        "  return dataset_train, dataset_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVaAhhMoySLZ"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "  \"\"\"\n",
        "  Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "  Args:\n",
        "  start (float): The starting value for the beta values. Default is START.\n",
        "  end (float): The ending value for the beta values. Default is END.\n",
        "  timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "  cumulative alpha values (alpha bars).\n",
        "  \"\"\"\n",
        "  betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "  #alphas = 1.0 - betas\n",
        "  #alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "  assert(betas.numel() == TIMESTEPS)\n",
        "  return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1QHrqCDxdwY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "def visualize_smiles_from_file(filepath):\n",
        "    # Read SMILES from file\n",
        "    with open(filepath, 'r') as file:\n",
        "        smiles_list = [line.strip() for line in file.readlines()]\n",
        "\n",
        "    # Convert SMILES to RDKit Mol objects, filtering out invalid ones\n",
        "    mols = [Chem.MolFromSmiles(smile) for smile in smiles_list[:100]]\n",
        "    mols = [mol for mol in mols if mol is not None]\n",
        "\n",
        "    # Determine grid size\n",
        "    num_mols = len(mols)\n",
        "    cols = 10\n",
        "    rows = min(10, -(-num_mols // cols))  # ceil division\n",
        "\n",
        "    # Create a subplot grid\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(20, 20),\n",
        "                            gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            ax = axs[i, j]\n",
        "            ax.axis(\"off\")  # hide axis\n",
        "            idx = i * cols + j  # index in mols list\n",
        "            if idx < num_mols:\n",
        "                img = Draw.MolToImage(mols[idx], size=(200, 200))\n",
        "                ax.imshow(img)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(filepath + '.jpg', format='jpg', bbox_inches='tight')\n",
        "    plt.close(fig)  # Close the figure after saving to free up memory\n",
        "    try:\n",
        "        time.sleep(0.01)\n",
        "        wandb.log_artifact(filepath + '.jpg', name=f\"jpg_{SWEEP_ID}_{filepath.replace('.','')}\", type=\"smiles_grid_graph\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "\n",
        "# Example usage:\n",
        "# Replace YOUR_FILE_PATH with the path to your SMILES file.\n",
        "# visualize_smiles_from_file(YOUR_FILE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnya1MDuxseM"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1FxjM0jyd1k"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  try:\n",
        "    deg = load_file('deg.pickle')\n",
        "    deg = deg.to(DEVICE)\n",
        "    return deg\n",
        "  except Exception as e:\n",
        "    print(f\"Could not find degree bin due to error: {str(e)}, generate it now\")\n",
        "  assert(train_dataset is not None)\n",
        "\n",
        "\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "\n",
        "  write_file(\"deg.pickle\", deg.cpu())\n",
        "  return deg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=HIDDEN_CHANNELS_PRED, depth=DEPTH_PRED, dropout=DROPOUT_PRED, towers=TOWERS_PRED, normalization=NORMALIZATION_PRED, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM+ TIME_FEATURE_DIM #INDICATOR_FEATURE_DIM entries are noise free\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    row_num = x_in.shape[0]\n",
        "    t = t.view(-1,TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "    assert(x.shape[0] == row_num)\n",
        "\n",
        "    #node_indicator = x_in[:,0] > 0\n",
        "    #node_indicator = x_in[:,0] < 0\n",
        "    #x[node_indicator, NON_NODES] = x_in[node_indicator, NON_NODES]\n",
        "    #x[edge_indicator, NON_EDGES] = x_in[edge_indicator, NON_EDGES]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSm4qgdXRlo0"
      },
      "outputs": [],
      "source": [
        "#path_pattern = \"aliamol_model_epoch_*.pth\"\n",
        "#sorted(glob.glob(path_pattern))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvkRRWDcrRqZ"
      },
      "outputs": [],
      "source": [
        "def load_latest_checkpoint(model, optimizer, loss_list, epoch_i, path_pattern=None):\n",
        "  if path_pattern is None:\n",
        "    path_pattern = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(path_pattern))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    loss_list = checkpoint['loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "def save_model(model, optimizer, loss_list, epoch_i, upload=False):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"{PATH_PATTERN}_model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "  if upload:\n",
        "    try:\n",
        "      wandb.log_artifact(save_path, name=f\"src_txt_{SWEEP_ID}_{epoch_i:08}_weightfile\", type=\"weight\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDm63cFIrG8K"
      },
      "outputs": [],
      "source": [
        "def load_base_model(dataset_train, path_pattern=None):\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  loss_list = None\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE_GEN)\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0, path_pattern=path_pattern)\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4NRBuWuxUDl"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP3_DiRvGjKr"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step_wild(model, g, i):\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  #noise_pred = noise_pred.view(row_num, -1)\n",
        "  #x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  #assert(noise_pred.shape == x_with_noise.shape)\n",
        "  #future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  #original_pred = get_pred_from_noise(noise_pred, x_with_noise, future_t)\n",
        "\n",
        "  if t-1>0:\n",
        "    x_with_noise_again, _ = forward_diffusion(original_pred, t-1)\n",
        "    denoised_x[mask] = x_with_noise_again.flatten()\n",
        "  else:\n",
        "    denoised_x[mask] = original_pred.flatten()\n",
        "  return denoised_x\n",
        "\n",
        "\n",
        "\n",
        "  #x_in = g.x[mask].flatten()\n",
        "  #original_pred = get_pred_from_noise(noise_pred, x_in, future_t)\n",
        "  ##original_pred = (x_in - torch.sqrt(1. - alphas_cumprod_t) * noise_pred)/torch.sqrt(alphas_cumprod_t)\n",
        "  #assert(original_pred.shape[0] = x_in.shape[0])\n",
        "  #x = g.x.clone()\n",
        "  #x[mask] = original_pred\n",
        "  #if t-1 <= 0:\n",
        "  #  return x\n",
        "  #x_with_noise_again, _ = forward_diffusion(x, t-1)\n",
        "  #denoised_x[mask] = x_with_noise_again[mask]\n",
        "  #return denoised_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbcU3sZBxqwh"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step(model, g, i):\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  noise_pred = get_noise_from_pred(original_pred, x_with_noise, future_t)\n",
        "\n",
        "  values_now = g.x[mask].view(row_num, -1)\n",
        "  values_endpoint = noise_pred.view(row_num, -1)#[mask] network only prdicts noise\n",
        "\n",
        "  assert(values_now.shape == values_endpoint.shape)\n",
        "\n",
        "  # now compute values_one_step_denoised\n",
        "  model_mean = sqrt_recip_alphas_t * (values_now - beta_t * values_endpoint / sqrt_one_minus_alphas_cumprod_t)\n",
        "  values_one_step_denoised = model_mean # if t == 0\n",
        "  if t != 0:\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # in the paper this is in 3.2. note that sigma^2 is variance, not std\n",
        "    posterior_std_t = torch.sqrt(posterior_variance[t])\n",
        "    noise = torch.randn_like(values_now, device = DEVICE)\n",
        "    values_one_step_denoised = model_mean + posterior_std_t * noise\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  denoised_x[mask] = values_one_step_denoised.flatten()\n",
        "  return denoised_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSHkoX_-xngv"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  g.x_old = g.x.clone()\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  g.x[mask] = torch.randn_like(g.x[mask])\n",
        "  return g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbvUY6H2xaWb"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples(model, dataset_train, num=100,wild=False):\n",
        "  # Setup\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "    g = dataset_train_start[-1]\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "\n",
        "  # Inference\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    g = overwrite_with_noise(g)\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if wild:\n",
        "        x_with_less_noise = denoise_one_step_wild(model, g, i)\n",
        "      else:\n",
        "        x_with_less_noise = denoise_one_step(model, g, i)\n",
        "      g.x = x_with_less_noise\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    graph_list = [g.cpu() for g in graph_list]\n",
        "\n",
        "    print(\"generated graphs \", graph_list[:10])\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9AAQNu54u5f"
      },
      "source": [
        "#### Frac Correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na5iiitt4w63"
      },
      "outputs": [],
      "source": [
        "def find_frac_correct(graphs):\n",
        "  correct = 0\n",
        "  smiles_list = list()\n",
        "  for i, g in tqdm(list(enumerate(graphs))):\n",
        "    smiles = pyg_to_smiles(g)\n",
        "    if smiles is not None and '.' not in smiles:\n",
        "      mol = Chem.MolFromSmiles(smiles)\n",
        "      if mol is not None:\n",
        "        correct += 1\n",
        "        smiles_list.append((smiles, i))\n",
        "\n",
        "  frac_correct = correct/len(graphs)\n",
        "  unique_frac = len(list(set(smiles_list)))/len(graphs)\n",
        "  return frac_correct, smiles_list, unique_frac"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8BWfguzgy5"
      },
      "source": [
        "### Gen many graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2mkhyZ2xMbc"
      },
      "outputs": [],
      "source": [
        "#!ls aliamol2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeHCO82gziKT"
      },
      "outputs": [],
      "source": [
        "def gen_graphs(num_per_generation=1000, num_generations=40, wild=False, path_pattern=None):\n",
        "  if DEBUG:\n",
        "    num_generations = int(num_generations/10)\n",
        "  if path_pattern is None:\n",
        "    path_pattern = PATH_PATTERN+\"_model_epoch_*.pth\" #\"aliamol_model_epoch_*.pth\"\n",
        "  path = sorted(glob.glob(path_pattern))[-1]\n",
        "  num_samples = num_per_generation*num_generations\n",
        "  filepath = path.replace(\".pth\", f'_{num_samples:06d}_w{wild}_generated.pickle')\n",
        "\n",
        "  results = list()\n",
        "  try:\n",
        "    results = load_file(filepath)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  if len(results) == num_per_generation*num_generations:\n",
        "    return results\n",
        "\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  scatter_list = list()\n",
        "  model_base = load_base_model(dataset_base, path_pattern = path)\n",
        "\n",
        "  i = 0\n",
        "  while len(results) < num_samples:\n",
        "    i += 1\n",
        "    num = max(num_per_generation, len(results) - num_samples)\n",
        "    graphs = generate_examples(model_base, dataset_base, num=num, wild=wild)\n",
        "    results = results + graphs\n",
        "    if i % 5 == 0 or len(results) >= num_samples:\n",
        "      write_file(filepath, results)\n",
        "\n",
        "  assert(len(results) == num_per_generation*num_generations)\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "def test_graph_generation(path_pattern=None, wild=False):\n",
        "  generated_graphs = gen_graphs(wild=wild, path_pattern=path_pattern)\n",
        "  return find_frac_correct(generated_graphs) #0.54 #0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0p9ss6BJ_UM"
      },
      "outputs": [],
      "source": [
        "#test_graph_generation(path_pattern=\"aliamol_model_epoch_00003901.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dJOf1G5O0K"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEo07bzN4bAP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfJgXwe15QG4"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "\n",
        "\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=HIDDEN_CHANNELS_DISC, depth=DEPTH_DISC, dropout=DROPOUT_DISC, towers=1, normalization=NORMALIZATION_DISC, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM\n",
        "    assert in_channels == 11\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    deg = deg.to(DEVICE)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=1, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "    #self.pnanet = PNA(in_channels=11, hidden_channels=hidden_channels, out_channels=1, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "    #self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch=None):\n",
        "    #print(\"before: x.shape\",x.shape, \"edge_index.shape\",edge_index.shape)\n",
        "    x = x + torch.randn_like(x)*DISC_NOISE\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    #print(\"after: x.shape\",x.shape, \"edge_index.shape\",edge_index.shape)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    #x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91xp2SGvGTSU"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer):\n",
        "  model_disc.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    #print(\"batch.x, batch.edge_index, batch.batch\", batch, batch.x, batch.edge_index, batch.batch)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    #print(\"pred \",pred, \"y \", batch.y)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZcRLtjSKIfA"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader):\n",
        "  model_disc.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaC-s2FMJkPq"
      },
      "outputs": [],
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc)\n",
        "  model_disc = model_disc.to(DEVICE)\n",
        "  weight_path = f\"discriminator_model_{round_i:05}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:05}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 1 or epoch_i == EPOCHS_DISC_MODEL-1:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      #print(loss_train,loss_test,acc_train,acc_test,t_train)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:01.3f}\")\n",
        "      log({\"disc/step\": epoch_i, \"disc/epoch\": epoch_i, \"disc/loss_train\": loss_train, 'disc/loss_test': loss_test, \"disc/acc_trian\": acc_train, \"disc/acc_trian\": acc_test, \"disc/time\": t_train})\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"discriminator_model_{round_i:05}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_disc.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH85qTaDKkF7"
      },
      "outputs": [],
      "source": [
        "def run_disc(round_i=1):\n",
        "  fake_graphs = gen_graphs(wild=False)\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  real_graphs = random.sample(dataset_base, len(fake_graphs))\n",
        "  dataset = list()\n",
        "\n",
        "  for g in fake_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(0.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  for g in real_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(1.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  random.shuffle(dataset)\n",
        "  cut_off = int(len(dataset) * 0.8)\n",
        "  dataloader_train = DataLoader(dataset[:cut_off], batch_size = BATCH_SIZE, shuffle=True)\n",
        "  dataloader_test = DataLoader(dataset[cut_off:], batch_size = BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  model_disc = train_disc_model(dataloader_train, dataloader_test, round_i)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLHpXu-W6GbJ"
      },
      "outputs": [],
      "source": [
        "#model_disc = run_disc() #0000390 is the last good one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF7pU0QnPQMb"
      },
      "source": [
        "# Forward Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQ5kwb5PTkC",
        "outputId": "721f64b0-79d3-4fd0-8917-3abf77a4bf06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((tensor([[1.0018],\n",
              "          [2.0140],\n",
              "          [1.3912]], device='cuda:0'),\n",
              "  tensor([[0.1831],\n",
              "          [1.4092],\n",
              "          [1.3241]], device='cuda:0')),\n",
              " None,\n",
              " (tensor([[-1.3671],\n",
              "          [-0.0480],\n",
              "          [ 1.1922]], device='cuda:0'),\n",
              "  tensor([[-1.3899],\n",
              "          [-0.0931],\n",
              "          [ 1.1250]], device='cuda:0')))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "\n",
        "  if \"class 'int'\" in str(type(future_t)) or \"class 'float'\" in str(type(future_t)):\n",
        "    future_t = torch.tensor([int(future_t)] * row_num).to(DEVICE)\n",
        "\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "  assert(future_t[0] == future_t[1]) #lets assume the belong to the same graph\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # column-wise multiplication, now matrix #todo but we want row wise #.view(row_num,1)\n",
        "  assert(new_node_features_mean.shape == node_features.shape)\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) #this is a col vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) #this is a matrix\n",
        "  assert(new_node_features_mean.shape == new_node_features_std.shape)\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihPbotsmRafu"
      },
      "source": [
        "# Train Jointly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG8AOy2CfG8F"
      },
      "outputs": [],
      "source": [
        "def get_pred_from_noise(noise_pred, x_with_noise, future_t):\n",
        "\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(1.0-alphabar_t)\n",
        "  x_without_noise = x_with_noise - scaled_noise*noise_pred\n",
        "  x_without_noise = x_without_noise/torch.sqrt(alphabar_t)\n",
        "  return x_without_noise\n",
        "\n",
        "\n",
        "def get_noise_from_pred(original_pred, x_with_noise, future_t):\n",
        "\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(alphabar_t)\n",
        "  noise = x_with_noise - scaled_noise*original_pred\n",
        "  noise = noise / torch.sqrt(1.0-alphabar_t)\n",
        "\n",
        "  return noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBBNjxFxRZef"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, model_disc=None):\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  loss_list_start = list()\n",
        "  loss_row = nn.MSELoss(reduction='none')\n",
        "\n",
        "  for batch in tqdm(dataloader): #todo batches deactivated\n",
        "    if batch.x.shape[0] < 2:\n",
        "      continue\n",
        "    optimizer.zero_grad()\n",
        "    batch.to(DEVICE)\n",
        "    row_num = batch.x.shape[0]\n",
        "\n",
        "    num_graphs_in_batch = int(torch.max(batch.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, batch.batch)\n",
        "    assert(future_t.numel() == row_num)\n",
        "\n",
        "    mask = torch.concat((torch.tensor([False]*row_num, device=DEVICE).view(-1,1), batch.x[:,1:]>-0.5), dim=1) #this only works on original values\n",
        "    x_start_gt = batch.x[mask].view(row_num, FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x_start_gt, future_t)\n",
        "\n",
        "    x_in = batch.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    x_start_pred = model(x_in, future_t, batch.edge_index)\n",
        "    loss = F.mse_loss(x_start_gt, x_start_pred)\n",
        "\n",
        "\n",
        "    #row_num = x_in.shape[0]\n",
        "    #assert(x_with_noise.shape[0] == row_num)\n",
        "   # assert(noise_pred.shape[0] == row_num)\n",
        "    #assert(noise_pred.shape == x_with_noise.shape)\n",
        "    #assert(noise_pred.shape == noise_gt.shape)\n",
        "    #assert(noise_pred.shape == x_start_gt.shape)\n",
        "    #x_start_pred = get_pred_from_noise(noise_pred, x_with_noise, future_t)\n",
        "\n",
        "    #assert(F.mse_loss(get_pred_from_noise(noise_gt, x_with_noise, future_t), x_start_gt) < 0.00001)\n",
        "\n",
        "    #loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    #loss_start = F.mse_loss(x_start_gt, x_start_pred)  #multiply with torch.sqrt(1.0-alphabar_t)  #F.mse_loss(x_start_gt, x_start_pred)  # torch.sum(F.mse_loss(x_start_gt, x_start_pred, dim=1)/future_t) #torch.sum(torch.sum((x_start_gt- x_start_pred)**2,dim=1) / (1+future_t.view(-1,1)))\n",
        "    #loss_agg = loss + 0.5*loss_start\n",
        "\n",
        "    #x_in = batch.x.clone()\n",
        "    #x_in[mask] = x_start_pred.flatten()\n",
        "    #disc_loss = torch.abs(1.0- model_disc(x_in, batch.edge_index, batch=batch.batch))\n",
        "    #disc_loss = torch.mean(disc_loss)\n",
        "    #loss_agg = loss + 0.25*disc_loss\n",
        "\n",
        "    disc_loss = torch.tensor(0.0, device=DEVICE)\n",
        "    if model_disc is not None:\n",
        "      x_in[mask] = x_start_pred.flatten()\n",
        "      disc_loss = torch.mean((1.0- model_disc(x_in, batch.edge_index, batch=batch.batch))**2)\n",
        "      loss = (1.0 - GAMMA) * loss + GAMMA*disc_loss\n",
        "\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    loss_list_start.append(disc_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return np.mean(loss_list),np.mean(loss_list_start), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47jE9PU9bVBC"
      },
      "outputs": [],
      "source": [
        "def log_smiles(smiles, filename):\n",
        "  try:\n",
        "    with open(filename, \"w\") as file:\n",
        "      for string in smiles:\n",
        "        file.write(str(string) + \"\\n\")\n",
        "    wandb.log_artifact(filename, name=f\"src_txt_{SWEEP_ID}_{filename}\", type=\"smiles\")\n",
        "    time.sleep(0.01)\n",
        "    visualize_smiles_from_file(filename)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQU6xUvvRf6t"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=EPOCHS_GEN, model_disc=None):\n",
        "  print(\"train base model\")\n",
        "  if DEBUG:\n",
        "    epoch_num = int(epoch_num/10)\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE_GEN*0.01) #ok makes no sense\n",
        "  loss_list = list()\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "  print(\"from\", epoch_start, \"to\", epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    try:\n",
        "      loss, loss_start, time_elapsed = train_epoch(model_base, train_loader, optimizer, model_disc=model_disc)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      if epoch_i % 1 == 0 or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #plot_list(loss_list, \"train_base.png\", title=\"train loss base model\", xlabel='epoch', ylabel='loss')\n",
        "        mean_loss = np.mean([y for x,y in loss_list] + [loss])\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {mean_loss:05.4f} with start loss {loss_start:05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "        log({\"gen/step\": epoch_i, \"gen/epoch\": epoch_i, \"gen/loss\": loss, \"gen/mean_loss\": mean_loss, \"gen/start_loss\": loss_start, \"gen/runtime\": time_elapsed})\n",
        "\n",
        "      if (epoch_i % 20 == 0 and epoch_i > epoch_start) or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "        #graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "        #print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "        #plot_base(graph_loss_list, loss_list)\n",
        "        #pass\n",
        "        print(\"save\")\n",
        "        save_model(model_base, optimizer, loss_list, epoch_i+1, upload=epoch_i % 100 == 0 and epoch_i>9) #todo really +1?\n",
        "        time.sleep(0.1)\n",
        "        frac, smiles_list, unique_frac = test_graph_generation(wild=False)\n",
        "        frac_wild, smiles_list_wild, unique_frac_wild = test_graph_generation(wild=True)\n",
        "        print(\"frac correct graphs: \", frac, \"with wild inference\", frac_wild)\n",
        "        log({\"inference/step\": epoch_i, \"inference/epoch\": epoch_i, \"inference/frac_normal\": frac, \"inference/frac_wild\": frac_wild, \"inference/frac_normal_unique\": unique_frac, \"inference/frac_wild_unique\": unique_frac_wild})\n",
        "        log_smiles(smiles_list, f\"{PATH_PATTERN}_smiles_{epoch_i}_normal.txt\")\n",
        "        log_smiles(smiles_list_wild, f\"{PATH_PATTERN}_smiles_{epoch_i}_wild.txt\")\n",
        "        try:\n",
        "          print(smiles_list[:20])\n",
        "          print(smiles_list_wild[:20])\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          pass\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBLiBcZLRokF"
      },
      "outputs": [],
      "source": [
        "def start_experiments(rounds=5):\n",
        "  global DISC_NOISE\n",
        "  print(\"DISC_NOISE\", DISC_NOISE)\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*1)\n",
        "\n",
        "  for round_i in range(1, rounds):\n",
        "    if BASELINE:\n",
        "      model_disc = None\n",
        "    else:\n",
        "      model_disc = run_disc(round_i=round_i)\n",
        "    model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*(round_i+1), model_disc=model_disc)\n",
        "\n",
        "  save_src_file()\n",
        "  return  model_base\n",
        "\n",
        "\n",
        "#0000390 is the last good one\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFXyZBfWMfxo"
      },
      "outputs": [],
      "source": [
        "#!rm aliamol_model_epoch_00004001_010000_generated.pickle aliamol_model_epoch_00004001.pth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpKbb3ArSqg0"
      },
      "source": [
        "### With WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "719HFLnH3Eqm",
        "outputId": "1f6e747b-8222-4bb6-b5e2-0a9351f4d568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/usr/local/lib/python3.10/dist-packages/wandb']\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "print(wandb.__path__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF6EmzdCYJSZ"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"AliaMol\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"ENZYMES/besttest_acc\",\n",
        "        \"goal\": \"maximize\",\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"BATCH_SIZE\": {\"values\": [128*2]},\n",
        "        \"GAMMA\": {\"values\": [0.1]},\n",
        "        \"DISC_NOISE\": {\"values\": [0.3]},\n",
        "        \"EPOCHS_DISC_MODEL\": {\"values\": [100]},\n",
        "        \"EPOCHS_GEN\": {\"values\": [100]},\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkqiydqAtMx7"
      },
      "outputs": [],
      "source": [
        "def save_src_file():\n",
        "  os.system(\"pip list > pip_list.txt 2>&1\")\n",
        "  for txt_file in sorted(glob.glob('*.txt')):\n",
        "    z = \"\".join(filter(str.isalnum, txt_file))\n",
        "    wandb.log_artifact(txt_file, name=f\"src_txt_{SWEEP_ID}_{z}\", type=\"my_dataset_txt\")\n",
        "  for python_file in sorted(glob.glob('*.ipynb')):\n",
        "    z = \"\".join(filter(str.isalnum, python_file))\n",
        "    wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}_{z}\", type=\"my_dataset_ipynb\")\n",
        "  for python_file in sorted(glob.glob('*.py')):\n",
        "    z = \"\".join(filter(str.isalnum, python_file))\n",
        "    wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}_{z}\", type=\"my_dataset_py\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgG12j-1yQ3X"
      },
      "outputs": [],
      "source": [
        "#! cp ../Insa/api_key.txt api_key.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoYB0l4fwBUT"
      },
      "outputs": [],
      "source": [
        "#os.system('wandb login --relogin --host=https://api.wandb.ai --key='+get_wand_api_key())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJDIzKzmtQUJ"
      },
      "outputs": [],
      "source": [
        "def get_wand_api_key():\n",
        "  import sys\n",
        "  IN_COLAB = 'google.colab' in sys.modules\n",
        "  if not IN_COLAB:\n",
        "    os.system(\"cp ~/api_key.txt api_key.txt\")\n",
        "  file_path = 'api_key.txt'\n",
        "  with open(file_path, 'r') as file:\n",
        "      api_key = file.read().strip()\n",
        "  return api_key\n",
        "\n",
        "#wandb.login(key=get_wand_api_key())\n",
        "\n",
        "def main():\n",
        "  global PATH_PATTERN\n",
        "  with wandb.init() as run:\n",
        "    run_id = 0\n",
        "    try:\n",
        "      run_id = load_file(\"runs.pickle\") + 1\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    PATH_PATTERN = PATH_PATTERN_BASE + '_' +str(run_id) + '_' +str(BASELINE)\n",
        "    save_src_file()\n",
        "    for hyper_param_name in sweep_config['parameters']:\n",
        "      globals()[hyper_param_name] = run.config[hyper_param_name]\n",
        "      print(\"set \", hyper_param_name, \"=\", run.config[hyper_param_name])\n",
        "    start_experiments()\n",
        "    write_file(\"runs.pickle\", run_id)\n",
        "\n",
        "def start_with_wandb(set_baseline_true=False):\n",
        "  import wandb\n",
        "  global SWEEP_ID, USE_WANDB, PATH_PATTERN, BASELINE\n",
        "  if set_baseline_true:\n",
        "    BASELINE = True\n",
        "  else:\n",
        "    BASELINE = False\n",
        "  USE_WANDB = True\n",
        "  os.environ[\"WANDB_MODE\"] = \"online\"\n",
        "  try:\n",
        "    SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "    wandb.agent(SWEEP_ID, function=main, count=5)\n",
        "  except Exception as e:\n",
        "    error_message = traceback.format_exc()\n",
        "    print(\"final error:\\n\", error_message)\n",
        "    with open('_error_log.txt', 'a') as f:\n",
        "      f.write(error_message + '\\n')\n",
        "    time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cxnsmGC7yLGX",
        "outputId": "877732ee-b8be-4c76-89ac-b08c7b7f4348"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: yyxpv29n\n",
            "Sweep URL: https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pto40o2f with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgerritgr\u001b[0m (\u001b[33mnextaid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculePaperColab5/wandb/run-20231025_133709-pto40o2f</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/pto40o2f' target=\"_blank\">eager-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/pto40o2f' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/pto40o2f</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  runs.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'runs.pickle'\n",
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.3\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "DISC_NOISE 0.3\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 10 to 10\n",
            "try to read  aliamol_paper_0_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00001\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 20 to 20\n",
            "try to read  aliamol_paper_0_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00002\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 30 to 30\n",
            "try to read  aliamol_paper_0_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train discriminator: epoch: 00001, loss: 0.6895, loss test: 0.6884, acc: 0.524, acc test: 0.499, time: 0.964\n",
            "train discriminator: epoch: 00011, loss: 0.0868, loss test: 0.0780, acc: 0.998, acc test: 1.000, time: 0.965\n",
            "train discriminator: epoch: 00021, loss: 0.0200, loss test: 0.0198, acc: 1.000, acc test: 1.000, time: 0.985\n",
            "train discriminator: epoch: 00031, loss: 0.0092, loss test: 0.0079, acc: 1.000, acc test: 1.000, time: 0.965\n",
            "train discriminator: epoch: 00041, loss: 0.0052, loss test: 0.0036, acc: 1.000, acc test: 1.000, time: 1.002\n",
            "train discriminator: epoch: 00051, loss: 0.0031, loss test: 0.0023, acc: 1.000, acc test: 1.000, time: 0.974\n",
            "train discriminator: epoch: 00061, loss: 0.0026, loss test: 0.0018, acc: 1.000, acc test: 1.000, time: 0.985\n",
            "train discriminator: epoch: 00071, loss: 0.0016, loss test: 0.0011, acc: 1.000, acc test: 1.000, time: 0.958\n",
            "train discriminator: epoch: 00081, loss: 0.0018, loss test: 0.0010, acc: 1.000, acc test: 1.000, time: 0.956\n",
            "train discriminator: epoch: 00091, loss: 0.0009, loss test: 0.0009, acc: 1.000, acc test: 1.000, time: 0.965\n",
            "train discriminator: epoch: 00099, loss: 0.0009, loss test: 0.0006, acc: 1.000, acc test: 1.000, time: 1.005\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 30 to 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.1774 with mean loss 0.1781 with start loss 0.9992 with runtime 3.6728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.1774 with mean loss 0.1781 with start loss 0.9992 with runtime 3.4019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.1773 with mean loss 0.1781 with start loss 0.9993 with runtime 3.3436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.1773 with mean loss 0.1781 with start loss 0.9992 with runtime 3.4380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.1772 with mean loss 0.1780 with start loss 0.9991 with runtime 3.4549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.1772 with mean loss 0.1780 with start loss 0.9992 with runtime 3.3671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.1772 with mean loss 0.1780 with start loss 0.9993 with runtime 3.3661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.1771 with mean loss 0.1780 with start loss 0.9992 with runtime 3.4170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.1770 with mean loss 0.1779 with start loss 0.9992 with runtime 3.5373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.1768 with mean loss 0.1779 with start loss 0.9990 with runtime 3.3401\n",
            "save\n",
            "try to read  aliamol_paper_0_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_0_False_model_epoch_00000040_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137972], x=[43297, 11], batch=[43297], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137876], x=[43273, 11], batch=[43273], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137536], x=[43177, 11], batch=[43177], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137624], x=[43199, 11], batch=[43199], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_0_False_model_epoch_00000040_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 260.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_0_False_model_epoch_00000040_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_0_False_model_epoch_00000040_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137928], x=[43287, 11], batch=[43287], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136824], x=[42972, 11], batch=[42972], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 18.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137240], x=[43092, 11], batch=[43092], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 18.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137976], x=[43297, 11], batch=[43297], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 17.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_0_False_model_epoch_00000040_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 262.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_0_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "train discriminator: epoch: 00001, loss: 0.7154, loss test: 0.7382, acc: 0.500, acc test: 0.499, time: 1.018\n",
            "train discriminator: epoch: 00011, loss: 0.1486, loss test: 0.1250, acc: 0.999, acc test: 0.999, time: 0.999\n",
            "train discriminator: epoch: 00021, loss: 0.0358, loss test: 0.0319, acc: 0.999, acc test: 1.000, time: 1.016\n",
            "train discriminator: epoch: 00031, loss: 0.0146, loss test: 0.0137, acc: 0.999, acc test: 0.999, time: 1.003\n",
            "train discriminator: epoch: 00041, loss: 0.0082, loss test: 0.0065, acc: 1.000, acc test: 1.000, time: 0.988\n",
            "train discriminator: epoch: 00051, loss: 0.0053, loss test: 0.0039, acc: 1.000, acc test: 1.000, time: 0.974\n",
            "train discriminator: epoch: 00061, loss: 0.0037, loss test: 0.0027, acc: 1.000, acc test: 1.000, time: 0.991\n",
            "train discriminator: epoch: 00071, loss: 0.0024, loss test: 0.0018, acc: 1.000, acc test: 1.000, time: 0.990\n",
            "train discriminator: epoch: 00081, loss: 0.0016, loss test: 0.0016, acc: 1.000, acc test: 1.000, time: 1.011\n",
            "train discriminator: epoch: 00091, loss: 0.0013, loss test: 0.0019, acc: 1.000, acc test: 0.999, time: 0.988\n",
            "train discriminator: epoch: 00099, loss: 0.0012, loss test: 0.0008, acc: 1.000, acc test: 1.000, time: 1.003\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "from 40 to 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.1765 with mean loss 0.1779 with start loss 0.9972 with runtime 3.4575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.1763 with mean loss 0.1778 with start loss 0.9972 with runtime 3.4806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.1761 with mean loss 0.1778 with start loss 0.9972 with runtime 3.4499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.1759 with mean loss 0.1777 with start loss 0.9972 with runtime 3.6302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 10.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.1754 with mean loss 0.1777 with start loss 0.9971 with runtime 3.8893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:04<00:00, 10.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.1750 with mean loss 0.1776 with start loss 0.9971 with runtime 4.0434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:04<00:00, 10.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.1745 with mean loss 0.1775 with start loss 0.9972 with runtime 4.0401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:04<00:00, 10.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.1743 with mean loss 0.1775 with start loss 0.9966 with runtime 4.0874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:04<00:00, 10.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.1737 with mean loss 0.1774 with start loss 0.9963 with runtime 4.1288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 10.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.1732 with mean loss 0.1773 with start loss 0.9958 with runtime 3.8915\n",
            "save\n",
            "try to read  aliamol_paper_0_False_model_epoch_00000050_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_0_False_model_epoch_00000050_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137716], x=[43228, 11], batch=[43228], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138244], x=[43375, 11], batch=[43375], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136584], x=[42902, 11], batch=[42902], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137616], x=[43199, 11], batch=[43199], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamol_paper_0_False_model_epoch_00000050_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:16<00:00, 246.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_0_False_model_epoch_00000050_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_0_False_model_epoch_00000050_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137608], x=[43197, 11], batch=[43197], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138388], x=[43417, 11], batch=[43417], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138080], x=[43329, 11], batch=[43329], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137592], x=[43192, 11], batch=[43192], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_0_False_model_epoch_00000050_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 253.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to write  runs.pickle\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>disc/acc_trian</td><td>▁██████████▁██████████</td></tr><tr><td>disc/epoch</td><td>▁▂▂▃▄▅▅▆▇▇█▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>disc/loss_test</td><td>█▂▁▁▁▁▁▁▁▁▁█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>disc/loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>disc/step</td><td>▁▂▂▃▄▅▅▆▇▇█▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>disc/time</td><td>▂▂▄▂▆▃▄▁▁▂▇█▆█▆▅▃▅▅▇▅▆</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▇▇▇███</td></tr><tr><td>frac_normal</td><td>▁▁</td></tr><tr><td>frac_normal_unique</td><td>▁▁</td></tr><tr><td>frac_wild</td><td>▁▁</td></tr><tr><td>frac_wild_unique</td><td>▁▁</td></tr><tr><td>loss</td><td>████████▇▇▆▆▆▅▅▄▃▃▂▁</td></tr><tr><td>mean_loss</td><td>███▇▇▇▇▇▆▆▆▅▅▅▄▄▃▂▂▁</td></tr><tr><td>runtime</td><td>▄▂▁▂▂▁▁▂▃▁▂▂▂▄▆▇▇██▆</td></tr><tr><td>start_loss</td><td>█████████▇▄▄▄▄▄▄▄▃▂▁</td></tr><tr><td>step</td><td>▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>disc/acc_trian</td><td>1.0</td></tr><tr><td>disc/epoch</td><td>99</td></tr><tr><td>disc/loss_test</td><td>0.00084</td></tr><tr><td>disc/loss_train</td><td>0.00119</td></tr><tr><td>disc/step</td><td>99</td></tr><tr><td>disc/time</td><td>1.00329</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>frac_normal</td><td>0.0</td></tr><tr><td>frac_normal_unique</td><td>0.0</td></tr><tr><td>frac_wild</td><td>0.0</td></tr><tr><td>frac_wild_unique</td><td>0.0</td></tr><tr><td>loss</td><td>0.17316</td></tr><tr><td>mean_loss</td><td>0.17729</td></tr><tr><td>runtime</td><td>3.89154</td></tr><tr><td>start_loss</td><td>0.9958</td></tr><tr><td>step</td><td>49</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eager-sweep-1</strong> at: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/pto40o2f' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/pto40o2f</a><br/>Synced 5 W&B file(s), 0 media file(s), 21 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231025_133709-pto40o2f/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mxln8jb6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculePaperColab5/wandb/run-20231025_140318-mxln8jb6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/mxln8jb6' target=\"_blank\">upbeat-sweep-2</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/mxln8jb6' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/mxln8jb6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  runs.pickle\n",
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.3\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "DISC_NOISE 0.3\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.1768 with mean loss 0.1768 with start loss 0.0000 with runtime 2.4596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.1687 with mean loss 0.1714 with start loss 0.0000 with runtime 2.3936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.1593 with mean loss 0.1661 with start loss 0.0000 with runtime 2.2994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.1487 with mean loss 0.1605 with start loss 0.0000 with runtime 2.3030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.1389 with mean loss 0.1552 with start loss 0.0000 with runtime 2.2644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.1282 with mean loss 0.1498 with start loss 0.0000 with runtime 2.3634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.1172 with mean loss 0.1444 with start loss 0.0000 with runtime 2.4240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.1071 with mean loss 0.1391 with start loss 0.0000 with runtime 2.2782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.0992 with mean loss 0.1343 with start loss 0.0000 with runtime 2.2281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.0938 with mean loss 0.1302 with start loss 0.0000 with runtime 2.2859\n",
            "save\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138124], x=[43342, 11], batch=[43342], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137496], x=[43166, 11], batch=[43166], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137212], x=[43083, 11], batch=[43083], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138616], x=[43480, 11], batch=[43480], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:59<00:00, 16.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000010_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:16<00:00, 235.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_1_False_model_epoch_00000010_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000010_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137272], x=[43100, 11], batch=[43100], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137712], x=[43224, 11], batch=[43224], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138372], x=[43413, 11], batch=[43413], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137412], x=[43142, 11], batch=[43142], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000010_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:16<00:00, 245.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00001\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "from 10 to 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.1096 with mean loss 0.1298 with start loss 0.2810 with runtime 3.5514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.1074 with mean loss 0.1279 with start loss 0.2759 with runtime 3.5601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.1061 with mean loss 0.1262 with start loss 0.2735 with runtime 3.5287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.1053 with mean loss 0.1248 with start loss 0.2707 with runtime 3.4967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.1048 with mean loss 0.1235 with start loss 0.2679 with runtime 3.4546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.1042 with mean loss 0.1223 with start loss 0.2637 with runtime 3.5271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.1041 with mean loss 0.1213 with start loss 0.2637 with runtime 3.5004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.1039 with mean loss 0.1204 with start loss 0.2623 with runtime 3.4509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.1040 with mean loss 0.1196 with start loss 0.2640 with runtime 3.4745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.1039 with mean loss 0.1188 with start loss 0.2631 with runtime 3.5086\n",
            "save\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000020_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138344], x=[43406, 11], batch=[43406], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137856], x=[43262, 11], batch=[43262], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137336], x=[43119, 11], batch=[43119], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137376], x=[43129, 11], batch=[43129], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000020_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_1_False_model_epoch_00000020_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000020_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137308], x=[43111, 11], batch=[43111], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137772], x=[43238, 11], batch=[43238], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138352], x=[43405, 11], batch=[43405], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137996], x=[43306, 11], batch=[43306], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000020_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 256.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00002\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "from 20 to 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.1233 with mean loss 0.1199 with start loss 0.4583 with runtime 3.5366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000021 is: 0.1228 with mean loss 0.1200 with start loss 0.4548 with runtime 3.5216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000022 is: 0.1226 with mean loss 0.1201 with start loss 0.4533 with runtime 3.4935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000023 is: 0.1225 with mean loss 0.1202 with start loss 0.4521 with runtime 3.3730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000024 is: 0.1224 with mean loss 0.1203 with start loss 0.4514 with runtime 3.3863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000025 is: 0.1227 with mean loss 0.1204 with start loss 0.4550 with runtime 3.5445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000026 is: 0.1224 with mean loss 0.1204 with start loss 0.4522 with runtime 3.4454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000027 is: 0.1226 with mean loss 0.1205 with start loss 0.4542 with runtime 3.4217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000028 is: 0.1226 with mean loss 0.1206 with start loss 0.4538 with runtime 3.3832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000029 is: 0.1226 with mean loss 0.1207 with start loss 0.4541 with runtime 3.5314\n",
            "save\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000030_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138304], x=[43394, 11], batch=[43394], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138480], x=[43442, 11], batch=[43442], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137296], x=[43102, 11], batch=[43102], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137572], x=[43186, 11], batch=[43186], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000030_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 257.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_1_False_model_epoch_00000030_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000030_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136436], x=[42862, 11], batch=[42862], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 17.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137792], x=[43246, 11], batch=[43246], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137760], x=[43237, 11], batch=[43237], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137736], x=[43234, 11], batch=[43234], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000030_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00003\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 30 to 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.1131 with mean loss 0.1201 with start loss 0.3587 with runtime 3.5373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.1130 with mean loss 0.1199 with start loss 0.3578 with runtime 3.4540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.1127 with mean loss 0.1197 with start loss 0.3553 with runtime 3.5225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.1129 with mean loss 0.1195 with start loss 0.3567 with runtime 3.4564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.1127 with mean loss 0.1193 with start loss 0.3547 with runtime 3.4356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.1126 with mean loss 0.1191 with start loss 0.3535 with runtime 3.4349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.1129 with mean loss 0.1190 with start loss 0.3567 with runtime 3.5033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.1124 with mean loss 0.1188 with start loss 0.3510 with runtime 3.4160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.1127 with mean loss 0.1186 with start loss 0.3539 with runtime 3.4448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.1127 with mean loss 0.1185 with start loss 0.3545 with runtime 3.4583\n",
            "save\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000040_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138136], x=[43347, 11], batch=[43347], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137752], x=[43235, 11], batch=[43235], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138468], x=[43438, 11], batch=[43438], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136428], x=[42862, 11], batch=[42862], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000040_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 260.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_1_False_model_epoch_00000040_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000040_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137100], x=[43054, 11], batch=[43054], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138296], x=[43390, 11], batch=[43390], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137616], x=[43197, 11], batch=[43197], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137300], x=[43110, 11], batch=[43110], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000040_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 260.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00004\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "from 40 to 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.1135 with mean loss 0.1184 with start loss 0.3636 with runtime 3.7301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.1132 with mean loss 0.1183 with start loss 0.3636 with runtime 3.4860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.1134 with mean loss 0.1182 with start loss 0.3664 with runtime 3.4033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.1127 with mean loss 0.1180 with start loss 0.3615 with runtime 3.4309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.1126 with mean loss 0.1179 with start loss 0.3624 with runtime 3.5595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.1125 with mean loss 0.1178 with start loss 0.3628 with runtime 3.4145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.1119 with mean loss 0.1176 with start loss 0.3598 with runtime 3.4144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.1121 with mean loss 0.1175 with start loss 0.3637 with runtime 3.4326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.1116 with mean loss 0.1174 with start loss 0.3642 with runtime 3.4148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.1110 with mean loss 0.1173 with start loss 0.3608 with runtime 3.4469\n",
            "save\n",
            "try to read  aliamol_paper_1_False_model_epoch_00000050_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000050_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137508], x=[43165, 11], batch=[43165], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138316], x=[43396, 11], batch=[43396], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137212], x=[43083, 11], batch=[43083], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137500], x=[43162, 11], batch=[43162], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000050_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_1_False_model_epoch_00000050_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_1_False_model_epoch_00000050_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138568], x=[43468, 11], batch=[43468], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138556], x=[43464, 11], batch=[43464], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137988], x=[43304, 11], batch=[43304], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138416], x=[43423, 11], batch=[43423], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_1_False_model_epoch_00000050_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to write  runs.pickle\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>frac_normal</td><td>▁▁▁▁▁</td></tr><tr><td>frac_normal_unique</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild_unique</td><td>▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▂▁▂▂▂▂▁▁▁▁▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>mean_loss</td><td>█▇▇▆▅▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>runtime</td><td>▂▂▁▁▂▂▁▁▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▆▇▇▇▇▇</td></tr><tr><td>start_loss</td><td>▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅████████▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>frac_normal</td><td>0.0</td></tr><tr><td>frac_normal_unique</td><td>0.0</td></tr><tr><td>frac_wild</td><td>0.0</td></tr><tr><td>frac_wild_unique</td><td>0.0</td></tr><tr><td>loss</td><td>0.11095</td></tr><tr><td>mean_loss</td><td>0.11727</td></tr><tr><td>runtime</td><td>3.44694</td></tr><tr><td>start_loss</td><td>0.36079</td></tr><tr><td>step</td><td>49</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">upbeat-sweep-2</strong> at: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/mxln8jb6' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/mxln8jb6</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231025_140318-mxln8jb6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: obda287t with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculePaperColab5/wandb/run-20231025_145514-obda287t</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/obda287t' target=\"_blank\">faithful-sweep-3</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/obda287t' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/obda287t</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  runs.pickle\n",
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.3\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "DISC_NOISE 0.3\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.2234 with mean loss 0.2234 with start loss 0.0000 with runtime 2.3974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.2172 with mean loss 0.2193 with start loss 0.0000 with runtime 2.2343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.2113 with mean loss 0.2158 with start loss 0.0000 with runtime 2.1850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.2045 with mean loss 0.2122 with start loss 0.0000 with runtime 2.2166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.1968 with mean loss 0.2084 with start loss 0.0000 with runtime 2.2059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.1885 with mean loss 0.2043 with start loss 0.0000 with runtime 2.2291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.1805 with mean loss 0.2003 with start loss 0.0000 with runtime 2.2636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.1721 with mean loss 0.1963 with start loss 0.0000 with runtime 2.2438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.1631 with mean loss 0.1921 with start loss 0.0000 with runtime 2.2023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.1534 with mean loss 0.1877 with start loss 0.0000 with runtime 2.1748\n",
            "save\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137500], x=[43166, 11], batch=[43166], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138180], x=[43359, 11], batch=[43359], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138556], x=[43462, 11], batch=[43462], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137656], x=[43210, 11], batch=[43210], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000010_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 252.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_2_False_model_epoch_00000010_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000010_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137720], x=[43228, 11], batch=[43228], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 17.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137312], x=[43110, 11], batch=[43110], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 17.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137384], x=[43132, 11], batch=[43132], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137388], x=[43133, 11], batch=[43133], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000010_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00001\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "from 10 to 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.1603 with mean loss 0.1860 with start loss 0.3082 with runtime 3.5864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.1502 with mean loss 0.1824 with start loss 0.3033 with runtime 3.5270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.1383 with mean loss 0.1784 with start loss 0.2973 with runtime 3.3991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.1278 with mean loss 0.1744 with start loss 0.2891 with runtime 3.3470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.1185 with mean loss 0.1703 with start loss 0.2820 with runtime 3.4442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.1123 with mean loss 0.1665 with start loss 0.2740 with runtime 3.4849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.1088 with mean loss 0.1631 with start loss 0.2710 with runtime 3.4438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.1064 with mean loss 0.1600 with start loss 0.2661 with runtime 3.3954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.1054 with mean loss 0.1572 with start loss 0.2656 with runtime 3.4799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.1049 with mean loss 0.1547 with start loss 0.2642 with runtime 3.4149\n",
            "save\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000020_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138664], x=[43496, 11], batch=[43496], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137832], x=[43259, 11], batch=[43259], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137676], x=[43214, 11], batch=[43214], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137320], x=[43115, 11], batch=[43115], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000020_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 253.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_2_False_model_epoch_00000020_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000020_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137256], x=[43096, 11], batch=[43096], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138240], x=[43375, 11], batch=[43375], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137116], x=[43057, 11], batch=[43057], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137252], x=[43095, 11], batch=[43095], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000020_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 256.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00002\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "from 20 to 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.1234 with mean loss 0.1541 with start loss 0.4538 with runtime 3.5463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000021 is: 0.1230 with mean loss 0.1527 with start loss 0.4524 with runtime 3.5969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000022 is: 0.1229 with mean loss 0.1515 with start loss 0.4526 with runtime 3.3700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000023 is: 0.1228 with mean loss 0.1503 with start loss 0.4519 with runtime 3.3856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000024 is: 0.1230 with mean loss 0.1493 with start loss 0.4548 with runtime 3.4562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000025 is: 0.1226 with mean loss 0.1483 with start loss 0.4517 with runtime 3.5190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000026 is: 0.1230 with mean loss 0.1474 with start loss 0.4559 with runtime 3.3801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000027 is: 0.1230 with mean loss 0.1466 with start loss 0.4562 with runtime 3.4011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000028 is: 0.1228 with mean loss 0.1458 with start loss 0.4543 with runtime 3.4789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000029 is: 0.1227 with mean loss 0.1450 with start loss 0.4542 with runtime 3.5280\n",
            "save\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000030_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137672], x=[43212, 11], batch=[43212], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138116], x=[43340, 11], batch=[43340], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137888], x=[43273, 11], batch=[43273], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138424], x=[43428, 11], batch=[43428], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000030_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_2_False_model_epoch_00000030_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000030_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138084], x=[43331, 11], batch=[43331], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136896], x=[42995, 11], batch=[42995], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137652], x=[43207, 11], batch=[43207], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137172], x=[43069, 11], batch=[43069], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 17.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000030_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 263.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-a8b9fb38318c>:20: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, axs = plt.subplots(rows, cols, figsize=(20, 20),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00003\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 30 to 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.1128 with mean loss 0.1437 with start loss 0.3551 with runtime 3.5815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.1127 with mean loss 0.1428 with start loss 0.3547 with runtime 3.5157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.1130 with mean loss 0.1419 with start loss 0.3567 with runtime 3.6157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.1128 with mean loss 0.1411 with start loss 0.3555 with runtime 3.4259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.1126 with mean loss 0.1403 with start loss 0.3528 with runtime 3.4845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.1124 with mean loss 0.1395 with start loss 0.3506 with runtime 3.6485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.1124 with mean loss 0.1388 with start loss 0.3510 with runtime 3.5499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.1128 with mean loss 0.1381 with start loss 0.3550 with runtime 3.4048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.1126 with mean loss 0.1375 with start loss 0.3533 with runtime 3.4342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.1129 with mean loss 0.1369 with start loss 0.3555 with runtime 3.5812\n",
            "save\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000040_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138428], x=[43429, 11], batch=[43429], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136888], x=[42992, 11], batch=[42992], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137832], x=[43258, 11], batch=[43258], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137312], x=[43110, 11], batch=[43110], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000040_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_2_False_model_epoch_00000040_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000040_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137556], x=[43183, 11], batch=[43183], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138360], x=[43408, 11], batch=[43408], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136460], x=[42871, 11], batch=[42871], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137688], x=[43219, 11], batch=[43219], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000040_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 257.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00004\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "from 40 to 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.1137 with mean loss 0.1364 with start loss 0.3645 with runtime 3.7175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.1136 with mean loss 0.1358 with start loss 0.3635 with runtime 3.6355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.1135 with mean loss 0.1353 with start loss 0.3624 with runtime 3.6923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.1137 with mean loss 0.1348 with start loss 0.3644 with runtime 3.6640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.1138 with mean loss 0.1344 with start loss 0.3658 with runtime 3.6053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.1135 with mean loss 0.1339 with start loss 0.3626 with runtime 3.5089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.1133 with mean loss 0.1335 with start loss 0.3610 with runtime 3.5851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.1134 with mean loss 0.1331 with start loss 0.3615 with runtime 3.5433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.1135 with mean loss 0.1327 with start loss 0.3633 with runtime 3.5899\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.1134 with mean loss 0.1323 with start loss 0.3615 with runtime 3.5391\n",
            "save\n",
            "try to read  aliamol_paper_2_False_model_epoch_00000050_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000050_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137696], x=[43221, 11], batch=[43221], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138284], x=[43387, 11], batch=[43387], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137584], x=[43186, 11], batch=[43186], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137500], x=[43167, 11], batch=[43167], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000050_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 251.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_2_False_model_epoch_00000050_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_2_False_model_epoch_00000050_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138024], x=[43314, 11], batch=[43314], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137776], x=[43243, 11], batch=[43243], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137328], x=[43117, 11], batch=[43117], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137448], x=[43150, 11], batch=[43150], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_2_False_model_epoch_00000050_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 256.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to write  runs.pickle\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>frac_normal</td><td>▁▁▁▁▁</td></tr><tr><td>frac_normal_unique</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild_unique</td><td>▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▇▇▆▅▅▄▄▄▃▂▁▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_loss</td><td>██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>runtime</td><td>▂▁▁▁▁▁▁▁▇▇▇▆▇▇▇▇▇▇▆▆▇▆▇▇▇▇█▇█▇▇▇████▇▇▇▇</td></tr><tr><td>start_loss</td><td>▁▁▁▁▁▁▁▁▆▆▆▅▅▅▅▅████████▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>frac_normal</td><td>0.0</td></tr><tr><td>frac_normal_unique</td><td>0.0</td></tr><tr><td>frac_wild</td><td>0.0</td></tr><tr><td>frac_wild_unique</td><td>0.0</td></tr><tr><td>loss</td><td>0.11336</td></tr><tr><td>mean_loss</td><td>0.13233</td></tr><tr><td>runtime</td><td>3.53905</td></tr><tr><td>start_loss</td><td>0.36151</td></tr><tr><td>step</td><td>49</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">faithful-sweep-3</strong> at: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/obda287t' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/obda287t</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231025_145514-obda287t/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ptfz4pt7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculePaperColab5/wandb/run-20231025_154709-ptfz4pt7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/ptfz4pt7' target=\"_blank\">clear-sweep-4</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/ptfz4pt7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/ptfz4pt7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  runs.pickle\n",
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.3\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "DISC_NOISE 0.3\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.2160 with mean loss 0.2160 with start loss 0.0000 with runtime 2.3812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.2113 with mean loss 0.2129 with start loss 0.0000 with runtime 2.2462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.2066 with mean loss 0.2101 with start loss 0.0000 with runtime 2.2127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.2014 with mean loss 0.2074 with start loss 0.0000 with runtime 2.2934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.1947 with mean loss 0.2041 with start loss 0.0000 with runtime 2.2669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.1840 with mean loss 0.1997 with start loss 0.0000 with runtime 2.2808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.1681 with mean loss 0.1938 with start loss 0.0000 with runtime 2.2916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.1531 with mean loss 0.1876 with start loss 0.0000 with runtime 2.2537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.1401 with mean loss 0.1816 with start loss 0.0000 with runtime 2.2280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.1288 with mean loss 0.1757 with start loss 0.0000 with runtime 2.3084\n",
            "save\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136932], x=[43003, 11], batch=[43003], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137740], x=[43234, 11], batch=[43234], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137452], x=[43153, 11], batch=[43153], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137836], x=[43257, 11], batch=[43257], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000010_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_3_False_model_epoch_00000010_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000010_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137408], x=[43140, 11], batch=[43140], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137036], x=[43034, 11], batch=[43034], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:55<00:00, 17.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138224], x=[43371, 11], batch=[43371], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137828], x=[43257, 11], batch=[43257], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000010_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 261.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00001\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "from 10 to 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.1368 with mean loss 0.1732 with start loss 0.2934 with runtime 3.5605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.1300 with mean loss 0.1693 with start loss 0.2913 with runtime 3.4289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.1245 with mean loss 0.1657 with start loss 0.2895 with runtime 3.5108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.1192 with mean loss 0.1623 with start loss 0.2845 with runtime 3.5284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.1147 with mean loss 0.1590 with start loss 0.2792 with runtime 3.3668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.1119 with mean loss 0.1561 with start loss 0.2805 with runtime 3.3836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.1096 with mean loss 0.1534 with start loss 0.2785 with runtime 3.4285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.1076 with mean loss 0.1509 with start loss 0.2728 with runtime 3.4670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.1067 with mean loss 0.1486 with start loss 0.2719 with runtime 3.3453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.1056 with mean loss 0.1465 with start loss 0.2669 with runtime 3.4482\n",
            "save\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000020_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137900], x=[43279, 11], batch=[43279], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136844], x=[42980, 11], batch=[42980], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137536], x=[43172, 11], batch=[43172], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138204], x=[43365, 11], batch=[43365], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 16.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000020_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:16<00:00, 240.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_3_False_model_epoch_00000020_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000020_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138104], x=[43336, 11], batch=[43336], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138836], x=[43540, 11], batch=[43540], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:59<00:00, 16.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137480], x=[43155, 11], batch=[43155], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137912], x=[43282, 11], batch=[43282], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000020_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:16<00:00, 249.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00002\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "from 20 to 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.1240 with mean loss 0.1463 with start loss 0.4556 with runtime 3.6001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000021 is: 0.1239 with mean loss 0.1453 with start loss 0.4567 with runtime 3.6577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000022 is: 0.1237 with mean loss 0.1444 with start loss 0.4559 with runtime 3.5525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000023 is: 0.1235 with mean loss 0.1436 with start loss 0.4553 with runtime 3.3987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000024 is: 0.1235 with mean loss 0.1428 with start loss 0.4560 with runtime 3.3542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000025 is: 0.1232 with mean loss 0.1421 with start loss 0.4546 with runtime 3.5300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000026 is: 0.1231 with mean loss 0.1414 with start loss 0.4534 with runtime 3.4905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000027 is: 0.1233 with mean loss 0.1408 with start loss 0.4563 with runtime 3.3704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000028 is: 0.1227 with mean loss 0.1401 with start loss 0.4515 with runtime 3.3920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000029 is: 0.1229 with mean loss 0.1396 with start loss 0.4537 with runtime 3.5200\n",
            "save\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000030_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137604], x=[43193, 11], batch=[43193], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137680], x=[43218, 11], batch=[43218], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138176], x=[43356, 11], batch=[43356], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138320], x=[43398, 11], batch=[43398], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000030_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 255.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_3_False_model_epoch_00000030_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000030_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138216], x=[43368, 11], batch=[43368], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137772], x=[43244, 11], batch=[43244], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136020], x=[42748, 11], batch=[42748], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138044], x=[43320, 11], batch=[43320], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 60], x=[21, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000030_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 253.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00003\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 30 to 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.1130 with mean loss 0.1385 with start loss 0.3557 with runtime 3.5346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.1135 with mean loss 0.1377 with start loss 0.3608 with runtime 3.4561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.1133 with mean loss 0.1370 with start loss 0.3588 with runtime 3.5634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.1129 with mean loss 0.1363 with start loss 0.3551 with runtime 3.4369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.1124 with mean loss 0.1356 with start loss 0.3509 with runtime 3.4447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.1124 with mean loss 0.1350 with start loss 0.3509 with runtime 3.4208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.1128 with mean loss 0.1344 with start loss 0.3553 with runtime 3.4332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.1127 with mean loss 0.1339 with start loss 0.3538 with runtime 3.4362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.1124 with mean loss 0.1333 with start loss 0.3514 with runtime 3.4686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.1126 with mean loss 0.1328 with start loss 0.3537 with runtime 3.5280\n",
            "save\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000040_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138068], x=[43328, 11], batch=[43328], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137144], x=[43063, 11], batch=[43063], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137856], x=[43263, 11], batch=[43263], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138084], x=[43330, 11], batch=[43330], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000040_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_3_False_model_epoch_00000040_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000040_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137356], x=[43125, 11], batch=[43125], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137476], x=[43157, 11], batch=[43157], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137428], x=[43143, 11], batch=[43143], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137436], x=[43148, 11], batch=[43148], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000040_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 255.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00004\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "from 40 to 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.1138 with mean loss 0.1324 with start loss 0.3655 with runtime 3.5936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.1137 with mean loss 0.1319 with start loss 0.3641 with runtime 3.4535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.1133 with mean loss 0.1315 with start loss 0.3600 with runtime 3.5830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.1135 with mean loss 0.1311 with start loss 0.3627 with runtime 3.4576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.1133 with mean loss 0.1307 with start loss 0.3608 with runtime 3.4172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.1130 with mean loss 0.1303 with start loss 0.3576 with runtime 3.4613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.1133 with mean loss 0.1300 with start loss 0.3605 with runtime 3.5825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.1137 with mean loss 0.1297 with start loss 0.3648 with runtime 3.5249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.1138 with mean loss 0.1294 with start loss 0.3659 with runtime 3.4472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.1135 with mean loss 0.1290 with start loss 0.3622 with runtime 3.4292\n",
            "save\n",
            "try to read  aliamol_paper_3_False_model_epoch_00000050_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000050_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138780], x=[43528, 11], batch=[43528], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:58<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137748], x=[43237, 11], batch=[43237], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137536], x=[43176, 11], batch=[43176], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137908], x=[43278, 11], batch=[43278], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000050_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 257.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_3_False_model_epoch_00000050_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_3_False_model_epoch_00000050_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138228], x=[43371, 11], batch=[43371], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137344], x=[43120, 11], batch=[43120], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138040], x=[43315, 11], batch=[43315], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137556], x=[43180, 11], batch=[43180], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_3_False_model_epoch_00000050_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to write  runs.pickle\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>frac_normal</td><td>▁▁▁▁▁</td></tr><tr><td>frac_normal_unique</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild_unique</td><td>▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▇▇▆▅▄▃▃▂▂▂▁▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_loss</td><td>███▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>runtime</td><td>▂▁▁▁▁▁▁▁█▇▇▇▇▇▇▆██▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇▇█▇▇</td></tr><tr><td>start_loss</td><td>▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅████████▆▇▇▆▆▆▆▆▇▇▇▇▆▇▇▇</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>frac_normal</td><td>0.0</td></tr><tr><td>frac_normal_unique</td><td>0.0</td></tr><tr><td>frac_wild</td><td>0.0</td></tr><tr><td>frac_wild_unique</td><td>0.0</td></tr><tr><td>loss</td><td>0.11345</td></tr><tr><td>mean_loss</td><td>0.12904</td></tr><tr><td>runtime</td><td>3.42916</td></tr><tr><td>start_loss</td><td>0.36223</td></tr><tr><td>step</td><td>49</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-sweep-4</strong> at: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/ptfz4pt7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/ptfz4pt7</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231025_154709-ptfz4pt7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7xcs3yno with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculePaperColab5/wandb/run-20231025_163927-7xcs3yno</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/7xcs3yno' target=\"_blank\">apricot-sweep-5</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/yyxpv29n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/7xcs3yno' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/7xcs3yno</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  runs.pickle\n",
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.3\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "DISC_NOISE 0.3\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.2558 with mean loss 0.2558 with start loss 0.0000 with runtime 2.2990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.2456 with mean loss 0.2490 with start loss 0.0000 with runtime 2.2086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.2356 with mean loss 0.2432 with start loss 0.0000 with runtime 2.2505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.2255 with mean loss 0.2376 with start loss 0.0000 with runtime 2.2515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.2142 with mean loss 0.2318 with start loss 0.0000 with runtime 2.3076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.2022 with mean loss 0.2259 with start loss 0.0000 with runtime 2.2590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.1902 with mean loss 0.2199 with start loss 0.0000 with runtime 2.2158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.1779 with mean loss 0.2139 with start loss 0.0000 with runtime 2.1796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.1652 with mean loss 0.2077 with start loss 0.0000 with runtime 2.2113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.1526 with mean loss 0.2016 with start loss 0.0000 with runtime 2.2383\n",
            "save\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137676], x=[43214, 11], batch=[43214], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137148], x=[43064, 11], batch=[43064], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138092], x=[43331, 11], batch=[43331], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138040], x=[43318, 11], batch=[43318], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000010_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_4_False_model_epoch_00000010_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000010_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137632], x=[43205, 11], batch=[43205], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138140], x=[43345, 11], batch=[43345], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138044], x=[43318, 11], batch=[43318], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138512], x=[43452, 11], batch=[43452], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000010_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 255.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00001\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "from 10 to 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.1574 with mean loss 0.1983 with start loss 0.3058 with runtime 3.6170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.1482 with mean loss 0.1937 with start loss 0.3030 with runtime 3.5123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.1405 with mean loss 0.1894 with start loss 0.3004 with runtime 3.5072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.1332 with mean loss 0.1852 with start loss 0.2968 with runtime 3.5981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.1263 with mean loss 0.1810 with start loss 0.2919 with runtime 3.4777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.1204 with mean loss 0.1771 with start loss 0.2852 with runtime 3.5055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.1158 with mean loss 0.1735 with start loss 0.2847 with runtime 3.4671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.1119 with mean loss 0.1700 with start loss 0.2783 with runtime 3.5526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.1097 with mean loss 0.1669 with start loss 0.2790 with runtime 3.4520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.1078 with mean loss 0.1640 with start loss 0.2744 with runtime 3.4762\n",
            "save\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000020_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138312], x=[43395, 11], batch=[43395], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137184], x=[43074, 11], batch=[43074], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138300], x=[43391, 11], batch=[43391], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137448], x=[43150, 11], batch=[43150], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000020_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_4_False_model_epoch_00000020_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000020_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137068], x=[43043, 11], batch=[43043], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138000], x=[43306, 11], batch=[43306], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138244], x=[43375, 11], batch=[43375], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137196], x=[43080, 11], batch=[43080], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000020_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:16<00:00, 247.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000020_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00002\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000020 from disc.\n",
            "from 20 to 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.1249 with mean loss 0.1630 with start loss 0.4541 with runtime 3.7125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000021 is: 0.1240 with mean loss 0.1613 with start loss 0.4504 with runtime 3.5716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000022 is: 0.1240 with mean loss 0.1597 with start loss 0.4531 with runtime 3.5619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000023 is: 0.1236 with mean loss 0.1582 with start loss 0.4516 with runtime 3.6694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000024 is: 0.1235 with mean loss 0.1569 with start loss 0.4527 with runtime 3.5836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000025 is: 0.1234 with mean loss 0.1557 with start loss 0.4534 with runtime 3.4430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000026 is: 0.1229 with mean loss 0.1545 with start loss 0.4496 with runtime 3.5069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000027 is: 0.1232 with mean loss 0.1534 with start loss 0.4539 with runtime 3.5726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000028 is: 0.1227 with mean loss 0.1524 with start loss 0.4500 with runtime 3.4427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000029 is: 0.1233 with mean loss 0.1514 with start loss 0.4563 with runtime 3.4324\n",
            "save\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000030_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137996], x=[43303, 11], batch=[43303], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137640], x=[43207, 11], batch=[43207], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138320], x=[43399, 11], batch=[43399], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137620], x=[43199, 11], batch=[43199], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000030_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 253.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_4_False_model_epoch_00000030_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000030_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137856], x=[43265, 11], batch=[43265], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137452], x=[43151, 11], batch=[43151], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137400], x=[43136, 11], batch=[43136], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137368], x=[43127, 11], batch=[43127], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000030_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 259.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000030_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00003\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000030 from disc.\n",
            "from 30 to 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.1131 with mean loss 0.1499 with start loss 0.3558 with runtime 3.5494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.1131 with mean loss 0.1488 with start loss 0.3559 with runtime 3.4437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.1130 with mean loss 0.1478 with start loss 0.3552 with runtime 3.4920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.1129 with mean loss 0.1468 with start loss 0.3546 with runtime 3.5694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.1129 with mean loss 0.1458 with start loss 0.3544 with runtime 3.5108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.1129 with mean loss 0.1449 with start loss 0.3546 with runtime 3.4272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.1126 with mean loss 0.1441 with start loss 0.3518 with runtime 3.5245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.1124 with mean loss 0.1433 with start loss 0.3503 with runtime 3.4184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.1125 with mean loss 0.1425 with start loss 0.3515 with runtime 3.3931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.1129 with mean loss 0.1418 with start loss 0.3548 with runtime 3.4477\n",
            "save\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000040_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137956], x=[43294, 11], batch=[43294], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138208], x=[43365, 11], batch=[43365], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138308], x=[43395, 11], batch=[43395], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136792], x=[42963, 11], batch=[42963], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000040_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 257.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_4_False_model_epoch_00000040_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000040_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137664], x=[43211, 11], batch=[43211], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137752], x=[43237, 11], batch=[43237], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138008], x=[43310, 11], batch=[43310], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138496], x=[43447, 11], batch=[43447], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000040_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 253.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000040_004000_wFalse_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "found disc model in round 00004\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000040 from disc.\n",
            "from 40 to 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.1138 with mean loss 0.1411 with start loss 0.3643 with runtime 3.6760\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.1137 with mean loss 0.1405 with start loss 0.3630 with runtime 3.5583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.1135 with mean loss 0.1399 with start loss 0.3620 with runtime 3.6647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.1136 with mean loss 0.1393 with start loss 0.3623 with runtime 3.6040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.1136 with mean loss 0.1387 with start loss 0.3626 with runtime 3.5690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.1133 with mean loss 0.1382 with start loss 0.3604 with runtime 3.6010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.1136 with mean loss 0.1377 with start loss 0.3635 with runtime 3.5896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.1139 with mean loss 0.1372 with start loss 0.3667 with runtime 3.6158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.1135 with mean loss 0.1367 with start loss 0.3620 with runtime 3.5523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:03<00:00, 11.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.1137 with mean loss 0.1363 with start loss 0.3641 with runtime 3.5713\n",
            "save\n",
            "try to read  aliamol_paper_4_False_model_epoch_00000050_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000050_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137924], x=[43286, 11], batch=[43286], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138068], x=[43323, 11], batch=[43323], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137536], x=[43174, 11], batch=[43174], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138096], x=[43335, 11], batch=[43335], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000050_004000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 258.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamol_paper_4_False_model_epoch_00000050_004000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_4_False_model_epoch_00000050_004000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000050 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136644], x=[42919, 11], batch=[42919], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138520], x=[43455, 11], batch=[43455], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137700], x=[43222, 11], batch=[43222], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138008], x=[43307, 11], batch=[43307], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:56<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_4_False_model_epoch_00000050_004000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:15<00:00, 260.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0 with wild inference 0.0\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[]\n",
            "[]\n",
            "try to write  runs.pickle\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>frac_normal</td><td>▁▁▁▁▁</td></tr><tr><td>frac_normal_unique</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild</td><td>▁▁▁▁▁</td></tr><tr><td>frac_wild_unique</td><td>▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▇▇▅▅▄▄▃▃▂▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_loss</td><td>██▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>runtime</td><td>▂▁▁▁▁▁▁▁█▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇█▇</td></tr><tr><td>start_loss</td><td>▁▁▁▁▁▁▁▁▆▆▆▆▅▅▅▅████████▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>frac_normal</td><td>0.0</td></tr><tr><td>frac_normal_unique</td><td>0.0</td></tr><tr><td>frac_wild</td><td>0.0</td></tr><tr><td>frac_wild_unique</td><td>0.0</td></tr><tr><td>loss</td><td>0.11369</td></tr><tr><td>mean_loss</td><td>0.13627</td></tr><tr><td>runtime</td><td>3.57131</td></tr><tr><td>start_loss</td><td>0.36413</td></tr><tr><td>step</td><td>49</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">apricot-sweep-5</strong> at: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/7xcs3yno' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/7xcs3yno</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231025_163927-7xcs3yno/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: s2yv7a5w\n",
            "Sweep URL: https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/s2yv7a5w\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 29v8mgc7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculePaperColab5/wandb/run-20231025_173145-29v8mgc7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/29v8mgc7' target=\"_blank\">stoic-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/s2yv7a5w' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/s2yv7a5w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/s2yv7a5w' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/sweeps/s2yv7a5w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/29v8mgc7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculePaperColab5/runs/29v8mgc7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  runs.pickle\n",
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.3\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "DISC_NOISE 0.3\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 17.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.2390 with mean loss 0.2390 with start loss 0.0000 with runtime 2.3550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.2279 with mean loss 0.2316 with start loss 0.0000 with runtime 2.2604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.2183 with mean loss 0.2259 with start loss 0.0000 with runtime 2.1889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.2091 with mean loss 0.2207 with start loss 0.0000 with runtime 2.2200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.1998 with mean loss 0.2156 with start loss 0.0000 with runtime 2.2710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.1899 with mean loss 0.2106 with start loss 0.0000 with runtime 2.2390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.1786 with mean loss 0.2051 with start loss 0.0000 with runtime 2.1994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.1666 with mean loss 0.1995 with start loss 0.0000 with runtime 2.1785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.1549 with mean loss 0.1939 with start loss 0.0000 with runtime 2.1448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 19.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.1437 with mean loss 0.1883 with start loss 0.0000 with runtime 2.2078\n",
            "save\n",
            "try to read  aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000010 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137368], x=[43126, 11], batch=[43126], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137920], x=[43283, 11], batch=[43283], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137620], x=[43201, 11], batch=[43201], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:57<00:00, 17.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137828], x=[43259, 11], batch=[43259], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 892/1000 [00:50<00:06, 17.63it/s]--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
            "    resp = self._sock_client.read_server_response(timeout=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 285, in read_server_response\n",
            "    data = self._read_packet_bytes(timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 269, in _read_packet_bytes\n",
            "    raise SockClientClosedError\n",
            "wandb.sdk.lib.sock_client.SockClientClosedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
            "    msg = self._read_message()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
            "    raise MessageRouterClosedError\n",
            "wandb.sdk.interface.router.MessageRouterClosedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 77, in message_loop\n",
            "    logger.warning(\"message_loop has been closed\")\n",
            "Message: 'message_loop has been closed'\n",
            "Arguments: ()\n",
            "100%|██████████| 1000/1000 [00:57<00:00, 17.51it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-35-ec5d9f5c8858>\", line 37, in train_base_model\n",
            "    frac, smiles_list, unique_frac = test_graph_generation(wild=False)\n",
            "  File \"<ipython-input-23-5f41621f67c8>\", line 38, in test_graph_generation\n",
            "    generated_graphs = gen_graphs(wild=wild, path_pattern=path_pattern)\n",
            "  File \"<ipython-input-23-5f41621f67c8>\", line 30, in gen_graphs\n",
            "    write_file(filepath, results)\n",
            "  File \"<ipython-input-9-b33b4216b4e1>\", line 16, in write_file\n",
            "    with gzip.open(filepath, 'wb') as f:\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 58, in open\n",
            "    binary_file = GzipFile(filename, gz_mode, compresslevel)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 174, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 27, in main\n",
            "    start_experiments()\n",
            "  File \"<ipython-input-36-c0489cbdedd2>\", line 6, in start_experiments\n",
            "    model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*1)\n",
            "  File \"<ipython-input-35-ec5d9f5c8858>\", line 54, in train_base_model\n",
            "    raise e\n",
            "  File \"<ipython-input-35-ec5d9f5c8858>\", line 37, in train_base_model\n",
            "    frac, smiles_list, unique_frac = test_graph_generation(wild=False)\n",
            "  File \"<ipython-input-23-5f41621f67c8>\", line 38, in test_graph_generation\n",
            "    generated_graphs = gen_graphs(wild=wild, path_pattern=path_pattern)\n",
            "  File \"<ipython-input-23-5f41621f67c8>\", line 30, in gen_graphs\n",
            "    write_file(filepath, results)\n",
            "  File \"<ipython-input-9-b33b4216b4e1>\", line 16, in write_file\n",
            "    with gzip.open(filepath, 'wb') as f:\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 58, in open\n",
            "    binary_file = GzipFile(filename, gz_mode, compresslevel)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 174, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "Exception in thread Thread-31 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 27, in main\n",
            "  File \"<ipython-input-36-c0489cbdedd2>\", line 6, in start_experiments\n",
            "  File \"<ipython-input-35-ec5d9f5c8858>\", line 54, in train_base_model\n",
            "  File \"<ipython-input-35-ec5d9f5c8858>\", line 37, in train_base_model\n",
            "  File \"<ipython-input-23-5f41621f67c8>\", line 38, in test_graph_generation\n",
            "  File \"<ipython-input-23-5f41621f67c8>\", line 30, in gen_graphs\n",
            "  File \"<ipython-input-9-b33b4216b4e1>\", line 16, in write_file\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 58, in open\n",
            "    binary_file = GzipFile(filename, gz_mode, compresslevel)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 174, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3120, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3852, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 419, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 360, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1925, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle\n",
            "An error occurred during training: \n",
            " [Errno 107] Transport endpoint is not connected: 'aliamol_paper_5_True_model_epoch_00000010_004000_wFalse_generated.pickle'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q0r4yw05 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1198, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-34 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1208, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3852, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 419, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 360, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1925, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Exception in thread IntMsgThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 299, in check_internal_messages\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n",
            "    local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 743, in deliver_internal_messages\n",
            "    return self._deliver_internal_messages(internal_message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 481, in _deliver_internal_messages\n",
            "    return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 428, in _deliver_record\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "    interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xzbl8jvz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1198, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-35 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1208, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3852, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 419, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 360, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1925, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gn6to71o with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1198, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-36 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1208, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3852, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 419, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 360, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1925, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cyygzlhm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1198, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-37 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 191, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1312, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 861, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-440aa1454843>\", line 15, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1208, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3852, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 419, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 360, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1925, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x2000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7c15c4e2e290> (for post_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 433, in _pause_backend\n",
            "    if not self._require_nexus and self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 438, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "start_with_wandb()\n",
        "start_with_wandb(set_baseline_true=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4UhC4DWeyaRX",
        "outputId": "66773996-a9e0-4fb4-f17f-b84493279b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._resume_backend at 0x7c15c4e2e170> (for pre_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3148, in run_cell_async\n",
            "    self.events.trigger('pre_run_cell', info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 443, in _resume_backend\n",
            "    logger.info(\"resuming backend\")  # type: ignore\n",
            "Message: 'resuming backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7c15c4e2e290> (for post_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 433, in _pause_backend\n",
            "    if not self._require_nexus and self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 438, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "#!rm *.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BjI30ZSDxcbM",
        "outputId": "de2ac975-32cd-43aa-83cb-cafec008ebae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7c15c4e2e290> (for post_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 433, in _pause_backend\n",
            "    if not self._require_nexus and self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 438, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOctguf7KzZSL51654imyyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}