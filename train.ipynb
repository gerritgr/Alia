{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/Alia/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovmM6MKh0RHG"
      },
      "source": [
        "# ðŸ’ŠðŸŒ€ MoleculeDiffusionGAN ðŸŒ€ðŸ’Š"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXB58ofd0yX-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is used for the naming of files and folders\n",
        "PROJECT_NAME = \"MoldDiffGAN_shortDisc\"\n",
        "PATH_PATTERN_BASE = \"moldiffusion_run6\"\n",
        "PATH_PATTERN = PATH_PATTERN_BASE\n",
        "\n",
        "# Setting BASELINE to True would deactivate the discriminator.\n",
        "BASELINE = False\n",
        "DEBUG = False\n"
      ],
      "metadata": {
        "id": "gCcXEAS_7brw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yIsuEC808hb"
      },
      "source": [
        "### Handle Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX4PHxg-00D1"
      },
      "source": [
        "On Colab, we need to install some additional packages.\n",
        "If running on Colab, we use Google Drive to store results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Check for Google Colab and WandB\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  import wandb # need to do this before chaning CWD\n",
        "except:\n",
        "  os.system(\"pip install wandb\")\n",
        "\n",
        "# Load Google Drive\n",
        "if USE_COLAB:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())\n",
        "\n",
        "\n",
        "torch_version = torch.__version__.split(\"+\")\n",
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  os.system(\"pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\")\n",
        "  os.system(\"pip install torch-geometric\")\n",
        "\n",
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  os.system(\"pip install rdkit\")\n"
      ],
      "metadata": {
        "id": "W6wrjwx9vQmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5135bb-05fd-4a2d-dc21-0ddb4ca5022b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/MoldDiffGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceqoOXap7kBb"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100  # Set this to 300 to get better image quality\n",
        "import seaborn as sns\n",
        "\n",
        "import networkx as nx\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import traceback\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear as Lin\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import (\n",
        "    PNA,\n",
        "    GATv2Conv,\n",
        "    GraphNorm,\n",
        "    BatchNorm,\n",
        "    global_mean_pool,\n",
        "    global_add_pool\n",
        ")\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx, degree\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "id": "lnxsm_Qm8QQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7b6324-bcb4-4fee-bee3-362f12f1ad03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6k-s1v37muv"
      },
      "outputs": [],
      "source": [
        "# Load code to convert molecules to pyg tensors if using Colab\n",
        "if USE_COLAB and not os.path.exists(\"smiles_to_pyg\"):\n",
        "  os.system(\"git clone https://github.com/gerritgr/MoleculeDiffusionGAN.git && cp -R MoleculeDiffusionGAN/* .\")\n",
        "\n",
        "from smiles_to_pyg.molecule_load_and_convert import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2oEPNiw_utN"
      },
      "source": [
        "## Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "## Diffusion\n",
        "##\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 256\n",
        "GAMMA = 0.1\n",
        "\n",
        "##\n",
        "## Prediction/Denoising\n",
        "##\n",
        "LEARNING_RATE_GEN = 0.001\n",
        "EPOCHS_GEN = 60\n",
        "\n",
        "# PNA Pred\n",
        "DROPOUT_PRED = 0.05\n",
        "DEPTH_PRED = 4\n",
        "HIDDEN_CHANNELS_PRED = 32\n",
        "TOWERS_PRED = 1\n",
        "NORMALIZATION_PRED = True\n",
        "\n",
        "##\n",
        "## Discriminator\n",
        "##\n",
        "EPOCHS_DISC_MODEL = 70\n",
        "DISC_NOISE = 0.3\n",
        "\n",
        "# PNA Disc\n",
        "HIDDEN_CHANNELS_DISC = 8\n",
        "DEPTH_DISC = 3 # 4 in original\n",
        "DROPOUT_DISC = 0.1 # 0.03 in original\n",
        "NORMALIZATION_DISC = True\n",
        "\n",
        "##\n",
        "## Molecule Encoding\n",
        "##\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5  # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False] * 5 + [True] * 5\n",
        "NON_EDGES = [True] + [True] * 5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1\n"
      ],
      "metadata": {
        "id": "BpeBwAGC91Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9vsl3np_y0I"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log(d):\n",
        "  try:\n",
        "    import wandb\n",
        "    wandb.log(d)\n",
        "  except:\n",
        "    print(d)\n",
        "\n",
        "\n",
        "def load_file(filepath):\n",
        "  print(\"Trying to read\", filepath)\n",
        "  try:\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "def write_file(filepath, data):\n",
        "  try:\n",
        "    data = data.cpu()\n",
        "  except:\n",
        "    pass\n",
        "  print(\"Trying to write\", filepath)\n",
        "  with gzip.open(filepath, 'wb') as f:\n",
        "    pickle.dump(data, f)\n"
      ],
      "metadata": {
        "id": "8vbsdmdl-JFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(seed=1234):\n",
        "  try:\n",
        "    dataset_train, dataset_test = load_file('dataset.pickle')\n",
        "    if DEBUG:\n",
        "      return dataset_train[:len(dataset_train) // 10], dataset_test[:len(dataset_test) // 10]\n",
        "    return dataset_train, dataset_test\n",
        "  except Exception as e:\n",
        "    print(f\"Could not load dataset due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  dataset = read_qm9()\n",
        "  dataset_all = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  dataset = list()\n",
        "\n",
        "  for g in tqdm(dataset_all):\n",
        "    try:\n",
        "      assert \"None\" not in str(pyg_to_smiles(g))\n",
        "      dataset.append(g)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  print(f\"Built and cleaned dataset, length is {len(dataset)}, old length was {len(dataset_all)}\")\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset) * 0.8 + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0, :].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  write_file(\"dataset.pickle\", (dataset_train, dataset_test))\n",
        "  return dataset_train, dataset_test\n"
      ],
      "metadata": {
        "id": "QaL_PWZH-eiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQlj5MPz_4PB"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "  \"\"\"\n",
        "  Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "  Args:\n",
        "  start (float): The starting value for the beta values. Default is START.\n",
        "  end (float): The ending value for the beta values. Default is END.\n",
        "  timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "  cumulative alpha values (alpha bars).\n",
        "  \"\"\"\n",
        "  betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "  assert(betas.numel() == TIMESTEPS)\n",
        "  return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZJBlO6C_7-x"
      },
      "outputs": [],
      "source": [
        "def visualize_smiles_from_file(filepath):\n",
        "    print(\"Visualize molecules.\")\n",
        "    # Read SMILES from file\n",
        "    with open(filepath, 'r') as file:\n",
        "        smiles_list = [line.split(\"'\")[1] for line in file.readlines() if \"'\" in line]\n",
        "\n",
        "    # Convert SMILES to RDKit Mol objects, filtering out invalid ones\n",
        "    mols = [Chem.MolFromSmiles(smile) for smile in smiles_list[:100]]\n",
        "    mols = [mol for mol in mols if mol is not None]\n",
        "\n",
        "    if len(mols) == 0:\n",
        "        return\n",
        "\n",
        "    # Determine grid size\n",
        "    num_mols = len(mols)\n",
        "    cols = 10\n",
        "    rows = min(10, -(-num_mols // cols))  # ceil division\n",
        "\n",
        "    # Create a subplot grid\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(20, 20),\n",
        "                            gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            ax = axs[i, j]\n",
        "            ax.axis(\"off\")  # hide axis\n",
        "            idx = i * cols + j  # index in mols list\n",
        "            if idx < num_mols:\n",
        "                img = Draw.MolToImage(mols[idx], size=(200, 200))\n",
        "                ax.imshow(img)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(filepath + '.jpg', format='jpg', bbox_inches='tight')\n",
        "\n",
        "    time.sleep(0.01)\n",
        "    try:\n",
        "        wandb.log_artifact(filepath + '.jpg', name=f\"jpg_{SWEEP_ID}_{filepath.replace('.','')}\", type=\"smiles_grid_graph\")\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_from_noise(noise_pred, x_with_noise, future_t):\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(1.0 - alphabar_t)\n",
        "  x_without_noise = x_with_noise - scaled_noise * noise_pred\n",
        "  x_without_noise = x_without_noise / torch.sqrt(alphabar_t)\n",
        "  return x_without_noise\n",
        "\n",
        "\n",
        "def get_noise_from_pred(original_pred, x_with_noise, future_t):\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(alphabar_t)\n",
        "  noise = x_with_noise - scaled_noise * original_pred\n",
        "  noise = noise / torch.sqrt(1.0 - alphabar_t)\n",
        "\n",
        "  return noise\n"
      ],
      "metadata": {
        "id": "X5qDfWWc_FJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_smiles(smiles, filename):\n",
        "  try:\n",
        "    with open(filename, \"w\") as file:\n",
        "      for string in smiles:\n",
        "        file.write(str(string) + \"\\n\")\n",
        "\n",
        "    try:\n",
        "      wandb.log_artifact(filename, name=f\"src_txt_{SWEEP_ID}_{filename}\", type=\"smiles\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "    time.sleep(0.01)\n",
        "    visualize_smiles_from_file(filename)\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred during training: \\n\", str(e))\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "WvP1-Zdg_mQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04wgZXHaDUwG"
      },
      "source": [
        "## Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfqAxJ2bDWxr"
      },
      "outputs": [],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "\n",
        "  if \"class 'int'\" in str(type(future_t)) or \"class 'float'\" in str(type(future_t)):\n",
        "    future_t = torch.tensor([int(future_t)] * row_num).to(DEVICE)\n",
        "\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "  assert(future_t[0] == future_t[1]) # Let's assume they belong to the same graph.\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # Column-wise multiplication, now it is a matrix\n",
        "  assert(new_node_features_mean.shape == node_features.shape)\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) # This is a col. vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) # This is a matrix\n",
        "  assert(new_node_features_mean.shape == new_node_features_std.shape)\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "#forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2BUMzmPA6-W"
      },
      "source": [
        "## Denoising NN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_to_degree_bin(train_dataset):\n",
        "  \"\"\"\n",
        "  Convert a dataset to a histogram of node degrees (in-degrees).\n",
        "  Load from file if available; otherwise, compute from the dataset.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Attempt to load the degree histogram from a file.\n",
        "    deg = load_file('deg.pickle')\n",
        "    deg = deg.to(DEVICE)\n",
        "    return deg\n",
        "  except Exception as e:\n",
        "    print(f\"Could not find degree bin due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  # Assert that the dataset is provided.\n",
        "  assert(train_dataset is not None)\n",
        "\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  # Create an empty histogram for degrees.\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "  # Populate the histogram with data from the dataset.\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "\n",
        "  # Save the computed histogram to a file.\n",
        "  write_file(\"deg.pickle\", deg.cpu())\n",
        "\n",
        "  return deg\n"
      ],
      "metadata": {
        "id": "I78sdWNKNJL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=HIDDEN_CHANNELS_PRED, depth=DEPTH_PRED, dropout=DROPOUT_PRED, towers=TOWERS_PRED, normalization=NORMALIZATION_PRED, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Adjust hidden channels for the given towers.\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) # must match\n",
        "\n",
        "    # Calculate input and output channels.\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM + TIME_FEATURE_DIM\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    # Get degree histogram for the dataset\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "\n",
        "    # Set aggregators and scalers for the PNA layer.\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "    # Create a normalization layer if required.\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "\n",
        "    # Define the PNA layer.\n",
        "    self.pnanet = PNA(\n",
        "        in_channels=in_channels,\n",
        "        hidden_channels=hidden_channels,\n",
        "        out_channels=hidden_channels,\n",
        "        num_layers=depth,\n",
        "        aggregators=aggregators,\n",
        "        scalers=scalers,\n",
        "        deg=deg,\n",
        "        dropout=dropout,\n",
        "        towers=towers,\n",
        "        norm=self.normalization,\n",
        "        pre_layers=pre_post_layers,\n",
        "        post_layers=pre_post_layers\n",
        "    )\n",
        "\n",
        "    # Define the final MLP layer.\n",
        "    self.final_mlp = Seq(\n",
        "        Lin(hidden_channels, hidden_channels),\n",
        "        nn.ReLU(),\n",
        "        Lin(hidden_channels, hidden_channels),\n",
        "        nn.ReLU(),\n",
        "        Lin(hidden_channels, out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    \"\"\"\n",
        "    Perform a forward pass through the PNAnet.\n",
        "    \"\"\"\n",
        "    row_num = x_in.shape[0]\n",
        "    t = t.view(-1, TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "\n",
        "    # Assertions for sanity checks\n",
        "    assert(x.numel() > 1)\n",
        "    assert(x.shape[0] == row_num)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "270vRkHbNYB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_latest_checkpoint(model, optimizer, loss_list, epoch_i, path_pattern_checkpoint=None):\n",
        "  \"\"\"\n",
        "  Load the latest checkpoint from the disk.\n",
        "  \"\"\"\n",
        "  if path_pattern_checkpoint is None:\n",
        "    path_pattern_checkpoint = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(path_pattern_checkpoint))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    loss_list = checkpoint['loss_list']\n",
        "\n",
        "    print(f\"Loaded checkpoint of epoch {epoch_i:08} from disk.\")\n",
        "  except Exception as e:\n",
        "    print(f\"Failed to load checkpoint. Error: {str(e)}\")\n",
        "\n",
        "  return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "def save_model(model, optimizer, loss_list, epoch_i, upload=False):\n",
        "  \"\"\"\n",
        "  Save the model state to the disk.\n",
        "  \"\"\"\n",
        "  if epoch_i == 0: # Relevant for load_base_model()\n",
        "    return\n",
        "\n",
        "  save_path = f\"{PATH_PATTERN}_model_epoch_{epoch_i:08}.pth\" # Will do lexicographical ordering to load.\n",
        "\n",
        "  # Save the model and optimizer state dicts in a dictionary.\n",
        "  torch.save({\n",
        "    'epoch': epoch_i,\n",
        "    'loss_list': loss_list,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "  }, save_path)\n",
        "\n",
        "  if upload:\n",
        "    try:\n",
        "      wandb.log_artifact(save_path, name=f\"weights_{SWEEP_ID}_{epoch_i:08}_weightfile\", type=\"weight\")\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to upload model. Error: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "G2EDh-9vXPrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGUISrgECQ-e"
      },
      "outputs": [],
      "source": [
        "def load_base_model(dataset_train, path_pattern_checkpoint=None):\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  loss_list = None\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE_GEN)\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0, path_pattern_checkpoint=path_pattern_checkpoint)\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc7iJLKJCv3s"
      },
      "source": [
        "## Inference / Reverse Process"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a _normal_ and a _restart_ method for inference. The restart version is not implemented in this notebook."
      ],
      "metadata": {
        "id": "6WRAea25gUJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_one_step(model, g, i):\n",
        "  \"\"\"\n",
        "  Performs one step of denoising using the provided model.\n",
        "  \"\"\"\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  # Generate and calculate betas, alphas, and related parameters\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1  # i=0 indicates full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "  # Create the mask\n",
        "  mask = torch.concat(\n",
        "      (torch.tensor([False] * g.x_old.shape[0], device=DEVICE).view(-1, 1),\n",
        "       g.x_old[:, 1:] > -0.5),\n",
        "      dim=1\n",
        "  )\n",
        "\n",
        "  # Define future_t for the model predictions\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1, 1)\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  # Extract noisy values and predict noise\n",
        "  x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  noise_pred = get_noise_from_pred(original_pred, x_with_noise, future_t)\n",
        "\n",
        "  # Set endpoints values\n",
        "  values_now = g.x[mask].view(row_num, -1)\n",
        "  values_endpoint = noise_pred.view(row_num, -1)\n",
        "  assert values_now.shape == values_endpoint.shape\n",
        "\n",
        "  # Compute denoised values\n",
        "  model_mean = sqrt_recip_alphas_t * (values_now - beta_t * values_endpoint / sqrt_one_minus_alphas_cumprod_t)\n",
        "  values_one_step_denoised = model_mean  # in case that t == 0\n",
        "\n",
        "  if t != 0:\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)  # in the paper this is in 3.2. Note that sigma^2 is variance, not std.\n",
        "    posterior_std_t = torch.sqrt(posterior_variance[t])\n",
        "    noise = torch.randn_like(values_now, device=DEVICE)\n",
        "    values_one_step_denoised = model_mean + posterior_std_t * noise\n",
        "\n",
        "  # Clone and update with denoised values\n",
        "  denoised_x = g.x.clone()\n",
        "  denoised_x[mask] = values_one_step_denoised.flatten()\n",
        "\n",
        "  return denoised_x\n"
      ],
      "metadata": {
        "id": "oCpdISE2yxMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5AegWA7Cy-c"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  g.x_old = g.x.clone()\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  g.x[mask] = torch.randn_like(g.x[mask])\n",
        "  return g\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples(model, dataset_train, num=100, restart_inference_method=False):\n",
        "  \"\"\"\n",
        "  Generate graph samples in batches using the provided model.\n",
        "  \"\"\"\n",
        "  # Setup\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  dataset_train_start = list()\n",
        "\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.choice(range(len(dataset_train)))]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "\n",
        "  #old\n",
        "  #while len(dataset_train_start) < num:\n",
        "  #  g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "  #  dataset_train_start.append(g.clone().to(DEVICE))\n",
        "  #  g = dataset_train_start[-1]\n",
        "\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size=num)\n",
        "\n",
        "  # Inference\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    g = overwrite_with_noise(g)\n",
        "\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS - i - 1)\n",
        "      if restart_inference_method:\n",
        "        x_with_less_noise = denoise_one_step_restart(model, g, i) # not implemented\n",
        "      else:\n",
        "        x_with_less_noise = denoise_one_step(model, g, i)\n",
        "      g.x = x_with_less_noise\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    graph_list = [g.cpu() for g in graph_list]\n",
        "\n",
        "    print(\"generated graphs \", graph_list[:10])\n",
        "    return graph_list\n"
      ],
      "metadata": {
        "id": "c8RKX4tVZGy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3snibPC2C4-f"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def find_frac_correct(graphs):\n",
        "  \"\"\"\n",
        "  Determine the fraction and unique of correct graphs based on their conversion to SMILES.\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  smiles_list = list()\n",
        "\n",
        "  for i, g in tqdm(enumerate(graphs)):\n",
        "    smiles = pyg_to_smiles(g)\n",
        "    if smiles and '.' not in smiles:\n",
        "      mol = Chem.MolFromSmiles(smiles)\n",
        "      if mol:\n",
        "        correct += 1\n",
        "        smiles_list.append((smiles, i))\n",
        "\n",
        "  frac_correct = correct / len(graphs)\n",
        "  smiles_list_0 = [s[0] for s in smiles_list]\n",
        "  unique_frac = len(set(smiles_list_0)) / len(graphs)\n",
        "\n",
        "  return frac_correct, smiles_list, unique_frac\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm9B-IOqC6j2"
      },
      "outputs": [],
      "source": [
        "def gen_graphs(num_per_generation=1000, num_generations=40, restart_inference_method=False, model_path=None):\n",
        "  \"\"\"\n",
        "  Generate a specified number of graphs.\n",
        "  \"\"\"\n",
        "  print(f\"Generate {num_generations*num_per_generation} graphs.\")\n",
        "  if DEBUG:\n",
        "    num_generations = int(num_generations / 10)\n",
        "\n",
        "  if model_path is None:\n",
        "    model_path = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "\n",
        "  path = sorted(glob.glob(model_path))[-1]\n",
        "  num_samples = num_per_generation * num_generations\n",
        "  filepath = path.replace(\".pth\", f'_{num_samples:06d}_w{restart_inference_method}_generated.pickle')\n",
        "\n",
        "  results = list()\n",
        "  try:\n",
        "    results = load_file(filepath)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  if len(results) == num_samples:\n",
        "    return results\n",
        "\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  model_base = load_base_model(dataset_base, path_pattern_checkpoint=path)\n",
        "\n",
        "  i = 0\n",
        "  while len(results) < num_samples:\n",
        "    i += 1\n",
        "    num = max(num_per_generation, len(results) - num_samples)\n",
        "    graphs = generate_examples(model_base, dataset_base, num=num, restart_inference_method=restart_inference_method)\n",
        "    results.extend(graphs)\n",
        "    if i % 5 == 0 or len(results) >= num_samples:\n",
        "      write_file(filepath, results)\n",
        "\n",
        "  assert(len(results) == num_samples)\n",
        "  return results\n",
        "\n",
        "\n",
        "def test_graph_generation(path_pattern=None, restart_inference_method=False):\n",
        "  generated_graphs = gen_graphs(restart_inference_method=restart_inference_method, model_path=path_pattern)\n",
        "  return find_frac_correct(generated_graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBi59QK5C91I"
      },
      "source": [
        "## Discriminator NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWIOKsKWC_A5"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=HIDDEN_CHANNELS_DISC,\n",
        "               depth=DEPTH_DISC, dropout=DROPOUT_DISC, towers=1,\n",
        "               normalization=NORMALIZATION_DISC, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Adjust hidden channels based on towers\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM\n",
        "    assert in_channels == 11\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset).to(DEVICE)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels,\n",
        "                     hidden_channels=hidden_channels,\n",
        "                     out_channels=1,\n",
        "                     num_layers=depth,\n",
        "                     aggregators=aggregators,\n",
        "                     scalers=scalers,\n",
        "                     deg=deg,\n",
        "                     dropout=dropout,\n",
        "                     towers=towers,\n",
        "                     norm=self.normalization,\n",
        "                     pre_layers=pre_post_layers,\n",
        "                     post_layers=pre_post_layers)\n",
        "\n",
        "  def forward(self, x, edge_index, batch=None):\n",
        "    x = x + torch.randn_like(x) * DISC_NOISE\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh-x4OlODFBX"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer):\n",
        "  model_disc.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = []\n",
        "  acc_list = []\n",
        "\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = (torch.abs(pred.flatten() - batch.y.flatten()) < 0.5).float()\n",
        "    acc_list.extend(acc.detach().cpu().tolist())\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCnHC3mPDGoM"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader):\n",
        "  model_disc.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc).to(DEVICE)\n",
        "  weight_path = f\"{PATH_PATTERN}_discriminator_model_round_{round_i:05}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:05}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = []\n",
        "  losses_train = []\n",
        "  losses_test = []\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr=0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 1 or epoch_i == EPOCHS_DISC_MODEL - 1:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:.4f}, loss test: {loss_test:.4f}, acc: {acc_train:.3f}, acc test: {acc_test:.3f}, time: {t_train:.3f}\")\n",
        "      log({\n",
        "          \"disc/step\": epoch_i + (1+round_i) * EPOCHS_DISC_MODEL,\n",
        "          \"disc/epoch\": epoch_i + (1+round_i) * EPOCHS_DISC_MODEL,\n",
        "          \"disc/loss_train\": loss_train,\n",
        "          'disc/loss_test': loss_test,\n",
        "          \"disc/acc_train\": acc_train,\n",
        "          \"disc/acc_test\": acc_test,\n",
        "          \"disc/time\": t_train\n",
        "      })\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "\n",
        "  # Plotting losses\n",
        "  plt.clf()\n",
        "  plt.plot(epochs, losses_train, label='train')\n",
        "  plt.plot(epochs, losses_test, label='test')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"discriminator_model_{round_i:05}.png\")\n",
        "\n",
        "  torch.save({\n",
        "      'model_state_dict': model_disc.state_dict(),\n",
        "      'epochs': epochs,\n",
        "      \"losses_train\": losses_train,\n",
        "      \"losses_test\": losses_test\n",
        "  }, weight_path)\n",
        "\n",
        "  return model_disc\n"
      ],
      "metadata": {
        "id": "b6vWTeUicmzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF6Sq0OsDLHt"
      },
      "outputs": [],
      "source": [
        "def run_disc(round_i=1):\n",
        "  print(f\"Train discriminator round {round_i}.\")\n",
        "  fake_graphs = gen_graphs(restart_inference_method=False)\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  real_graphs = random.sample(dataset_base, len(fake_graphs))\n",
        "  dataset = list()\n",
        "\n",
        "  for g in fake_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(0.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  for g in real_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(1.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  random.shuffle(dataset)\n",
        "  cut_off = int(len(dataset) * 0.8)\n",
        "  dataloader_train = DataLoader(dataset[:cut_off], batch_size = BATCH_SIZE, shuffle=True)\n",
        "  dataloader_test = DataLoader(dataset[cut_off:], batch_size = BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  model_disc = train_disc_model(dataloader_train, dataloader_test, round_i)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAVWEgfDDkcM"
      },
      "source": [
        "## Train Jointly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, model_disc=None):\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = []\n",
        "  loss_list_disc = []\n",
        "\n",
        "  for batch in tqdm(dataloader):\n",
        "    if batch.x.shape[0] < 2:\n",
        "      continue\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = batch.to(DEVICE)\n",
        "    row_num = batch.x.shape[0]\n",
        "\n",
        "    num_graphs_in_batch = int(torch.max(batch.batch).item() + 1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device=DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, batch.batch)\n",
        "    assert future_t.numel() == row_num\n",
        "\n",
        "    mask = torch.cat((torch.tensor([False] * row_num, device=DEVICE).view(-1, 1), batch.x[:, 1:] > -0.5), dim=1)\n",
        "    x_start_gt = batch.x[mask].view(row_num, FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x_start_gt, future_t)\n",
        "\n",
        "    x_in = batch.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    x_start_pred = model(x_in, future_t, batch.edge_index)\n",
        "    loss = F.mse_loss(x_start_gt, x_start_pred)\n",
        "\n",
        "    disc_loss = torch.tensor(0.0, device=DEVICE)\n",
        "    if model_disc is not None:\n",
        "      x_in[mask] = x_start_pred.flatten()\n",
        "      disc_loss = torch.mean((1.0 - model_disc(x_in, batch.edge_index, batch=batch.batch))**2)\n",
        "      loss = (1.0 - GAMMA) * loss + GAMMA * disc_loss\n",
        "\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    loss_list_disc.append(disc_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "  return np.mean(loss_list), np.mean(loss_list_disc), time.time() - start_time\n"
      ],
      "metadata": {
        "id": "vSqf7G3GfIi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_base_model(train_loader, epoch_num=EPOCHS_GEN, model_disc=None):\n",
        "  print(\"Train denoising model.\")\n",
        "  if DEBUG:\n",
        "    epoch_num = int(epoch_num / 10)\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train).to(DEVICE)\n",
        "\n",
        "  optimizer = Adam(model_base.parameters(), lr=LEARNING_RATE_GEN * 0.01) # the mutliplication makes no real sense\n",
        "  loss_list = []\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0)\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "  print(f\"from {epoch_start} to {epoch_num}\")\n",
        "\n",
        "  for epoch_i in range(epoch_start, epoch_num):\n",
        "    try:\n",
        "      loss, loss_disc, time_elapsed = train_epoch(model_base, train_loader, optimizer, model_disc=model_disc)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      mean_loss = np.mean([y for _, y in loss_list] + [loss])\n",
        "      print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {mean_loss:05.4f} with disc loss {loss_disc:05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "      log({\n",
        "        \"gen/step\": epoch_i,\n",
        "        \"gen/epoch\": epoch_i,\n",
        "        \"gen/loss\": loss,\n",
        "        \"gen/mean_loss\": mean_loss,\n",
        "        \"gen/start_loss\": loss_disc,\n",
        "        \"gen/runtime\": time_elapsed\n",
        "      })\n",
        "\n",
        "      if (epoch_i % 20 == 0 and epoch_i > epoch_start) or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        print(\"save\")\n",
        "        save_model(model_base, optimizer, loss_list, epoch_i + 1, upload = epoch_i == epoch_num - 1)\n",
        "        time.sleep(0.01)\n",
        "        frac, smiles_list, unique_frac = test_graph_generation(restart_inference_method=False)\n",
        "        frac_restart, smiles_list_restart, unique_frac_restart = 0, list(), 0 #test_graph_generation(restart_inference_method=True)\n",
        "        print(f\"Fraction of correct graphs: {frac}, with restart_inference_method inference {frac_restart}\")\n",
        "        log({\n",
        "          \"inference/step\": epoch_i,\n",
        "          \"inference/epoch\": epoch_i,\n",
        "          \"inference/frac_normal\": frac,\n",
        "          \"inference/frac_restart\": frac_restart,\n",
        "          \"inference/frac_normal_unique\": unique_frac,\n",
        "          \"inference/frac_restart_unique\": unique_frac_restart\n",
        "        })\n",
        "        log_smiles(smiles_list, f\"{PATH_PATTERN}_smiles_{epoch_i}_normal.txt\")\n",
        "        log_smiles(smiles_list_restart, f\"{PATH_PATTERN}_smiles_{epoch_i}_restart.txt\")\n",
        "        try:\n",
        "          print(smiles_list[:20])\n",
        "          print(smiles_list_restart[:20])\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred during training: \\n{str(e)}\")\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "  return model_base\n"
      ],
      "metadata": {
        "id": "5hRd_XXGgkRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qbC0Wq8D5Ux"
      },
      "source": [
        "### Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6zFANMID6j-"
      },
      "outputs": [],
      "source": [
        "def start_experiments(rounds=6): #originally 5\n",
        "  global DISC_NOISE\n",
        "  if DEBUG:\n",
        "    rounds = rounds // 2\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*1)\n",
        "\n",
        "  for round_i in range(1, rounds):\n",
        "    if BASELINE:\n",
        "      model_disc = None\n",
        "    else:\n",
        "      model_disc = run_disc(round_i=round_i)\n",
        "    model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*(round_i+1), model_disc=model_disc)\n",
        "    #DISC_NOISE = DISC_NOISE*0.5\n",
        "\n",
        "  save_src_file()\n",
        "  return  model_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_OiyFytEAKd"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2haryq1EA_m"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import wandb\n",
        "except:\n",
        "  # Train with discriminator (our method)\n",
        "  start_experiments(rounds=5)\n",
        "  # Train without discriminator (baseline)\n",
        "  BASELINE = True\n",
        "  start_experiments(rounds=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "086_7Od-EVX1"
      },
      "source": [
        "## Training with WandB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7ZWyjSb0d_8"
      },
      "source": [
        "We can use WandB to save the training results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5SWqlSfEWSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c589fa2-f3a3-4f29-f007-9ff530c15544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/usr/local/lib/python3.10/dist-packages/wandb']\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "print(wandb.__path__) # this should look like ['/usr/local/lib/python3.10/dist-packages/wandb']. Make sure to not install wandb into your current working dir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFyzrxmZFAMJ"
      },
      "outputs": [],
      "source": [
        "WANDB_TOKEN = \"\" # Add you WandB token here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3MHvxtkEYW2"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"AliaMol\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"inference/frac_normal_unique\",\n",
        "        \"goal\": \"maximize\",\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"BATCH_SIZE\": {\"values\": [256]},\n",
        "        \"GAMMA\": {\"values\": [0.1]},\n",
        "        \"DISC_NOISE\": {\"values\": [0.05]},  # 0.3 in generation for paper\n",
        "        \"EPOCHS_DISC_MODEL\": {\"values\": [20]},\n",
        "        \"EPOCHS_GEN\": {\"values\": [100]},\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivM55NJ7EeuR"
      },
      "outputs": [],
      "source": [
        "def save_src_file():\n",
        "  try:\n",
        "    os.system(\"pip list > pip_list.txt 2>&1\")\n",
        "    for txt_file in sorted(glob.glob('*.txt')):\n",
        "      z = \"\".join(filter(str.isalnum, txt_file))\n",
        "      wandb.log_artifact(txt_file, name=f\"src_txt_{SWEEP_ID}_{z}\", type=\"my_dataset_txt\")\n",
        "    for python_file in sorted(glob.glob('*.ipynb')):\n",
        "      z = \"\".join(filter(str.isalnum, python_file))\n",
        "      wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}_{z}\", type=\"my_dataset_ipynb\")\n",
        "    for python_file in sorted(glob.glob('*.py')):\n",
        "      z = \"\".join(filter(str.isalnum, python_file))\n",
        "      wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}_{z}\", type=\"my_dataset_py\")\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNLB7QwoEgy9"
      },
      "outputs": [],
      "source": [
        "def get_wand_api_key():\n",
        "  global WANDB_TOKEN\n",
        "  if len(WANDB_TOKEN) > 0:\n",
        "    return WANDB_TOKEN\n",
        "  import sys\n",
        "  IN_COLAB = 'google.colab' in sys.modules\n",
        "  if not IN_COLAB:\n",
        "    os.system(\"cp ~/api_key.txt api_key.txt\")\n",
        "  file_path = 'api_key.txt'\n",
        "  with open(file_path, 'r') as file:\n",
        "      api_key = file.read().strip()\n",
        "  return api_key\n",
        "\n",
        "\n",
        "def main():\n",
        "  global PATH_PATTERN\n",
        "  with wandb.init() as run:\n",
        "    PATH_PATTERN = PATH_PATTERN_BASE + '_' +str(run.name) + '_' +str(BASELINE)\n",
        "    save_src_file()\n",
        "    for hyper_param_name in sweep_config['parameters']:\n",
        "      globals()[hyper_param_name] = run.config[hyper_param_name]\n",
        "      print(\"set \", hyper_param_name, \"=\", run.config[hyper_param_name])\n",
        "    start_experiments()\n",
        "\n",
        "def start_with_wandb(set_baseline_true=False):\n",
        "  global SWEEP_ID, USE_WANDB, PATH_PATTERN, BASELINE\n",
        "  if set_baseline_true:\n",
        "    BASELINE = True\n",
        "  else:\n",
        "    BASELINE = False\n",
        "  USE_WANDB = True\n",
        "  os.environ[\"WANDB_MODE\"] = \"online\"\n",
        "  try:\n",
        "    SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "    wandb.agent(SWEEP_ID, function=main, count=5)\n",
        "  except Exception as e:\n",
        "    error_message = traceback.format_exc()\n",
        "    print(\"final error:\\n\", error_message)\n",
        "    with open('_error_log.txt', 'a') as f:\n",
        "      f.write(error_message + '\\n')\n",
        "    time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_with_wandb()\n",
        "start_with_wandb(set_baseline_true=True)"
      ],
      "metadata": {
        "id": "MoEC1VsxA6Im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ec47d96-dbde-42e4-b8ce-9277b2f17fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 169hbwu9\n",
            "Sweep URL: https://wandb.ai/nextaid/MoldDiffGAN/sweeps/169hbwu9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x2ibyf56 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgerritgr\u001b[0m (\u001b[33mnextaid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/MoldDiffGAN/wandb/run-20231113_150005-x2ibyf56</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/MoldDiffGAN/runs/x2ibyf56' target=\"_blank\">brisk-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/MoldDiffGAN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/MoldDiffGAN/sweeps/169hbwu9' target=\"_blank\">https://wandb.ai/nextaid/MoldDiffGAN/sweeps/169hbwu9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/MoldDiffGAN' target=\"_blank\">https://wandb.ai/nextaid/MoldDiffGAN</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/MoldDiffGAN/sweeps/169hbwu9' target=\"_blank\">https://wandb.ai/nextaid/MoldDiffGAN/sweeps/169hbwu9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/MoldDiffGAN/runs/x2ibyf56' target=\"_blank\">https://wandb.ai/nextaid/MoldDiffGAN/runs/x2ibyf56</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set  BATCH_SIZE = 256\n",
            "set  GAMMA = 0.1\n",
            "set  DISC_NOISE = 0.075\n",
            "set  EPOCHS_DISC_MODEL = 100\n",
            "set  EPOCHS_GEN = 100\n",
            "Trying to read dataset.pickle\n",
            "Train denoising model.\n",
            "Trying to read deg.pickle\n",
            "from 0 to 100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:15<00:00, 27.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.1335 with mean loss 0.1335 with disc loss 0.0000 with runtime 15.0199\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.0897 with mean loss 0.1043 with disc loss 0.0000 with runtime 11.8222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.70it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.0863 with mean loss 0.0990 with disc loss 0.0000 with runtime 11.7419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.0858 with mean loss 0.0962 with disc loss 0.0000 with runtime 11.6972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.0857 with mean loss 0.0945 with disc loss 0.0000 with runtime 11.6664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.0856 with mean loss 0.0932 with disc loss 0.0000 with runtime 11.7378\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.0810 with mean loss 0.0911 with disc loss 0.0000 with runtime 11.7866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.0752 with mean loss 0.0887 with disc loss 0.0000 with runtime 11.7455\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.0734 with mean loss 0.0870 with disc loss 0.0000 with runtime 11.6526\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.0731 with mean loss 0.0857 with disc loss 0.0000 with runtime 11.6528\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.0729 with mean loss 0.0846 with disc loss 0.0000 with runtime 11.7443\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.0727 with mean loss 0.0837 with disc loss 0.0000 with runtime 11.8320\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.0724 with mean loss 0.0829 with disc loss 0.0000 with runtime 11.6779\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.0722 with mean loss 0.0821 with disc loss 0.0000 with runtime 11.6530\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.0715 with mean loss 0.0814 with disc loss 0.0000 with runtime 11.6935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.0709 with mean loss 0.0808 with disc loss 0.0000 with runtime 11.7355\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.0704 with mean loss 0.0802 with disc loss 0.0000 with runtime 11.8247\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.0700 with mean loss 0.0796 with disc loss 0.0000 with runtime 11.6999\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.0698 with mean loss 0.0791 with disc loss 0.0000 with runtime 11.6954\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.0695 with mean loss 0.0786 with disc loss 0.0000 with runtime 11.7535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.0694 with mean loss 0.0782 with disc loss 0.0000 with runtime 11.7235\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000021 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137836], x=[43262, 11], batch=[43262], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136916], x=[43001, 11], batch=[43001], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137024], x=[43031, 11], batch=[43031], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138108], x=[43338, 11], batch=[43338], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137488], x=[43164, 11], batch=[43164], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137228], x=[43088, 11], batch=[43088], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138040], x=[43319, 11], batch=[43319], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.79it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137524], x=[43173, 11], batch=[43173], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137836], x=[43261, 11], batch=[43261], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138100], x=[43336, 11], batch=[43336], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137860], x=[43266, 11], batch=[43266], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138636], x=[43486, 11], batch=[43486], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137636], x=[43201, 11], batch=[43201], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137768], x=[43241, 11], batch=[43241], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137568], x=[43187, 11], batch=[43187], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136888], x=[42990, 11], batch=[42990], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137424], x=[43146, 11], batch=[43146], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137304], x=[43110, 11], batch=[43110], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137424], x=[43144, 11], batch=[43144], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137580], x=[43188, 11], batch=[43188], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138044], x=[43320, 11], batch=[43320], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137852], x=[43266, 11], batch=[43266], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137696], x=[43221, 11], batch=[43221], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137104], x=[43054, 11], batch=[43054], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138072], x=[43328, 11], batch=[43328], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138188], x=[43361, 11], batch=[43361], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138536], x=[43460, 11], batch=[43460], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137584], x=[43191, 11], batch=[43191], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.79it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138452], x=[43435, 11], batch=[43435], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137556], x=[43182, 11], batch=[43182], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137424], x=[43144, 11], batch=[43144], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138180], x=[43359, 11], batch=[43359], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137236], x=[43091, 11], batch=[43091], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137864], x=[43269, 11], batch=[43269], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137496], x=[43164, 11], batch=[43164], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137132], x=[43062, 11], batch=[43062], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137752], x=[43238, 11], batch=[43238], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137772], x=[43244, 11], batch=[43244], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137824], x=[43257, 11], batch=[43257], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.82it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138028], x=[43314, 11], batch=[43314], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000021_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40000it [02:52, 232.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fraction of correct graphs: 0.3909, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('CC1CCCCCC1O', 2), ('CC1C23CC(C2)C13C', 3), ('C1C2CC3C2C3C2OC12', 5), ('CC1CCC2CC2CC1', 6), ('CCC(C)C(C)(O)C=O', 8), ('CC(CO)C(O)CO', 11), ('CCC(C)C12CC1C2C', 13), ('OC12OC3OC4C1C3C42', 19), ('CC12OCC3CC1C32O', 23), ('CC1CC(C)C(O)C1C', 28), ('COCC1(CCO)CO1', 29), ('COCCC1(C)CC1O', 30), ('CC1C(CO)CC1(C)C', 31), ('OC1CC(C2CC2)OO1', 34), ('CCC1CC23CC(C2)C13', 35), ('CCC(CC)CC1CO1', 39), ('CC1CC(O)C(C)C1O', 45), ('CCC(CC)C(C)C', 47), ('CC1C2CC(C)(C2)C1C', 49), ('CC1CC2COC2C1', 57)]\n",
            "[]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000021 is: 0.0692 with mean loss 0.0778 with disc loss 0.0000 with runtime 11.9104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000022 is: 0.0690 with mean loss 0.0774 with disc loss 0.0000 with runtime 11.8594\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000023 is: 0.0690 with mean loss 0.0771 with disc loss 0.0000 with runtime 12.0347\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000024 is: 0.0688 with mean loss 0.0768 with disc loss 0.0000 with runtime 11.7854\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000025 is: 0.0688 with mean loss 0.0765 with disc loss 0.0000 with runtime 11.8700\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000026 is: 0.0686 with mean loss 0.0762 with disc loss 0.0000 with runtime 11.8911\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000027 is: 0.0686 with mean loss 0.0759 with disc loss 0.0000 with runtime 11.9305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000028 is: 0.0686 with mean loss 0.0757 with disc loss 0.0000 with runtime 11.9573\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000029 is: 0.0684 with mean loss 0.0754 with disc loss 0.0000 with runtime 11.8075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.0683 with mean loss 0.0752 with disc loss 0.0000 with runtime 11.8871\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.0684 with mean loss 0.0750 with disc loss 0.0000 with runtime 11.8823\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.0681 with mean loss 0.0748 with disc loss 0.0000 with runtime 11.8769\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.0681 with mean loss 0.0746 with disc loss 0.0000 with runtime 11.9120\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.0681 with mean loss 0.0744 with disc loss 0.0000 with runtime 11.8022\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.0681 with mean loss 0.0743 with disc loss 0.0000 with runtime 11.8853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.0679 with mean loss 0.0741 with disc loss 0.0000 with runtime 11.8880\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.0679 with mean loss 0.0739 with disc loss 0.0000 with runtime 11.8704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.0678 with mean loss 0.0738 with disc loss 0.0000 with runtime 11.9200\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.0677 with mean loss 0.0736 with disc loss 0.0000 with runtime 11.8409\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.0676 with mean loss 0.0735 with disc loss 0.0000 with runtime 11.9143\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000041 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138268], x=[43383, 11], batch=[43383], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138252], x=[43378, 11], batch=[43378], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137296], x=[43108, 11], batch=[43108], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137748], x=[43235, 11], batch=[43235], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138320], x=[43398, 11], batch=[43398], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137884], x=[43276, 11], batch=[43276], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138348], x=[43407, 11], batch=[43407], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138052], x=[43321, 11], batch=[43321], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137724], x=[43227, 11], batch=[43227], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137192], x=[43078, 11], batch=[43078], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138108], x=[43338, 11], batch=[43338], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137296], x=[43108, 11], batch=[43108], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138252], x=[43379, 11], batch=[43379], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137148], x=[43067, 11], batch=[43067], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137072], x=[43044, 11], batch=[43044], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137824], x=[43256, 11], batch=[43256], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137364], x=[43125, 11], batch=[43125], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137236], x=[43090, 11], batch=[43090], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138244], x=[43375, 11], batch=[43375], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138128], x=[43343, 11], batch=[43343], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.70it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137816], x=[43255, 11], batch=[43255], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136900], x=[42997, 11], batch=[42997], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138124], x=[43342, 11], batch=[43342], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137732], x=[43230, 11], batch=[43230], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137648], x=[43208, 11], batch=[43208], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137396], x=[43137, 11], batch=[43137], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137968], x=[43300, 11], batch=[43300], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137680], x=[43215, 11], batch=[43215], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137232], x=[43091, 11], batch=[43091], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137820], x=[43256, 11], batch=[43256], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137060], x=[43041, 11], batch=[43041], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137940], x=[43291, 11], batch=[43291], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137692], x=[43221, 11], batch=[43221], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137316], x=[43114, 11], batch=[43114], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137444], x=[43150, 11], batch=[43150], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137348], x=[43122, 11], batch=[43122], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137976], x=[43301, 11], batch=[43301], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137376], x=[43129, 11], batch=[43129], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137276], x=[43102, 11], batch=[43102], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138148], x=[43349, 11], batch=[43349], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000041_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40000it [02:51, 233.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fraction of correct graphs: 0.177025, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('CC12CC1C1C(=O)CC12', 0), ('CC1(O)CC(O)C2CC21', 2), ('CC(=O)CC1(C)CC1C', 7), ('CCC1C2CC(C2)C1O', 8), ('C1CC2CC3CC1C23', 22), ('CCC1CC2(CC)CC12', 38), ('O=C(CC1CO1)C1CC1', 42), ('CCC(C)C1(C)CC1=O', 49), ('CCC1C(=O)C(=O)C1=O', 63), ('CC1C2C3C2C32C(C)C12', 69), ('CCCC1CC2CC12', 70), ('CCCCC(C)C1CC1', 71), ('CC1CCC(CO)C1O', 78), ('C1C2CC34CC3C1CC24', 79), ('CC1CCC2CC1C2=O', 82), ('CC1(C)CC2C1C2(C)C', 86), ('C1CCC23CC(C1)C2C3', 88), ('CCC1CCC(C)C1O', 93), ('COC(C)CC1(O)CO1', 94), ('CC1(CC2CCC2)CC1', 95)]\n",
            "[]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.0678 with mean loss 0.0734 with disc loss 0.0000 with runtime 11.9882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.0674 with mean loss 0.0732 with disc loss 0.0000 with runtime 11.8881\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.0674 with mean loss 0.0731 with disc loss 0.0000 with runtime 11.8565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.0675 with mean loss 0.0730 with disc loss 0.0000 with runtime 11.8666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.0674 with mean loss 0.0728 with disc loss 0.0000 with runtime 11.9909\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.0673 with mean loss 0.0727 with disc loss 0.0000 with runtime 11.9695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.0672 with mean loss 0.0726 with disc loss 0.0000 with runtime 11.8578\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.0672 with mean loss 0.0725 with disc loss 0.0000 with runtime 11.9029\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.0673 with mean loss 0.0724 with disc loss 0.0000 with runtime 11.9209\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000050 is: 0.0671 with mean loss 0.0723 with disc loss 0.0000 with runtime 12.0024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000051 is: 0.0671 with mean loss 0.0722 with disc loss 0.0000 with runtime 11.8998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000052 is: 0.0671 with mean loss 0.0721 with disc loss 0.0000 with runtime 11.8506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000053 is: 0.0671 with mean loss 0.0720 with disc loss 0.0000 with runtime 11.9583\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000054 is: 0.0670 with mean loss 0.0719 with disc loss 0.0000 with runtime 11.9505\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000055 is: 0.0669 with mean loss 0.0718 with disc loss 0.0000 with runtime 12.0161\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000056 is: 0.0669 with mean loss 0.0717 with disc loss 0.0000 with runtime 11.8673\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000057 is: 0.0668 with mean loss 0.0717 with disc loss 0.0000 with runtime 11.8760\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000058 is: 0.0668 with mean loss 0.0716 with disc loss 0.0000 with runtime 11.8639\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000059 is: 0.0667 with mean loss 0.0715 with disc loss 0.0000 with runtime 11.9566\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000060 is: 0.0669 with mean loss 0.0714 with disc loss 0.0000 with runtime 11.9826\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000061 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137940], x=[43292, 11], batch=[43292], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137388], x=[43135, 11], batch=[43135], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138528], x=[43456, 11], batch=[43456], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138212], x=[43366, 11], batch=[43366], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138376], x=[43414, 11], batch=[43414], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137724], x=[43230, 11], batch=[43230], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137768], x=[43241, 11], batch=[43241], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136176], x=[42788, 11], batch=[42788], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 32.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137212], x=[43086, 11], batch=[43086], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137088], x=[43047, 11], batch=[43047], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137172], x=[43073, 11], batch=[43073], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137356], x=[43127, 11], batch=[43127], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138224], x=[43370, 11], batch=[43370], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137768], x=[43241, 11], batch=[43241], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138200], x=[43364, 11], batch=[43364], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137448], x=[43153, 11], batch=[43153], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137628], x=[43203, 11], batch=[43203], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138044], x=[43320, 11], batch=[43320], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138024], x=[43312, 11], batch=[43312], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137860], x=[43269, 11], batch=[43269], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138580], x=[43472, 11], batch=[43472], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137188], x=[43076, 11], batch=[43076], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137472], x=[43158, 11], batch=[43158], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137740], x=[43235, 11], batch=[43235], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136852], x=[42983, 11], batch=[42983], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137988], x=[43305, 11], batch=[43305], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137420], x=[43142, 11], batch=[43142], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138332], x=[43400, 11], batch=[43400], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138116], x=[43341, 11], batch=[43341], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137700], x=[43223, 11], batch=[43223], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137384], x=[43133, 11], batch=[43133], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137820], x=[43257, 11], batch=[43257], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138644], x=[43488, 11], batch=[43488], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138320], x=[43399, 11], batch=[43399], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137608], x=[43198, 11], batch=[43198], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137624], x=[43200, 11], batch=[43200], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136924], x=[43003, 11], batch=[43003], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137436], x=[43145, 11], batch=[43145], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137036], x=[43035, 11], batch=[43035], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138176], x=[43358, 11], batch=[43358], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000061_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40000it [02:50, 234.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraction of correct graphs: 0.1573, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('C1CC2CC3CC2C3C1', 10), ('CCCC1CC1CCC', 11), ('CC(O)OC(C)C=O', 14), ('CCC(C)C(C)CCO', 35), ('CCCC(CC)CC=O', 39), ('CCCOC1CCCC1', 56), ('CCC1C2=NC=CCC21', 59), ('CON=C(C)CC1CC1', 61), ('CC1C2CC3(O)CC2C13', 72), ('CC1CC2(C)C(C)CC12', 112), ('CCC1CCC1OC', 115), ('CCC12CCC1(CO)C2', 116), ('CCC1C2CC12N1C=C1', 119), ('CCCC1CN=C(C)O1', 123), ('CC1=CN=CC1C(=N)O', 129), ('CC1CC2C3C1(C)C23O', 131), ('CCCCC(C)NCC', 141), ('CCC1C(C)C(C)C1O', 146), ('CC1CC(CC2CC2)C1', 155), ('CC12CC=CC1(O)CC2', 156)]\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000061 is: 0.0669 with mean loss 0.0714 with disc loss 0.0000 with runtime 11.9409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000062 is: 0.0668 with mean loss 0.0713 with disc loss 0.0000 with runtime 11.9233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000063 is: 0.0669 with mean loss 0.0712 with disc loss 0.0000 with runtime 11.8880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000064 is: 0.0670 with mean loss 0.0712 with disc loss 0.0000 with runtime 11.8638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000065 is: 0.0667 with mean loss 0.0711 with disc loss 0.0000 with runtime 11.8971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000066 is: 0.0668 with mean loss 0.0710 with disc loss 0.0000 with runtime 11.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000067 is: 0.0667 with mean loss 0.0710 with disc loss 0.0000 with runtime 12.0470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000068 is: 0.0667 with mean loss 0.0709 with disc loss 0.0000 with runtime 11.8568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000069 is: 0.0667 with mean loss 0.0708 with disc loss 0.0000 with runtime 11.8642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000070 is: 0.0668 with mean loss 0.0708 with disc loss 0.0000 with runtime 11.8831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000071 is: 0.0667 with mean loss 0.0707 with disc loss 0.0000 with runtime 11.8667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000072 is: 0.0665 with mean loss 0.0707 with disc loss 0.0000 with runtime 11.9851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000073 is: 0.0665 with mean loss 0.0706 with disc loss 0.0000 with runtime 11.9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000074 is: 0.0666 with mean loss 0.0706 with disc loss 0.0000 with runtime 11.8915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000075 is: 0.0666 with mean loss 0.0705 with disc loss 0.0000 with runtime 11.8318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000076 is: 0.0665 with mean loss 0.0705 with disc loss 0.0000 with runtime 11.9237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000077 is: 0.0666 with mean loss 0.0704 with disc loss 0.0000 with runtime 11.9955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000078 is: 0.0663 with mean loss 0.0703 with disc loss 0.0000 with runtime 11.8601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000079 is: 0.0664 with mean loss 0.0703 with disc loss 0.0000 with runtime 11.9650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000080 is: 0.0664 with mean loss 0.0703 with disc loss 0.0000 with runtime 11.8652\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000081 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137864], x=[43268, 11], batch=[43268], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138036], x=[43318, 11], batch=[43318], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137328], x=[43116, 11], batch=[43116], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138432], x=[43430, 11], batch=[43430], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137620], x=[43200, 11], batch=[43200], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137184], x=[43076, 11], batch=[43076], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137140], x=[43063, 11], batch=[43063], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137532], x=[43177, 11], batch=[43177], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137444], x=[43150, 11], batch=[43150], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137468], x=[43155, 11], batch=[43155], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138404], x=[43424, 11], batch=[43424], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138052], x=[43320, 11], batch=[43320], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137692], x=[43221, 11], batch=[43221], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138300], x=[43393, 11], batch=[43393], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138820], x=[43540, 11], batch=[43540], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136720], x=[42945, 11], batch=[42945], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137612], x=[43198, 11], batch=[43198], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137664], x=[43209, 11], batch=[43209], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137764], x=[43241, 11], batch=[43241], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137928], x=[43286, 11], batch=[43286], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138044], x=[43321, 11], batch=[43321], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136580], x=[42903, 11], batch=[42903], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137416], x=[43141, 11], batch=[43141], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138016], x=[43311, 11], batch=[43311], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137976], x=[43299, 11], batch=[43299], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138444], x=[43434, 11], batch=[43434], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138424], x=[43427, 11], batch=[43427], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137876], x=[43272, 11], batch=[43272], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137876], x=[43273, 11], batch=[43273], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137348], x=[43123, 11], batch=[43123], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137752], x=[43238, 11], batch=[43238], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138320], x=[43399, 11], batch=[43399], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137956], x=[43297, 11], batch=[43297], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138112], x=[43339, 11], batch=[43339], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138532], x=[43458, 11], batch=[43458], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138644], x=[43490, 11], batch=[43490], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137740], x=[43235, 11], batch=[43235], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137524], x=[43174, 11], batch=[43174], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137900], x=[43280, 11], batch=[43280], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137704], x=[43222, 11], batch=[43222], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000081_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40000it [02:54, 228.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraction of correct graphs: 0.522775, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('C1CC23C4CC2C3CC14', 2), ('C=C1CC1CC(O)CO', 4), ('C1C2CC3(CC4C1C43)O2', 7), ('CCCCC1CC1OO', 8), ('O=NNN=O', 9), ('C1C2C3OC4C5C2C13C45', 10), ('CCCC1C2C34CC3C124', 11), ('CC1OCCCC1CO', 13), ('CC1(CCO)CCCC1', 18), ('CC1OC1C1(C)CC1C', 19), ('CCC12CC1CC2O', 21), ('C1OC23CC4CC25C1C435', 22), ('CC1CCC2NCC2C1', 23), ('C=C1COCC1C1CC1', 24), ('CCCC1CC2OC2C1', 26), ('CCC12CCCC1N2', 27), ('OCC12C3CC34C1C24O', 28), ('CC1C(CCO)C2CC12', 29), ('O=C1C2CC2C1C1CO1', 30), ('CCNCCC(C)C=N', 31)]\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000081 is: 0.0663 with mean loss 0.0702 with disc loss 0.0000 with runtime 11.9976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000082 is: 0.0664 with mean loss 0.0702 with disc loss 0.0000 with runtime 11.9234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000083 is: 0.0665 with mean loss 0.0701 with disc loss 0.0000 with runtime 12.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000084 is: 0.0663 with mean loss 0.0701 with disc loss 0.0000 with runtime 11.9439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000085 is: 0.0665 with mean loss 0.0700 with disc loss 0.0000 with runtime 12.0088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000086 is: 0.0665 with mean loss 0.0700 with disc loss 0.0000 with runtime 12.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000087 is: 0.0665 with mean loss 0.0700 with disc loss 0.0000 with runtime 11.9164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000088 is: 0.0663 with mean loss 0.0699 with disc loss 0.0000 with runtime 11.9955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000089 is: 0.0663 with mean loss 0.0699 with disc loss 0.0000 with runtime 11.9734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000090 is: 0.0664 with mean loss 0.0698 with disc loss 0.0000 with runtime 11.9736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000091 is: 0.0660 with mean loss 0.0698 with disc loss 0.0000 with runtime 11.9552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 34.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000092 is: 0.0662 with mean loss 0.0698 with disc loss 0.0000 with runtime 11.9932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000093 is: 0.0661 with mean loss 0.0697 with disc loss 0.0000 with runtime 12.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000094 is: 0.0664 with mean loss 0.0697 with disc loss 0.0000 with runtime 11.9679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000095 is: 0.0661 with mean loss 0.0696 with disc loss 0.0000 with runtime 11.9341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000096 is: 0.0663 with mean loss 0.0696 with disc loss 0.0000 with runtime 11.9527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000097 is: 0.0661 with mean loss 0.0696 with disc loss 0.0000 with runtime 11.9693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:12<00:00, 34.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000098 is: 0.0660 with mean loss 0.0695 with disc loss 0.0000 with runtime 12.0480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:11<00:00, 35.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000099 is: 0.0661 with mean loss 0.0695 with disc loss 0.0000 with runtime 11.9576\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000100 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137460], x=[43156, 11], batch=[43156], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137956], x=[43293, 11], batch=[43293], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137100], x=[43052, 11], batch=[43052], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137020], x=[43031, 11], batch=[43031], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137100], x=[43049, 11], batch=[43049], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137052], x=[43036, 11], batch=[43036], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137164], x=[43070, 11], batch=[43070], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137436], x=[43146, 11], batch=[43146], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138212], x=[43365, 11], batch=[43365], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137596], x=[43190, 11], batch=[43190], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137720], x=[43226, 11], batch=[43226], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137960], x=[43294, 11], batch=[43294], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137700], x=[43222, 11], batch=[43222], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137808], x=[43251, 11], batch=[43251], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137632], x=[43203, 11], batch=[43203], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137396], x=[43133, 11], batch=[43133], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137792], x=[43249, 11], batch=[43249], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137148], x=[43067, 11], batch=[43067], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137564], x=[43184, 11], batch=[43184], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137512], x=[43168, 11], batch=[43168], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136664], x=[42927, 11], batch=[42927], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138592], x=[43475, 11], batch=[43475], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136548], x=[42896, 11], batch=[42896], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137836], x=[43261, 11], batch=[43261], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138028], x=[43316, 11], batch=[43316], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137720], x=[43224, 11], batch=[43224], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137012], x=[43026, 11], batch=[43026], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137636], x=[43203, 11], batch=[43203], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137176], x=[43076, 11], batch=[43076], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138368], x=[43410, 11], batch=[43410], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138148], x=[43350, 11], batch=[43350], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137372], x=[43131, 11], batch=[43131], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137056], x=[43040, 11], batch=[43040], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137956], x=[43293, 11], batch=[43293], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137700], x=[43222, 11], batch=[43222], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137884], x=[43272, 11], batch=[43272], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138188], x=[43360, 11], batch=[43360], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137036], x=[43036, 11], batch=[43036], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137976], x=[43302, 11], batch=[43302], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138468], x=[43438, 11], batch=[43438], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40000it [02:52, 231.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraction of correct graphs: 0.366675, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('C1CC2C3CC3C23CC13', 2), ('CN1CC2(CCO)CC12', 5), ('COCN=CCCN=O', 6), ('CC1(O)C2CN1C2CO', 13), ('COC1C2CCOC21O', 14), ('CCCC1CC(O)C1', 18), ('CCC(C)C1C2CC21O', 19), ('CCCCCC1(C)CO1', 22), ('CCN1CCC2(CN2)C1', 26), ('CC(C)CCC1CC1', 27), ('CC(CCO)C1CCC1', 28), ('CCOC1CC1C(C)C', 31), ('CCOC(C)(CN)CO', 35), ('CNCCOC(C)OC', 36), ('CN1C(N)CCC2CC21', 42), ('CC(C)C(C)O', 43), ('CCCCC1C2CC12O', 44), ('NC12CC3OC4CC1C432', 48), ('CC12C3CC14C31CC24O1', 52), ('CCC(C=O)CC1OO1', 55)]\n",
            "[]\n",
            "Train discriminator round 1.\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000100_040000_wFalse_generated.pickle\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train discriminator: epoch: 00001, loss: 0.5262, loss test: 0.3964, acc: 0.769, acc test: 0.847, time: 5.719\n",
            "train discriminator: epoch: 00011, loss: 0.1849, loss test: 0.1837, acc: 0.924, acc test: 0.926, time: 5.492\n",
            "train discriminator: epoch: 00021, loss: 0.1530, loss test: 0.1751, acc: 0.938, acc test: 0.926, time: 5.522\n",
            "train discriminator: epoch: 00031, loss: 0.1372, loss test: 0.2385, acc: 0.944, acc test: 0.895, time: 5.481\n",
            "train discriminator: epoch: 00041, loss: 0.1304, loss test: 0.1166, acc: 0.947, acc test: 0.954, time: 5.505\n",
            "train discriminator: epoch: 00051, loss: 0.1247, loss test: 0.1798, acc: 0.950, acc test: 0.922, time: 5.544\n",
            "train discriminator: epoch: 00061, loss: 0.1203, loss test: 0.1768, acc: 0.952, acc test: 0.924, time: 5.541\n",
            "train discriminator: epoch: 00071, loss: 0.1165, loss test: 0.2343, acc: 0.955, acc test: 0.903, time: 5.575\n",
            "train discriminator: epoch: 00081, loss: 0.1105, loss test: 0.1665, acc: 0.956, acc test: 0.929, time: 5.555\n",
            "train discriminator: epoch: 00091, loss: 0.1068, loss test: 0.0966, acc: 0.958, acc test: 0.963, time: 5.532\n",
            "train discriminator: epoch: 00099, loss: 0.1022, loss test: 0.1202, acc: 0.960, acc test: 0.953, time: 5.525\n",
            "Train denoising model.\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000100 from disk.\n",
            "from 100 to 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:18<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000100 is: 0.0901 with mean loss 0.0699 with disc loss 0.1254 with runtime 18.0708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000101 is: 0.0779 with mean loss 0.0699 with disc loss 0.0090 with runtime 17.7107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000102 is: 0.0767 with mean loss 0.0700 with disc loss 0.0083 with runtime 17.7083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000103 is: 0.0759 with mean loss 0.0700 with disc loss 0.0079 with runtime 17.5470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000104 is: 0.0753 with mean loss 0.0700 with disc loss 0.0071 with runtime 17.6764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000105 is: 0.0748 with mean loss 0.0701 with disc loss 0.0070 with runtime 17.5831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000106 is: 0.0748 with mean loss 0.0701 with disc loss 0.0068 with runtime 17.5258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000107 is: 0.0747 with mean loss 0.0702 with disc loss 0.0066 with runtime 17.5022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000108 is: 0.0744 with mean loss 0.0702 with disc loss 0.0066 with runtime 17.6891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000109 is: 0.0744 with mean loss 0.0702 with disc loss 0.0064 with runtime 17.7448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000110 is: 0.0740 with mean loss 0.0703 with disc loss 0.0065 with runtime 17.5224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000111 is: 0.0740 with mean loss 0.0703 with disc loss 0.0064 with runtime 17.5649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000112 is: 0.0740 with mean loss 0.0703 with disc loss 0.0062 with runtime 17.7182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000113 is: 0.0737 with mean loss 0.0704 with disc loss 0.0061 with runtime 17.6359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000114 is: 0.0738 with mean loss 0.0704 with disc loss 0.0060 with runtime 17.7792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000115 is: 0.0736 with mean loss 0.0704 with disc loss 0.0060 with runtime 17.5409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000116 is: 0.0736 with mean loss 0.0704 with disc loss 0.0060 with runtime 17.6939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000117 is: 0.0736 with mean loss 0.0705 with disc loss 0.0058 with runtime 17.6395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000118 is: 0.0735 with mean loss 0.0705 with disc loss 0.0059 with runtime 17.5730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000119 is: 0.0734 with mean loss 0.0705 with disc loss 0.0058 with runtime 17.6443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000120 is: 0.0735 with mean loss 0.0705 with disc loss 0.0059 with runtime 17.5366\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000121 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137660], x=[43213, 11], batch=[43213], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137352], x=[43124, 11], batch=[43124], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137272], x=[43101, 11], batch=[43101], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137716], x=[43224, 11], batch=[43224], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138296], x=[43392, 11], batch=[43392], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137632], x=[43203, 11], batch=[43203], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136996], x=[43023, 11], batch=[43023], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138208], x=[43366, 11], batch=[43366], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137004], x=[43023, 11], batch=[43023], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138176], x=[43358, 11], batch=[43358], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137576], x=[43188, 11], batch=[43188], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137308], x=[43112, 11], batch=[43112], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137924], x=[43285, 11], batch=[43285], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137432], x=[43145, 11], batch=[43145], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138220], x=[43369, 11], batch=[43369], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137968], x=[43299, 11], batch=[43299], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137940], x=[43290, 11], batch=[43290], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137836], x=[43260, 11], batch=[43260], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137844], x=[43262, 11], batch=[43262], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137524], x=[43173, 11], batch=[43173], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138008], x=[43308, 11], batch=[43308], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137648], x=[43207, 11], batch=[43207], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136752], x=[42955, 11], batch=[42955], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137128], x=[43059, 11], batch=[43059], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137548], x=[43180, 11], batch=[43180], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138472], x=[43441, 11], batch=[43441], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137740], x=[43233, 11], batch=[43233], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137260], x=[43097, 11], batch=[43097], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137220], x=[43085, 11], batch=[43085], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137416], x=[43143, 11], batch=[43143], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137772], x=[43241, 11], batch=[43241], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137844], x=[43263, 11], batch=[43263], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137684], x=[43217, 11], batch=[43217], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136652], x=[42923, 11], batch=[42923], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137312], x=[43114, 11], batch=[43114], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137408], x=[43137, 11], batch=[43137], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138128], x=[43344, 11], batch=[43344], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137064], x=[43043, 11], batch=[43043], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138788], x=[43530, 11], batch=[43530], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137808], x=[43252, 11], batch=[43252], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000121_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40000it [02:52, 231.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraction of correct graphs: 0.401775, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('CC1CC2(C1)CC(C)O2', 0), ('NCCCC1=NC(=O)C1', 1), ('C1CC(C2C3CC2C3)C1', 3), ('COCCC1CCN1', 5), ('CC1CCCOCC1C', 15), ('CCCCCC1OC1C', 16), ('CCC1C2CC1C2', 17), ('CC(O)CCC1NCN1', 19), ('CCC1CNC2C3C1C23', 20), ('CCCCC(O)CCO', 21), ('CCC(C)C(C)C=O', 23), ('CC1CC1C1(C=O)CC1', 26), ('CCCC1CC1C1CC1', 27), ('CCCCC1CCCC1', 30), ('CC1CCCC1CCO', 31), ('OCC=CC1CCCC1', 32), ('CCCC1CC1C', 34), ('CCCOCC=NNC', 39), ('CC1C(O)C23OCC2C13', 41), ('CC1CCC(C)C1(C)C', 42)]\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000121 is: 0.0734 with mean loss 0.0706 with disc loss 0.0057 with runtime 17.5547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000122 is: 0.0734 with mean loss 0.0706 with disc loss 0.0057 with runtime 17.3987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000123 is: 0.0735 with mean loss 0.0706 with disc loss 0.0056 with runtime 17.4468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000124 is: 0.0734 with mean loss 0.0706 with disc loss 0.0056 with runtime 17.5019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000125 is: 0.0733 with mean loss 0.0707 with disc loss 0.0056 with runtime 17.5336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000126 is: 0.0734 with mean loss 0.0707 with disc loss 0.0056 with runtime 17.4830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000127 is: 0.0731 with mean loss 0.0707 with disc loss 0.0056 with runtime 17.4681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000128 is: 0.0732 with mean loss 0.0707 with disc loss 0.0055 with runtime 17.3898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000129 is: 0.0731 with mean loss 0.0707 with disc loss 0.0056 with runtime 17.3575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000130 is: 0.0732 with mean loss 0.0708 with disc loss 0.0054 with runtime 17.5309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000131 is: 0.0735 with mean loss 0.0708 with disc loss 0.0055 with runtime 17.3842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000132 is: 0.0733 with mean loss 0.0708 with disc loss 0.0054 with runtime 17.2946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000133 is: 0.0734 with mean loss 0.0708 with disc loss 0.0055 with runtime 17.3713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000134 is: 0.0732 with mean loss 0.0708 with disc loss 0.0055 with runtime 17.4871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000135 is: 0.0734 with mean loss 0.0709 with disc loss 0.0053 with runtime 17.3441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000136 is: 0.0732 with mean loss 0.0709 with disc loss 0.0055 with runtime 17.3455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000137 is: 0.0733 with mean loss 0.0709 with disc loss 0.0055 with runtime 17.3947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000138 is: 0.0732 with mean loss 0.0709 with disc loss 0.0056 with runtime 17.3872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000139 is: 0.0731 with mean loss 0.0709 with disc loss 0.0054 with runtime 17.7205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000140 is: 0.0733 with mean loss 0.0709 with disc loss 0.0055 with runtime 17.5747\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000141 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137612], x=[43197, 11], batch=[43197], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137852], x=[43266, 11], batch=[43266], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137748], x=[43236, 11], batch=[43236], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137656], x=[43209, 11], batch=[43209], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137804], x=[43252, 11], batch=[43252], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137948], x=[43292, 11], batch=[43292], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137996], x=[43304, 11], batch=[43304], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137388], x=[43136, 11], batch=[43136], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137476], x=[43157, 11], batch=[43157], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137656], x=[43209, 11], batch=[43209], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138268], x=[43384, 11], batch=[43384], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137800], x=[43250, 11], batch=[43250], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138116], x=[43340, 11], batch=[43340], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136796], x=[42966, 11], batch=[42966], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138372], x=[43414, 11], batch=[43414], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138116], x=[43340, 11], batch=[43340], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137692], x=[43219, 11], batch=[43219], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137608], x=[43196, 11], batch=[43196], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137708], x=[43225, 11], batch=[43225], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137588], x=[43189, 11], batch=[43189], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137512], x=[43169, 11], batch=[43169], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137936], x=[43289, 11], batch=[43289], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137636], x=[43203, 11], batch=[43203], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137664], x=[43213, 11], batch=[43213], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137456], x=[43154, 11], batch=[43154], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137304], x=[43112, 11], batch=[43112], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137676], x=[43213, 11], batch=[43213], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137284], x=[43100, 11], batch=[43100], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137364], x=[43129, 11], batch=[43129], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137600], x=[43195, 11], batch=[43195], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137436], x=[43149, 11], batch=[43149], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136640], x=[42922, 11], batch=[42922], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138264], x=[43383, 11], batch=[43383], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137064], x=[43043, 11], batch=[43043], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137176], x=[43075, 11], batch=[43075], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138052], x=[43322, 11], batch=[43322], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137744], x=[43234, 11], batch=[43234], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137360], x=[43125, 11], batch=[43125], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137312], x=[43110, 11], batch=[43110], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136472], x=[42875, 11], batch=[42875], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000141_040000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40000it [02:54, 229.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraction of correct graphs: 0.48165, with restart_inference_method inference 0\n",
            "Visualize molecules.\n",
            "Visualize molecules.\n",
            "[('CC1CCC2CC1(O)C2', 5), ('CCC(C)C(C)CC', 8), ('CCC1C(C=O)C1CC', 9), ('CCCC12C3C1C32OC', 11), ('CCCCCCCCO', 14), ('CCC1CCC2C(O)C12', 21), ('CCCCC1CCC1=O', 24), ('NCCC1COC12CC2', 29), ('CCC1(C)CC1C(C)C', 30), ('O=CCCC1CCC1', 31), ('CC1C(C)C(CO)C1C', 35), ('C1CC(CC23CC2O3)C1', 36), ('CC12CCCC(C1)C2O', 37), ('NCC12CC=CC1CO2', 38), ('c1ncc(CC2CN2)o1', 39), ('C1CC(OCC2CC2)C1', 40), ('C=CC1CC1(C)C(O)O', 41), ('CC1COC2C3CC12C3', 42), ('CCCCCC12CC1O2', 44), ('CCC1CCC2C(C)C12', 47)]\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000141 is: 0.0732 with mean loss 0.0710 with disc loss 0.0054 with runtime 17.6495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000142 is: 0.0732 with mean loss 0.0710 with disc loss 0.0055 with runtime 17.5474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000143 is: 0.0731 with mean loss 0.0710 with disc loss 0.0054 with runtime 17.5091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000144 is: 0.0732 with mean loss 0.0710 with disc loss 0.0053 with runtime 17.3596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000145 is: 0.0731 with mean loss 0.0710 with disc loss 0.0055 with runtime 17.5382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000146 is: 0.0730 with mean loss 0.0710 with disc loss 0.0053 with runtime 17.4480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000147 is: 0.0731 with mean loss 0.0710 with disc loss 0.0053 with runtime 17.3780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000148 is: 0.0730 with mean loss 0.0710 with disc loss 0.0053 with runtime 17.5931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000149 is: 0.0731 with mean loss 0.0711 with disc loss 0.0053 with runtime 17.4078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000150 is: 0.0730 with mean loss 0.0711 with disc loss 0.0052 with runtime 17.4451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000151 is: 0.0732 with mean loss 0.0711 with disc loss 0.0054 with runtime 17.4833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000152 is: 0.0730 with mean loss 0.0711 with disc loss 0.0053 with runtime 17.5102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000153 is: 0.0730 with mean loss 0.0711 with disc loss 0.0053 with runtime 17.3961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000154 is: 0.0727 with mean loss 0.0711 with disc loss 0.0052 with runtime 17.3866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000155 is: 0.0730 with mean loss 0.0711 with disc loss 0.0052 with runtime 17.4872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000156 is: 0.0730 with mean loss 0.0711 with disc loss 0.0051 with runtime 17.4838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 23.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000157 is: 0.0728 with mean loss 0.0712 with disc loss 0.0052 with runtime 17.5531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000158 is: 0.0729 with mean loss 0.0712 with disc loss 0.0053 with runtime 17.4019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000159 is: 0.0726 with mean loss 0.0712 with disc loss 0.0052 with runtime 17.4441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [00:17<00:00, 24.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000160 is: 0.0728 with mean loss 0.0712 with disc loss 0.0051 with runtime 17.2869\n",
            "save\n",
            "Generate 40000 graphs.\n",
            "Trying to read moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle'\n",
            "Trying to read dataset.pickle\n",
            "Trying to read deg.pickle\n",
            "Loaded checkpoint of epoch 00000161 from disk.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137476], x=[43159, 11], batch=[43159], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138376], x=[43414, 11], batch=[43414], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137968], x=[43300, 11], batch=[43300], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 138160], x=[43352, 11], batch=[43352], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137384], x=[43133, 11], batch=[43133], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137608], x=[43195, 11], batch=[43195], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 136944], x=[43008, 11], batch=[43008], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [00:25<00:06, 31.89it/s]--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
            "    resp = self._sock_client.read_server_response(timeout=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 285, in read_server_response\n",
            "    data = self._read_packet_bytes(timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 269, in _read_packet_bytes\n",
            "    raise SockClientClosedError\n",
            "wandb.sdk.lib.sock_client.SockClientClosedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
            "    msg = self._read_message()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
            "    raise MessageRouterClosedError\n",
            "wandb.sdk.interface.router.MessageRouterClosedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 77, in message_loop\n",
            "    logger.warning(\"message_loop has been closed\")\n",
            "Message: 'message_loop has been closed'\n",
            "Arguments: ()\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137896], x=[43279, 11], batch=[43279], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|â–ˆâ–Š        | 176/1000 [00:05<00:25, 31.71it/s]Exception in thread IntMsgThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
            "    local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 766, in deliver_internal_messages\n",
            "    return self._deliver_internal_messages(internal_message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 490, in _deliver_internal_messages\n",
            "    return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 437, in _deliver_record\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "    interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137368], x=[43128, 11], batch=[43128], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 137452], x=[43152, 11], batch=[43152], ptr=[1001]) tensor([  0,   0,   0,  ..., 999, 999, 999], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.66it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-28-68b08097e1b7>\", line 34, in train_base_model\n",
            "    frac, smiles_list, unique_frac = test_graph_generation(restart_inference_method=False)\n",
            "  File \"<ipython-input-21-93fa337ffc0a>\", line 42, in test_graph_generation\n",
            "    generated_graphs = gen_graphs(restart_inference_method=restart_inference_method, model_path=path_pattern)\n",
            "  File \"<ipython-input-21-93fa337ffc0a>\", line 35, in gen_graphs\n",
            "    write_file(filepath, results)\n",
            "  File \"<ipython-input-6-952c3a5bde74>\", line 25, in write_file\n",
            "    with gzip.open(filepath, 'wb') as f:\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 58, in open\n",
            "    binary_file = GzipFile(filename, gz_mode, compresslevel)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 174, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-35-a06676553879>\", line 23, in main\n",
            "    start_experiments()\n",
            "  File \"<ipython-input-29-05f43aeae5a6>\", line 14, in start_experiments\n",
            "    model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*(round_i+1), model_disc=model_disc)\n",
            "  File \"<ipython-input-28-68b08097e1b7>\", line 55, in train_base_model\n",
            "    raise e\n",
            "  File \"<ipython-input-28-68b08097e1b7>\", line 34, in train_base_model\n",
            "    frac, smiles_list, unique_frac = test_graph_generation(restart_inference_method=False)\n",
            "  File \"<ipython-input-21-93fa337ffc0a>\", line 42, in test_graph_generation\n",
            "    generated_graphs = gen_graphs(restart_inference_method=restart_inference_method, model_path=path_pattern)\n",
            "  File \"<ipython-input-21-93fa337ffc0a>\", line 35, in gen_graphs\n",
            "    write_file(filepath, results)\n",
            "  File \"<ipython-input-6-952c3a5bde74>\", line 25, in write_file\n",
            "    with gzip.open(filepath, 'wb') as f:\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 58, in open\n",
            "    binary_file = GzipFile(filename, gz_mode, compresslevel)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 174, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle'\n",
            "Exception in thread Thread-13 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-35-a06676553879>\", line 23, in main\n",
            "  File \"<ipython-input-29-05f43aeae5a6>\", line 14, in start_experiments\n",
            "  File \"<ipython-input-28-68b08097e1b7>\", line 55, in train_base_model\n",
            "  File \"<ipython-input-28-68b08097e1b7>\", line 34, in train_base_model\n",
            "  File \"<ipython-input-21-93fa337ffc0a>\", line 42, in test_graph_generation\n",
            "  File \"<ipython-input-21-93fa337ffc0a>\", line 35, in gen_graphs\n",
            "  File \"<ipython-input-6-952c3a5bde74>\", line 25, in write_file\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 58, in open\n",
            "    binary_file = GzipFile(filename, gz_mode, compresslevel)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 174, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3280, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "Trying to write moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle\n",
            "An error occurred during training: \n",
            "[Errno 107] Transport endpoint is not connected: 'moldiffusion_run6_brisk-sweep-1_False_model_epoch_00000161_040000_wFalse_generated.pickle'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r5osx48t with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-17 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yc9jhlft with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-18 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fmna44yl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-19 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 81v4g1e9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-20 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-36-0c6511c9ca55>\", line 2, in <cell line: 2>\n",
            "    start_with_wandb(set_baseline_true=True)\n",
            "  File \"<ipython-input-35-a06676553879>\", line 35, in start_with_wandb\n",
            "    wandb.agent(SWEEP_ID, function=main, count=5)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/wandb_agent.py\", line 581, in agent\n",
            "    return pyagent(sweep_id, function, entity, project, count)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 348, in pyagent\n",
            "    agent.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 314, in run\n",
            "    logger.info(\n",
            "Message: 'Starting sweep agent: entity=None, project=None, count=5'\n",
            "Arguments: ()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m os.getcwd() no longer exists, using system temp directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 5bx90lv0\n",
            "Sweep URL: https://wandb.ai/nextaid/MoldDiffGAN/sweeps/5bx90lv0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9rjs1d51 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-22 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ulrgqzyl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-23 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mhf39alv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-24 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tzc9rh05 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-25 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmgddpfr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tDISC_NOISE: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_DISC_MODEL: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCHS_GEN: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAMMA: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "    with wandb.init() as run:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1194, in init\n",
            "    logger.error(\"error\", exc_info=e)\n",
            "Message: 'error'\n",
            "Arguments: ()\n",
            "Exception in thread Thread-26 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1162, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
            "    self._wl = wandb_setup.setup(settings=setup_settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
            "    ret = _setup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
            "    wl = _WandbSetup(settings=settings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
            "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 108, in __init__\n",
            "    self._settings = self._settings_setup(settings, self._early_logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 125, in _settings_setup\n",
            "    s = wandb_settings.Settings()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 1302, in __init__\n",
            "    default_props = self._default_props()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 851, in _default_props\n",
            "    \"value\": os.path.abspath(os.getcwd()),\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-35-a06676553879>\", line 17, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1204, in init\n",
            "    raise Error(\"An unexpected error occurred\") from error_seen\n",
            "wandb.errors.Error: An unexpected error occurred\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1960, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 758, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 769, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7e168e41a2f0>> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 430, in _pause_backend\n",
            "    if self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 435, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#  noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMxSfVz/N4Xx/ktHPkh7noX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}