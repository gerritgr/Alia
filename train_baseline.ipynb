{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/Alia/blob/main/train_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCMM1H64tA7p"
      },
      "source": [
        "# AliaMolecule Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5NrAGm7to1n"
      },
      "source": [
        "#### Project Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "833DrsZU2o7r"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCeS1g3btmT9"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"AliaMoleculeDeskBaseline\"\n",
        "PATH_PATTERN = \"aliamolEllisDisc\" #aliamol2 is trained on denoised image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z7g6wEvtFrr"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9JUGxi3tEae",
        "outputId": "321606d5-fd6c-4fb5-fac5-146824dc38ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/AliaMoleculeDesk3\n"
          ]
        }
      ],
      "source": [
        "# Load drive\n",
        "\n",
        "import os\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  import wandb # need to do this before chaning cwd\n",
        "except:\n",
        "  os.system(\"pip install wandb\")\n",
        "\n",
        "\n",
        "if USE_COLAB:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9oArycxtC6J"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "\n",
        "import os\n",
        "import torch\n",
        "torch_version = torch.__version__.split(\"+\")\n",
        "#os.environ[\"TORCH\"] = torch_version[0]\n",
        "#os.environ[\"CUDA\"] = torch_version[1]\n",
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  os.system(\"pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\")\n",
        "  os.system(\"pip install torch-geometric\")\n",
        "\n",
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  os.system(\"pip install rdkit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LU94GR6x1y-"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD1DOMjwx29q",
        "outputId": "67d5b382-d5b1-47de-aa88-9698682d2412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
        "from PIL import Image # We use PIL to load images\n",
        "import seaborn as sns\n",
        "#import imageio # to generate .gifs\n",
        "import networkx as nx\n",
        "\n",
        "# always good to have\n",
        "import glob, random, os, traceback, time, copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Linear as Lin\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oscW9KW_NOTi"
      },
      "source": [
        "### Load External"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCNRU4kbNQAJ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"smiles_to_pyg\"):\n",
        "  os.system(\"git clone https://github.com/gerritgr/Alia.git && cp -R Alia/* .\")\n",
        "from smiles_to_pyg.molecule_load_and_convert import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef33eK-2yBVa"
      },
      "source": [
        "#### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3INYZ1OeyDZs"
      },
      "outputs": [],
      "source": [
        "# Diffusion\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 128*2\n",
        "EPOCHS_DISC_MODEL = 70\n",
        "DISC_NOISE=0.3\n",
        "\n",
        "LEARNING_RATE_GEN = 0.001\n",
        "EPOCHS_GEN = 100\n",
        "\n",
        "# Mol Gen\n",
        "NUM_SAMPLES = 500 # how many samples to generate for the trainings set\n",
        "NUM_GRAPHS_TO_GENERATE = 10 # during inference\n",
        "TRAIN_TEST_SPLIT = 0.8\n",
        "\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5 # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False]*5 + [True] * 5\n",
        "NON_EDGES = [True] + [True]*5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUzkUbpyRAP"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0-ubb5pwu84"
      },
      "outputs": [],
      "source": [
        "def log(d):\n",
        "  try:\n",
        "    import wandb\n",
        "    wandb.log(d)\n",
        "  except:\n",
        "    print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isR2usjlQr0k"
      },
      "outputs": [],
      "source": [
        "def load_file(filepath):\n",
        "  print(\"try to read \", filepath)\n",
        "  try:\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {str(e)}\")\n",
        "      raise\n",
        "\n",
        "def write_file(filepath, data):\n",
        "  print(\"try to write \", filepath)\n",
        "  with gzip.open(filepath, 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pb4cD9fMxkl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_dataset(seed=1234):\n",
        "  try:\n",
        "    dataset_train, dataset_test = load_file('dataset.pickle')\n",
        "    return dataset_train, dataset_test\n",
        "  except Exception as e:\n",
        "    print(f\"Could not load dataset due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  dataset = read_qm9()\n",
        "  dataset_all = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  dataset = list()\n",
        "  for g in tqdm(dataset_all):\n",
        "    try:\n",
        "      assert \"None\" not in str(pyg_to_smiles(g))\n",
        "      dataset.append(g)\n",
        "    except:\n",
        "      pass\n",
        "  print(\"Built and clean dataset, length is \", len(dataset), \"old length was\", len(dataset_all))\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset)*TRAIN_TEST_SPLIT + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0,:].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  write_file(\"dataset.pickle\", (dataset_train, dataset_test))\n",
        "  return dataset_train, dataset_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVaAhhMoySLZ"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "  \"\"\"\n",
        "  Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "  Args:\n",
        "  start (float): The starting value for the beta values. Default is START.\n",
        "  end (float): The ending value for the beta values. Default is END.\n",
        "  timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "  cumulative alpha values (alpha bars).\n",
        "  \"\"\"\n",
        "  betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "  #alphas = 1.0 - betas\n",
        "  #alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "  assert(betas.numel() == TIMESTEPS)\n",
        "  return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1QHrqCDxdwY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "def visualize_smiles_from_file(filepath):\n",
        "    # Read SMILES from file\n",
        "    with open(filepath, 'r') as file:\n",
        "        smiles_list = [line.strip() for line in file.readlines()]\n",
        "\n",
        "    # Convert SMILES to RDKit Mol objects, filtering out invalid ones\n",
        "    mols = [Chem.MolFromSmiles(smile) for smile in smiles_list[:100]]\n",
        "    mols = [mol for mol in mols if mol is not None]\n",
        "\n",
        "    # Determine grid size\n",
        "    num_mols = len(mols)\n",
        "    cols = 10\n",
        "    rows = min(10, -(-num_mols // cols))  # ceil division\n",
        "\n",
        "    # Create a subplot grid\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(20, 20),\n",
        "                            gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            ax = axs[i, j]\n",
        "            ax.axis(\"off\")  # hide axis\n",
        "            idx = i * cols + j  # index in mols list\n",
        "            if idx < num_mols:\n",
        "                img = Draw.MolToImage(mols[idx], size=(200, 200))\n",
        "                ax.imshow(img)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(filepath + '.jpg', format='jpg', bbox_inches='tight')\n",
        "    plt.close(fig)  # Close the figure after saving to free up memory\n",
        "    try:\n",
        "        time.sleep(0.01)\n",
        "        wandb.log_artifact(filepath + '.jpg', name=f\"jpg_{SWEEP_ID}_{filepath.replace('.','')}\", type=\"smiles_grid_graph\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "\n",
        "# Example usage:\n",
        "# Replace YOUR_FILE_PATH with the path to your SMILES file.\n",
        "# visualize_smiles_from_file(YOUR_FILE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnya1MDuxseM"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1FxjM0jyd1k"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  try:\n",
        "    deg = load_file('deg.pickle')\n",
        "    deg = deg.to(DEVICE)\n",
        "    return deg\n",
        "  except Exception as e:\n",
        "    print(f\"Could not find degree bin due to error: {str(e)}, generate it now\")\n",
        "  assert(train_dataset is not None)\n",
        "\n",
        "\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "\n",
        "  write_file(\"deg.pickle\", deg.cpu())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM+ TIME_FEATURE_DIM #INDICATOR_FEATURE_DIM entries are noise free\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    row_num = x_in.shape[0]\n",
        "    t = t.view(-1,TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "    assert(x.shape[0] == row_num)\n",
        "\n",
        "    #node_indicator = x_in[:,0] > 0\n",
        "    #node_indicator = x_in[:,0] < 0\n",
        "    #x[node_indicator, NON_NODES] = x_in[node_indicator, NON_NODES]\n",
        "    #x[edge_indicator, NON_EDGES] = x_in[edge_indicator, NON_EDGES]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSm4qgdXRlo0"
      },
      "outputs": [],
      "source": [
        "#path_pattern = \"aliamol_model_epoch_*.pth\"\n",
        "#sorted(glob.glob(path_pattern))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvkRRWDcrRqZ"
      },
      "outputs": [],
      "source": [
        "def load_latest_checkpoint(model, optimizer, loss_list, epoch_i, path_pattern=None):\n",
        "  if path_pattern is None:\n",
        "    path_pattern = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(path_pattern))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    loss_list = checkpoint['loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "def save_model(model, optimizer, loss_list, epoch_i, upload=False):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"{PATH_PATTERN}_model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "  if upload:\n",
        "    try:\n",
        "      wandb.log_artifact(save_path, name=f\"src_txt_{SWEEP_ID}_{epoch_i:08}_weightfile\", type=\"weight\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDm63cFIrG8K"
      },
      "outputs": [],
      "source": [
        "def load_base_model(dataset_train, path_pattern=None):\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  loss_list = None\n",
        "  optimizer = Adam(model_base.parameters(), lr = 0.1)\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0, path_pattern=path_pattern)\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4NRBuWuxUDl"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP3_DiRvGjKr"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step_wild(model, g, i):\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  #noise_pred = noise_pred.view(row_num, -1)\n",
        "  #x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  #assert(noise_pred.shape == x_with_noise.shape)\n",
        "  #future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  #original_pred = get_pred_from_noise(noise_pred, x_with_noise, future_t)\n",
        "\n",
        "  if t-1>0:\n",
        "    x_with_noise_again, _ = forward_diffusion(original_pred, t-1)\n",
        "    denoised_x[mask] = x_with_noise_again.flatten()\n",
        "  else:\n",
        "    denoised_x[mask] = original_pred.flatten()\n",
        "  return denoised_x\n",
        "\n",
        "\n",
        "\n",
        "  #x_in = g.x[mask].flatten()\n",
        "  #original_pred = get_pred_from_noise(noise_pred, x_in, future_t)\n",
        "  ##original_pred = (x_in - torch.sqrt(1. - alphas_cumprod_t) * noise_pred)/torch.sqrt(alphas_cumprod_t)\n",
        "  #assert(original_pred.shape[0] = x_in.shape[0])\n",
        "  #x = g.x.clone()\n",
        "  #x[mask] = original_pred\n",
        "  #if t-1 <= 0:\n",
        "  #  return x\n",
        "  #x_with_noise_again, _ = forward_diffusion(x, t-1)\n",
        "  #denoised_x[mask] = x_with_noise_again[mask]\n",
        "  #return denoised_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbcU3sZBxqwh"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step(model, g, i):\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  noise_pred = get_noise_from_pred(original_pred, x_with_noise, future_t)\n",
        "\n",
        "  values_now = g.x[mask].view(row_num, -1)\n",
        "  values_endpoint = noise_pred.view(row_num, -1)#[mask] network only prdicts noise\n",
        "\n",
        "  assert(values_now.shape == values_endpoint.shape)\n",
        "\n",
        "  # now compute values_one_step_denoised\n",
        "  model_mean = sqrt_recip_alphas_t * (values_now - beta_t * values_endpoint / sqrt_one_minus_alphas_cumprod_t)\n",
        "  values_one_step_denoised = model_mean # if t == 0\n",
        "  if t != 0:\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # in the paper this is in 3.2. note that sigma^2 is variance, not std\n",
        "    posterior_std_t = torch.sqrt(posterior_variance[t])\n",
        "    noise = torch.randn_like(values_now, device = DEVICE)\n",
        "    values_one_step_denoised = model_mean + posterior_std_t * noise\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  denoised_x[mask] = values_one_step_denoised.flatten()\n",
        "  return denoised_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSHkoX_-xngv"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  g.x_old = g.x.clone()\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  g.x[mask] = torch.randn_like(g.x[mask])\n",
        "  return g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbvUY6H2xaWb"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples(model, dataset_train, num=100,wild=False):\n",
        "  # Setup\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "    g = dataset_train_start[-1]\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "\n",
        "  # Inference\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    g = overwrite_with_noise(g)\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if wild:\n",
        "        x_with_less_noise = denoise_one_step_wild(model, g, i)\n",
        "      else:\n",
        "        x_with_less_noise = denoise_one_step(model, g, i)\n",
        "      g.x = x_with_less_noise\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    graph_list = [g.cpu() for g in graph_list]\n",
        "\n",
        "    print(\"generated graphs \", graph_list[:10])\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9AAQNu54u5f"
      },
      "source": [
        "#### Frac Correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na5iiitt4w63"
      },
      "outputs": [],
      "source": [
        "def find_frac_correct(graphs):\n",
        "  correct = 0\n",
        "  smiles_list = list()\n",
        "  for i, g in tqdm(list(enumerate(graphs))):\n",
        "    smiles = pyg_to_smiles(g)\n",
        "    if smiles is not None and '.' not in smiles:\n",
        "      mol = Chem.MolFromSmiles(smiles)\n",
        "      if mol is not None:\n",
        "        correct += 1\n",
        "        smiles_list.append((smiles, i))\n",
        "\n",
        "  frac_correct = correct/len(graphs)\n",
        "  return frac_correct, smiles_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8BWfguzgy5"
      },
      "source": [
        "### Gen many graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2mkhyZ2xMbc"
      },
      "outputs": [],
      "source": [
        "#!ls aliamol2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeHCO82gziKT"
      },
      "outputs": [],
      "source": [
        "def gen_graphs(num_per_generation=1000, num_generations=20, wild=False, path_pattern=None):\n",
        "  if path_pattern is None:\n",
        "    path_pattern = PATH_PATTERN+\"_model_epoch_*.pth\" #\"aliamol_model_epoch_*.pth\"\n",
        "  path = sorted(glob.glob(path_pattern))[-1]\n",
        "  num_samples = num_per_generation*num_generations\n",
        "  filepath = path.replace(\".pth\", f'_{num_samples:06d}_w{wild}_generated.pickle')\n",
        "\n",
        "  results = list()\n",
        "  try:\n",
        "    results = load_file(filepath)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  if len(results) == num_per_generation*num_generations:\n",
        "    return results\n",
        "\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  scatter_list = list()\n",
        "  model_base = load_base_model(dataset_base, path_pattern = path)\n",
        "\n",
        "  i = 0\n",
        "  while len(results) < num_samples:\n",
        "    i += 1\n",
        "    num = max(num_per_generation, len(results) - num_samples)\n",
        "    graphs = generate_examples(model_base, dataset_base, num=num, wild=wild)\n",
        "    results = results + graphs\n",
        "    if i % 5 == 0 or len(results) >= num_samples:\n",
        "      write_file(filepath, results)\n",
        "\n",
        "  assert(len(results) == num_per_generation*num_generations)\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "def test_graph_generation(path_pattern=None, wild=False):\n",
        "  generated_graphs = gen_graphs(wild=wild, path_pattern=path_pattern)\n",
        "  return find_frac_correct(generated_graphs) #0.54 #0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0p9ss6BJ_UM"
      },
      "outputs": [],
      "source": [
        "#test_graph_generation(path_pattern=\"aliamol_model_epoch_00003901.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dJOf1G5O0K"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEo07bzN4bAP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfJgXwe15QG4"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=8, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM\n",
        "    assert in_channels == 11\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    deg = deg.to(DEVICE)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=1, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "    #self.pnanet = PNA(in_channels=11, hidden_channels=hidden_channels, out_channels=1, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "    #self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch=None):\n",
        "    #print(\"before: x.shape\",x.shape, \"edge_index.shape\",edge_index.shape)\n",
        "    x = x + torch.randn_like(x)*DISC_NOISE\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    #print(\"after: x.shape\",x.shape, \"edge_index.shape\",edge_index.shape)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    #x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91xp2SGvGTSU"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer):\n",
        "  model_disc.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    #print(\"batch.x, batch.edge_index, batch.batch\", batch, batch.x, batch.edge_index, batch.batch)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    #print(\"pred \",pred, \"y \", batch.y)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZcRLtjSKIfA"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader):\n",
        "  model_disc.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaC-s2FMJkPq"
      },
      "outputs": [],
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc)\n",
        "  model_disc = model_disc.to(DEVICE)\n",
        "  weight_path = f\"discriminator_model_{round_i:05}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:05}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 1 or epoch_i == EPOCHS_DISC_MODEL-1:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      #print(loss_train,loss_test,acc_train,acc_test,t_train)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:01.3f}\")\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"discriminator_model_{round_i:05}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_disc.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH85qTaDKkF7"
      },
      "outputs": [],
      "source": [
        "def run_disc(round_i=1):\n",
        "  fake_graphs = gen_graphs(wild=True)\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  real_graphs = random.sample(dataset_base, len(fake_graphs))\n",
        "  dataset = list()\n",
        "\n",
        "  for g in fake_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(0.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  for g in real_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(1.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  random.shuffle(dataset)\n",
        "  cut_off = int(len(dataset) * 0.8)\n",
        "  dataloader_train = DataLoader(dataset[:cut_off], batch_size = BATCH_SIZE, shuffle=True)\n",
        "  dataloader_test = DataLoader(dataset[cut_off:], batch_size = BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  model_disc = train_disc_model(dataloader_train, dataloader_test, round_i)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLHpXu-W6GbJ"
      },
      "outputs": [],
      "source": [
        "#model_disc = run_disc() #0000390 is the last good one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF7pU0QnPQMb"
      },
      "source": [
        "# Forward Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQ5kwb5PTkC",
        "outputId": "25a2b86a-dd8f-44f4-fa1a-928f94a76a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((tensor([[ 1.0117],\n",
              "          [ 1.9837],\n",
              "          [-2.7044]], device='cuda:0'),\n",
              "  tensor([[ 1.1752],\n",
              "          [-1.6218],\n",
              "          [-2.7726]], device='cuda:0')),\n",
              " None,\n",
              " (tensor([[-0.4461],\n",
              "          [ 1.1887],\n",
              "          [-0.1109]], device='cuda:0'),\n",
              "  tensor([[-0.4688],\n",
              "          [ 1.1439],\n",
              "          [-0.1784]], device='cuda:0')))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "\n",
        "  if \"class 'int'\" in str(type(future_t)) or \"class 'float'\" in str(type(future_t)):\n",
        "    future_t = torch.tensor([int(future_t)] * row_num).to(DEVICE)\n",
        "\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "  assert(future_t[0] == future_t[1]) #lets assume the belong to the same graph\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # column-wise multiplication, now matrix #todo but we want row wise #.view(row_num,1)\n",
        "  assert(new_node_features_mean.shape == node_features.shape)\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) #this is a col vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) #this is a matrix\n",
        "  assert(new_node_features_mean.shape == new_node_features_std.shape)\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihPbotsmRafu"
      },
      "source": [
        "# Train Jointly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG8AOy2CfG8F"
      },
      "outputs": [],
      "source": [
        "def get_pred_from_noise(noise_pred, x_with_noise, future_t):\n",
        "\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(1.0-alphabar_t)\n",
        "  x_without_noise = x_with_noise - scaled_noise*noise_pred\n",
        "  x_without_noise = x_without_noise/torch.sqrt(alphabar_t)\n",
        "  return x_without_noise\n",
        "\n",
        "\n",
        "def get_noise_from_pred(original_pred, x_with_noise, future_t):\n",
        "\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(alphabar_t)\n",
        "  noise = x_with_noise - scaled_noise*original_pred\n",
        "  noise = noise / torch.sqrt(1.0-alphabar_t)\n",
        "\n",
        "  return noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBBNjxFxRZef"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, model_disc=None):\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  loss_list_start = list()\n",
        "  loss_row = nn.MSELoss(reduction='none')\n",
        "\n",
        "  for batch in tqdm(dataloader): #todo batches deactivated\n",
        "    if batch.x.shape[0] < 2:\n",
        "      continue\n",
        "    optimizer.zero_grad()\n",
        "    batch.to(DEVICE)\n",
        "    row_num = batch.x.shape[0]\n",
        "\n",
        "    num_graphs_in_batch = int(torch.max(batch.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, batch.batch)\n",
        "    assert(future_t.numel() == row_num)\n",
        "\n",
        "    mask = torch.concat((torch.tensor([False]*row_num, device=DEVICE).view(-1,1), batch.x[:,1:]>-0.5), dim=1) #this only works on original values\n",
        "    x_start_gt = batch.x[mask].view(row_num, FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x_start_gt, future_t)\n",
        "\n",
        "    x_in = batch.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    x_start_pred = model(x_in, future_t, batch.edge_index)\n",
        "    loss = F.mse_loss(x_start_gt, x_start_pred)\n",
        "\n",
        "\n",
        "    #row_num = x_in.shape[0]\n",
        "    #assert(x_with_noise.shape[0] == row_num)\n",
        "   # assert(noise_pred.shape[0] == row_num)\n",
        "    #assert(noise_pred.shape == x_with_noise.shape)\n",
        "    #assert(noise_pred.shape == noise_gt.shape)\n",
        "    #assert(noise_pred.shape == x_start_gt.shape)\n",
        "    #x_start_pred = get_pred_from_noise(noise_pred, x_with_noise, future_t)\n",
        "\n",
        "    #assert(F.mse_loss(get_pred_from_noise(noise_gt, x_with_noise, future_t), x_start_gt) < 0.00001)\n",
        "\n",
        "    #loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    #loss_start = F.mse_loss(x_start_gt, x_start_pred)  #multiply with torch.sqrt(1.0-alphabar_t)  #F.mse_loss(x_start_gt, x_start_pred)  # torch.sum(F.mse_loss(x_start_gt, x_start_pred, dim=1)/future_t) #torch.sum(torch.sum((x_start_gt- x_start_pred)**2,dim=1) / (1+future_t.view(-1,1)))\n",
        "    #loss_agg = loss + 0.5*loss_start\n",
        "\n",
        "    #x_in = batch.x.clone()\n",
        "    #x_in[mask] = x_start_pred.flatten()\n",
        "    #disc_loss = torch.abs(1.0- model_disc(x_in, batch.edge_index, batch=batch.batch))\n",
        "    #disc_loss = torch.mean(disc_loss)\n",
        "    #loss_agg = loss + 0.25*disc_loss\n",
        "\n",
        "    disc_loss = torch.tensor(0.0, device=DEVICE)\n",
        "    if model_disc is not None:\n",
        "      x_in[mask] = x_start_pred.flatten()\n",
        "      disc_loss = torch.mean((1.0- model_disc(x_in, batch.edge_index, batch=batch.batch))**2)\n",
        "      loss += 0.1*disc_loss\n",
        "\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    loss_list_start.append(disc_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return np.mean(loss_list),np.mean(loss_list_start), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47jE9PU9bVBC"
      },
      "outputs": [],
      "source": [
        "def log_smiles(smiles, filename):\n",
        "  try:\n",
        "    with open(filename, \"w\") as file:\n",
        "      for string in smiles:\n",
        "        file.write(str(string) + \"\\n\")\n",
        "    wandb.log_artifact(filename, name=f\"src_txt_{SWEEP_ID}_{filename}\", type=\"smiles\")\n",
        "    time.sleep(0.01)\n",
        "    visualize_smiles_from_file(filename)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQU6xUvvRf6t"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=EPOCHS_GEN, model_disc=None):\n",
        "  print(\"train base model\")\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE_GEN*0.01) #ok makes no sense\n",
        "  loss_list = list()\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "  print(\"from\", epoch_start, \"to\", epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    try:\n",
        "      loss, loss_start, time_elapsed = train_epoch(model_base, train_loader, optimizer, model_disc=model_disc)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      if epoch_i % 1 == 0 or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #plot_list(loss_list, \"train_base.png\", title=\"train loss base model\", xlabel='epoch', ylabel='loss')\n",
        "        mean_loss = np.mean([y for x,y in loss_list] + [loss])\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {mean_loss:05.4f} with start loss {loss_start:05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "        log({\"epoch\": epoch_i, \"loss\": loss, \"mean_loss\": mean_loss, \"start_loss\": loss_start, \"runtime\": time_elapsed})\n",
        "\n",
        "      if (epoch_i % 20 == 0 and epoch_i > 0) or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "        #graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "        #print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "        #plot_base(graph_loss_list, loss_list)\n",
        "        #pass\n",
        "        print(\"save\")\n",
        "        save_model(model_base, optimizer, loss_list, epoch_i+1, upload=epoch_i % 100 == 0 and epoch_i>9) #todo really +1?\n",
        "        time.sleep(0.1)\n",
        "        frac, smiles_list = test_graph_generation(wild=False)\n",
        "        frac_wild, smiles_list_wild = test_graph_generation(wild=True)\n",
        "        print(\"frac correct graphs: \", frac, \"with wild inference\", frac_wild)\n",
        "        log({\"epoch\": epoch_i, \"frac_normal\": frac, \"frac_wild\": frac_wild})\n",
        "        log_smiles(smiles_list, f\"smiles_{epoch_i}_normal.txt\")\n",
        "        log_smiles(smiles_list_wild, f\"smiles_{epoch_i}_wild.txt\")\n",
        "        try:\n",
        "          print(smiles_list[:20])\n",
        "          print(smiles_list_wild[:20])\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          pass\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBLiBcZLRokF"
      },
      "outputs": [],
      "source": [
        "def start_experiments():\n",
        "  global DISC_NOISE\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 101)\n",
        "\n",
        "  DISC_NOISE = 0.3\n",
        "  #model_disc = run_disc(round_i=1)\n",
        "  model_disc = None\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 201, model_disc=model_disc)\n",
        "\n",
        "  DISC_NOISE = 0.3\n",
        "  #model_disc = run_disc(round_i=2)\n",
        "  model_disc = None\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 301, model_disc=model_disc)\n",
        "\n",
        "  DISC_NOISE = 0.3\n",
        "  #model_disc = run_disc(round_i=3)\n",
        "  model_disc = None\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 501, model_disc=model_disc)\n",
        "\n",
        "  save_src_file() # do it again\n",
        "  return  model_base\n",
        "\n",
        "\n",
        "#0000390 is the last good one\n",
        "\n",
        "#model_base = start_experiments()# loss in epoch 0000410 is: 0.0486 with mean loss 0.0643 with start loss 1.6791 with runtime 18.3035"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFXyZBfWMfxo"
      },
      "outputs": [],
      "source": [
        "#!rm aliamol_model_epoch_00004001_010000_generated.pickle aliamol_model_epoch_00004001.pth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpKbb3ArSqg0"
      },
      "source": [
        "### With WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "719HFLnH3Eqm",
        "outputId": "ea271bea-16b9-4300-9048-b17e14a90f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/usr/local/lib/python3.10/dist-packages/wandb']\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "print(wandb.__path__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF6EmzdCYJSZ"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"AliaMol\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"ENZYMES/besttest_acc\",\n",
        "        \"goal\": \"maximize\",\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"BATCH_SIZE\": {\"values\": [128*2]},\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkqiydqAtMx7"
      },
      "outputs": [],
      "source": [
        "def save_src_file():\n",
        "  os.system(\"pip list > pip_list.txt 2>&1\")\n",
        "  for txt_file in sorted(glob.glob('*.txt')):\n",
        "    z = \"\".join(filter(str.isalnum, txt_file))\n",
        "    wandb.log_artifact(txt_file, name=f\"src_txt_{SWEEP_ID}_{z}\", type=\"my_dataset_txt\")\n",
        "  for python_file in sorted(glob.glob('*.ipynb')):\n",
        "    z = \"\".join(filter(str.isalnum, python_file))\n",
        "    wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}_{z}\", type=\"my_dataset_ipynb\")\n",
        "  for python_file in sorted(glob.glob('*.py')):\n",
        "    z = \"\".join(filter(str.isalnum, python_file))\n",
        "    wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}_{z}\", type=\"my_dataset_py\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgG12j-1yQ3X"
      },
      "outputs": [],
      "source": [
        "#! cp ../Insa/api_key.txt api_key.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoYB0l4fwBUT"
      },
      "outputs": [],
      "source": [
        "#os.system('wandb login --relogin --host=https://api.wandb.ai --key='+get_wand_api_key())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJDIzKzmtQUJ"
      },
      "outputs": [],
      "source": [
        "def get_wand_api_key():\n",
        "  import sys\n",
        "  IN_COLAB = 'google.colab' in sys.modules\n",
        "  if not IN_COLAB:\n",
        "    os.system(\"cp ~/api_key.txt api_key.txt\")\n",
        "  file_path = 'api_key.txt'\n",
        "  with open(file_path, 'r') as file:\n",
        "      api_key = file.read().strip()\n",
        "  return api_key\n",
        "\n",
        "#wandb.login(key=get_wand_api_key())\n",
        "\n",
        "def main():\n",
        "  with wandb.init() as run:\n",
        "    save_src_file()\n",
        "    for hyper_param_name in sweep_config['parameters']:\n",
        "      globals()[hyper_param_name] = run.config[hyper_param_name]\n",
        "      print(\"set \", hyper_param_name, \"=\", run.config[hyper_param_name])\n",
        "    return start_experiments()\n",
        "\n",
        "def start_with_wandb():\n",
        "  import wandb\n",
        "  global SWEEP_ID, USE_WANDB\n",
        "  USE_WANDB = True\n",
        "  os.environ[\"WANDB_MODE\"] = \"online\"\n",
        "  try:\n",
        "    SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "    wandb.agent(SWEEP_ID, function=main, count=1)\n",
        "  except Exception as e:\n",
        "    error_message = traceback.format_exc()\n",
        "    print(\"final error:\\n\", error_message)\n",
        "    with open('_error_log.txt', 'a') as f:\n",
        "      f.write(error_message + '\\n')\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cxnsmGC7yLGX",
        "outputId": "48ad0470-6d9d-4f34-8c03-ddd561de11ed"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 62doxxa7\n",
            "Sweep URL: https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lvob1skl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgerritgr\u001b[0m (\u001b[33mnextaid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculeDesk3/wandb/run-20231012_111528-lvob1skl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/runs/lvob1skl' target=\"_blank\">winter-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/runs/lvob1skl' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3/runs/lvob1skl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set  BATCH_SIZE = 256\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|██████████| 419/419 [00:16<00:00, 25.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.1623 with mean loss 0.1623 with start loss 0.0000 with runtime 16.5761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.1151 with mean loss 0.1309 with start loss 0.0000 with runtime 13.4754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.0881 with mean loss 0.1134 with start loss 0.0000 with runtime 13.5445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.0852 with mean loss 0.1072 with start loss 0.0000 with runtime 13.6023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.0787 with mean loss 0.1013 with start loss 0.0000 with runtime 13.5078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.0739 with mean loss 0.0967 with start loss 0.0000 with runtime 13.4978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.0727 with mean loss 0.0936 with start loss 0.0000 with runtime 13.4566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.0722 with mean loss 0.0912 with start loss 0.0000 with runtime 13.5055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.0717 with mean loss 0.0892 with start loss 0.0000 with runtime 13.5534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.0713 with mean loss 0.0875 with start loss 0.0000 with runtime 13.5754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.0710 with mean loss 0.0861 with start loss 0.0000 with runtime 13.5277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.0705 with mean loss 0.0849 with start loss 0.0000 with runtime 13.5506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.0701 with mean loss 0.0838 with start loss 0.0000 with runtime 13.5365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.0696 with mean loss 0.0828 with start loss 0.0000 with runtime 13.5688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.0696 with mean loss 0.0820 with start loss 0.0000 with runtime 13.5718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.0694 with mean loss 0.0812 with start loss 0.0000 with runtime 13.5961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.0693 with mean loss 0.0806 with start loss 0.0000 with runtime 13.5788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.0692 with mean loss 0.0799 with start loss 0.0000 with runtime 13.5518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.0690 with mean loss 0.0794 with start loss 0.0000 with runtime 13.5642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.0691 with mean loss 0.0789 with start loss 0.0000 with runtime 13.5644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.0688 with mean loss 0.0784 with start loss 0.0000 with runtime 13.6081\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000021 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68440], x=[21495, 11], batch=[21495], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68936], x=[21635, 11], batch=[21635], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21602, 11], batch=[21602], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68920], x=[21630, 11], batch=[21630], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68556], x=[21528, 11], batch=[21528], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68588], x=[21534, 11], batch=[21534], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69252], x=[21725, 11], batch=[21725], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68372], x=[21475, 11], batch=[21475], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69336], x=[21748, 11], batch=[21748], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68508], x=[21512, 11], batch=[21512], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68100], x=[21400, 11], batch=[21400], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68688], x=[21565, 11], batch=[21565], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69128], x=[21691, 11], batch=[21691], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69272], x=[21731, 11], batch=[21731], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21526, 11], batch=[21526], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68984], x=[21647, 11], batch=[21647], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69252], x=[21723, 11], batch=[21723], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68916], x=[21630, 11], batch=[21630], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68816], x=[21600, 11], batch=[21600], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69228], x=[21718, 11], batch=[21718], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 256.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000021 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68888], x=[21623, 11], batch=[21623], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67984], x=[21365, 11], batch=[21365], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69068], x=[21673, 11], batch=[21673], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69100], x=[21681, 11], batch=[21681], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68968], x=[21645, 11], batch=[21645], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68500], x=[21512, 11], batch=[21512], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68832], x=[21606, 11], batch=[21606], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68952], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68396], x=[21482, 11], batch=[21482], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68476], x=[21506, 11], batch=[21506], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69012], x=[21657, 11], batch=[21657], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68628], x=[21547, 11], batch=[21547], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68352], x=[21468, 11], batch=[21468], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68404], x=[21485, 11], batch=[21485], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69084], x=[21677, 11], batch=[21677], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69028], x=[21661, 11], batch=[21661], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68884], x=[21622, 11], batch=[21622], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68972], x=[21645, 11], batch=[21645], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68388], x=[21480, 11], batch=[21480], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 260.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.2497 with wild inference 0.0954\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CC1OCC2(O)CC1C2', 2), ('CCCCCC(O)CC', 6), ('CCC(O)(O)C1C2CC21', 10), ('CC1C2C34CC3C(O)C124', 13), ('CCC1(O)OC1C(C)O', 16), ('CCCC(CC)COC', 20), ('COCC(O)C(O)OC', 30), ('OC1(O)C2C3CC21CO3', 32), ('CCC(O)OCOCO', 38), ('CCC1(O)C(C)OC1O', 42), ('CCCCC(O)OC', 46), ('CCC1(C2CC2)CC1C', 47), ('OC1OC23CC2CC13', 48), ('CC12CCCC1CC2', 49), ('COCC12CC3(O)C1C32', 53), ('OC12CCCC13CC23O', 54), ('CCC1(CC)CC(C)C1', 55), ('C1C2OC3C4CC13CC24', 61), ('CCC12C(C)C1C1CC12', 67), ('CCCC1CC2CC12', 73)]\n",
            "[('CCC(O)CC1(C)CC1', 17), ('CCC12CC1CCC2C', 30), ('CCC(C)C1C(C)C1C', 37), ('CCCCCOC(C)O', 46), ('CCC(C)(C)CC(C)O', 58), ('CCC1CC(C)C1CC', 83), ('CC1C2CCCC1CC2', 85), ('CCC(CCO)C(C)O', 87), ('CC1CCC(C)C2CC12', 91), ('CCC(CC)CC(C)C', 93), ('CCCCC(O)CC', 95), ('CCCC(C)CC(C)C', 101), ('OC1CCCCC(O)C1', 109), ('CC12CCCC1CC2O', 125), ('CC1(C)CC(O)C1CO', 128), ('CCCC1CCC(C)C1', 136), ('CCC(C)C(C)CCO', 152), ('CC1CC2(CO)C(O)C12', 162), ('CCCCC1CCC1O', 164), ('CCC1CC1(CC)CC', 171)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000021 is: 0.0689 with mean loss 0.0780 with start loss 0.0000 with runtime 13.5968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000022 is: 0.0687 with mean loss 0.0776 with start loss 0.0000 with runtime 13.5172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000023 is: 0.0686 with mean loss 0.0773 with start loss 0.0000 with runtime 13.5575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000024 is: 0.0685 with mean loss 0.0769 with start loss 0.0000 with runtime 13.5544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000025 is: 0.0684 with mean loss 0.0766 with start loss 0.0000 with runtime 13.5457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000026 is: 0.0682 with mean loss 0.0763 with start loss 0.0000 with runtime 13.5182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000027 is: 0.0681 with mean loss 0.0760 with start loss 0.0000 with runtime 13.4957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000028 is: 0.0680 with mean loss 0.0757 with start loss 0.0000 with runtime 13.4508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000029 is: 0.0677 with mean loss 0.0755 with start loss 0.0000 with runtime 13.5319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000030 is: 0.0676 with mean loss 0.0752 with start loss 0.0000 with runtime 13.5656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000031 is: 0.0674 with mean loss 0.0750 with start loss 0.0000 with runtime 13.4816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000032 is: 0.0674 with mean loss 0.0748 with start loss 0.0000 with runtime 13.5326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000033 is: 0.0673 with mean loss 0.0745 with start loss 0.0000 with runtime 13.4853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000034 is: 0.0673 with mean loss 0.0743 with start loss 0.0000 with runtime 13.7100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000035 is: 0.0672 with mean loss 0.0741 with start loss 0.0000 with runtime 13.4806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000036 is: 0.0671 with mean loss 0.0740 with start loss 0.0000 with runtime 13.5521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000037 is: 0.0671 with mean loss 0.0738 with start loss 0.0000 with runtime 13.4700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000038 is: 0.0669 with mean loss 0.0736 with start loss 0.0000 with runtime 13.5427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000039 is: 0.0670 with mean loss 0.0734 with start loss 0.0000 with runtime 13.5675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000040 is: 0.0669 with mean loss 0.0733 with start loss 0.0000 with runtime 13.6104\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000041 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21604, 11], batch=[21604], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68780], x=[21590, 11], batch=[21590], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68664], x=[21558, 11], batch=[21558], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69400], x=[21767, 11], batch=[21767], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68552], x=[21527, 11], batch=[21527], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69140], x=[21693, 11], batch=[21693], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68280], x=[21449, 11], batch=[21449], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69188], x=[21706, 11], batch=[21706], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69288], x=[21735, 11], batch=[21735], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68660], x=[21558, 11], batch=[21558], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69016], x=[21658, 11], batch=[21658], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68920], x=[21630, 11], batch=[21630], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68364], x=[21473, 11], batch=[21473], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68780], x=[21591, 11], batch=[21591], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68964], x=[21644, 11], batch=[21644], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68732], x=[21579, 11], batch=[21579], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69232], x=[21719, 11], batch=[21719], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67948], x=[21357, 11], batch=[21357], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69292], x=[21736, 11], batch=[21736], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 259.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000041 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69320], x=[21744, 11], batch=[21744], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68840], x=[21608, 11], batch=[21608], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69464], x=[21785, 11], batch=[21785], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69480], x=[21790, 11], batch=[21790], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68708], x=[21572, 11], batch=[21572], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67880], x=[21334, 11], batch=[21334], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69020], x=[21659, 11], batch=[21659], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68832], x=[21607, 11], batch=[21607], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68956], x=[21641, 11], batch=[21641], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21525, 11], batch=[21525], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21602, 11], batch=[21602], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69576], x=[21817, 11], batch=[21817], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68984], x=[21650, 11], batch=[21650], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69080], x=[21676, 11], batch=[21676], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68424], x=[21492, 11], batch=[21492], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69204], x=[21712, 11], batch=[21712], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67864], x=[21333, 11], batch=[21333], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68928], x=[21633, 11], batch=[21633], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69092], x=[21677, 11], batch=[21677], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68688], x=[21565, 11], batch=[21565], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:37<00:00, 263.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.2467 with wild inference 0.0681\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CCC1CC2CC2(O)C1', 5), ('OCCCC(O)N1CC1', 12), ('O=CC(CO)C1CC1O', 15), ('CC(CCC=O)C1CN1', 16), ('C1CC23CCC24CC4N13', 17), ('C1CC23C4C1OCN2C43', 21), ('CNC(N)COCCN', 22), ('O=C1CCCNCCN1', 24), ('C1C2C3C4NC5(CC135)C24', 28), ('OC1CC2C1C1CC21O', 36), ('N=CNC1CN=C(N)C1', 41), ('CC(C)C(CN)C(C)N', 46), ('C1C2CC3CC3NC1N2', 49), ('CC12CNC1CC2CO', 52), ('CNC(=N)N(C)C=O', 57), ('O=C1CC12C1CONC12', 62), ('COC(CN)OCN', 63), ('CC1CCC(C)(N)C1O', 64), ('CCCN(CN)CCC', 66), ('CCOC12CC1CC2C', 67)]\n",
            "[('NCCC(CN)NCN', 0), ('NCCC(N)C(N)CN', 5), ('O=C1CC1CCCCO', 28), ('CCCCCC(N)CN', 45), ('NCCCC(N)NCN', 50), ('CC(C(=O)O)C(N)CO', 66), ('OCC1CCCOCO1', 74), ('NCNCCC(O)CN', 83), ('CC(C)CCC(C)CO', 127), ('CCCC(O)NCCN', 153), ('NCC(N)CCCCO', 164), ('NCC(N)C12CC1C2N', 216), ('NCNCCCCCO', 248), ('NC(N)NCNC(N)N', 267), ('CCCCNCC(C)C', 279), ('CCCCNC1NC1N', 295), ('CCNC(N)C(N)CN', 303), ('NCCCC1NC1(N)N', 304), ('CC1NC(N)C(N)C1N', 340), ('CCCCC(C)CCC', 341)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000041 is: 0.0668 with mean loss 0.0731 with start loss 0.0000 with runtime 13.6314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000042 is: 0.0669 with mean loss 0.0730 with start loss 0.0000 with runtime 13.5165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000043 is: 0.0667 with mean loss 0.0728 with start loss 0.0000 with runtime 13.4981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000044 is: 0.0666 with mean loss 0.0727 with start loss 0.0000 with runtime 13.5666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000045 is: 0.0666 with mean loss 0.0726 with start loss 0.0000 with runtime 13.4841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000046 is: 0.0666 with mean loss 0.0725 with start loss 0.0000 with runtime 13.4414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000047 is: 0.0665 with mean loss 0.0723 with start loss 0.0000 with runtime 13.6948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000048 is: 0.0664 with mean loss 0.0722 with start loss 0.0000 with runtime 13.5552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000049 is: 0.0666 with mean loss 0.0721 with start loss 0.0000 with runtime 13.5629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000050 is: 0.0664 with mean loss 0.0720 with start loss 0.0000 with runtime 13.5428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000051 is: 0.0663 with mean loss 0.0719 with start loss 0.0000 with runtime 13.5355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000052 is: 0.0662 with mean loss 0.0718 with start loss 0.0000 with runtime 13.4051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000053 is: 0.0663 with mean loss 0.0717 with start loss 0.0000 with runtime 13.4613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000054 is: 0.0662 with mean loss 0.0716 with start loss 0.0000 with runtime 13.4377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000055 is: 0.0662 with mean loss 0.0715 with start loss 0.0000 with runtime 13.4995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000056 is: 0.0661 with mean loss 0.0714 with start loss 0.0000 with runtime 13.5046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000057 is: 0.0662 with mean loss 0.0713 with start loss 0.0000 with runtime 13.4930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000058 is: 0.0660 with mean loss 0.0712 with start loss 0.0000 with runtime 13.4623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000059 is: 0.0661 with mean loss 0.0711 with start loss 0.0000 with runtime 13.6171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000060 is: 0.0660 with mean loss 0.0710 with start loss 0.0000 with runtime 13.4497\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000061 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68188], x=[21425, 11], batch=[21425], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69612], x=[21826, 11], batch=[21826], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68628], x=[21548, 11], batch=[21548], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69324], x=[21746, 11], batch=[21746], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68616], x=[21544, 11], batch=[21544], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68188], x=[21422, 11], batch=[21422], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68740], x=[21581, 11], batch=[21581], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68424], x=[21490, 11], batch=[21490], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68960], x=[21643, 11], batch=[21643], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69104], x=[21681, 11], batch=[21681], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68748], x=[21582, 11], batch=[21582], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68884], x=[21622, 11], batch=[21622], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69104], x=[21683, 11], batch=[21683], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68868], x=[21617, 11], batch=[21617], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68952], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68532], x=[21520, 11], batch=[21520], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68508], x=[21514, 11], batch=[21514], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69068], x=[21674, 11], batch=[21674], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68808], x=[21599, 11], batch=[21599], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21523, 11], batch=[21523], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 255.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000061 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68864], x=[21613, 11], batch=[21613], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68360], x=[21472, 11], batch=[21472], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69656], x=[21840, 11], batch=[21840], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69256], x=[21726, 11], batch=[21726], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68268], x=[21446, 11], batch=[21446], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68320], x=[21461, 11], batch=[21461], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68956], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68220], x=[21430, 11], batch=[21430], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68460], x=[21501, 11], batch=[21501], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69564], x=[21812, 11], batch=[21812], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68760], x=[21587, 11], batch=[21587], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69024], x=[21660, 11], batch=[21660], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68656], x=[21557, 11], batch=[21557], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68848], x=[21610, 11], batch=[21610], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69200], x=[21710, 11], batch=[21710], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69380], x=[21762, 11], batch=[21762], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69464], x=[21784, 11], batch=[21784], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68856], x=[21614, 11], batch=[21614], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69368], x=[21758, 11], batch=[21758], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69192], x=[21708, 11], batch=[21708], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 250.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.5467 with wild inference 0.8979\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CCC1C2(N)CC12CC', 5), ('CC1CC23CCC2CC13', 6), ('CCC(C)(O)CC1CC1', 9), ('CC1C(N)CCC1CN', 10), ('CC1(O)C2C3C4CC21C43', 16), ('C1COC(C2CC2)C1', 19), ('CCC1CCC1CCO', 22), ('CCC1CC2(O)OCC12', 23), ('CCCCCCC1CC1', 25), ('CCCOCC(C)=O', 26), ('CC1C(C)C23CCC12C3', 30), ('C1CC23CNC(C2)N1C3', 31), ('C1OC2CC3C1C31CC21', 32), ('NC1(O)CCCCCC1', 33), ('C=CC1(CC)C(N)C1O', 34), ('C=C1CC1C(C)O', 35), ('CCCCC(C)C1CC1', 38), ('O=CC(O)C1OC1CO', 39), ('C1CCC2C3CC23CC1', 40), ('C1COC2CCC2CN1', 41)]\n",
            "[('OC12CC3COC3C1C2', 1), ('C1CC2CC2C1', 2), ('OC1C2CCC3C(C2)C13', 3), ('CC1CC2(CC2)C12CC2', 4), ('O=C1C2C(O)CC3CC132', 5), ('C1CC2CC3CC23C1', 6), ('C1CC23CC1C21CC3C1', 7), ('C1CC23C4CC1C2C3C4', 8), ('CC1C2CCC34C1C3C24', 12), ('CC12CC1C1(C)C3C2C31', 13), ('CC1CC2CCC3C1C23', 14), ('OC12C3CCC4C(C41)C32', 15), ('CC1CC1C1C(C)C1C', 16), ('C1CC2C3CC2(C1)C3', 17), ('CCC1C2CC2C12CC2', 18), ('C1CC2CCC3CC23C1', 19), ('CC1CC2CC(C)C2C1', 20), ('CCC1CCC2CC1C2', 21), ('CC1CCC2CC(C)C12', 22), ('OC1CC1C1CC2CC21', 23)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000061 is: 0.0660 with mean loss 0.0710 with start loss 0.0000 with runtime 13.5305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000062 is: 0.0660 with mean loss 0.0709 with start loss 0.0000 with runtime 13.4906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000063 is: 0.0659 with mean loss 0.0708 with start loss 0.0000 with runtime 13.4991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000064 is: 0.0658 with mean loss 0.0707 with start loss 0.0000 with runtime 13.5918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000065 is: 0.0659 with mean loss 0.0707 with start loss 0.0000 with runtime 13.4753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000066 is: 0.0658 with mean loss 0.0706 with start loss 0.0000 with runtime 13.5339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000067 is: 0.0658 with mean loss 0.0705 with start loss 0.0000 with runtime 13.4637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000068 is: 0.0658 with mean loss 0.0704 with start loss 0.0000 with runtime 13.4013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000069 is: 0.0658 with mean loss 0.0704 with start loss 0.0000 with runtime 13.4740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000070 is: 0.0658 with mean loss 0.0703 with start loss 0.0000 with runtime 13.4499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000071 is: 0.0658 with mean loss 0.0703 with start loss 0.0000 with runtime 13.6288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000072 is: 0.0657 with mean loss 0.0702 with start loss 0.0000 with runtime 13.3921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000073 is: 0.0658 with mean loss 0.0701 with start loss 0.0000 with runtime 13.5722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000074 is: 0.0657 with mean loss 0.0701 with start loss 0.0000 with runtime 13.5794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000075 is: 0.0657 with mean loss 0.0700 with start loss 0.0000 with runtime 13.4999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000076 is: 0.0658 with mean loss 0.0700 with start loss 0.0000 with runtime 13.6954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000077 is: 0.0657 with mean loss 0.0699 with start loss 0.0000 with runtime 13.5954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000078 is: 0.0658 with mean loss 0.0699 with start loss 0.0000 with runtime 13.3849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000079 is: 0.0658 with mean loss 0.0698 with start loss 0.0000 with runtime 13.4105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000080 is: 0.0658 with mean loss 0.0698 with start loss 0.0000 with runtime 13.4848\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000081 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68848], x=[21611, 11], batch=[21611], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69832], x=[21889, 11], batch=[21889], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68860], x=[21614, 11], batch=[21614], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68600], x=[21542, 11], batch=[21542], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68932], x=[21634, 11], batch=[21634], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68764], x=[21588, 11], batch=[21588], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69256], x=[21725, 11], batch=[21725], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69120], x=[21688, 11], batch=[21688], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68396], x=[21483, 11], batch=[21483], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69356], x=[21754, 11], batch=[21754], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69224], x=[21717, 11], batch=[21717], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69488], x=[21790, 11], batch=[21790], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68776], x=[21589, 11], batch=[21589], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68844], x=[21609, 11], batch=[21609], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69336], x=[21749, 11], batch=[21749], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69232], x=[21720, 11], batch=[21720], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69388], x=[21763, 11], batch=[21763], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67928], x=[21350, 11], batch=[21350], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68680], x=[21564, 11], batch=[21564], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68884], x=[21621, 11], batch=[21621], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 257.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000081_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000081_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000081 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69040], x=[21664, 11], batch=[21664], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68552], x=[21526, 11], batch=[21526], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68756], x=[21584, 11], batch=[21584], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69000], x=[21654, 11], batch=[21654], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68312], x=[21458, 11], batch=[21458], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68776], x=[21591, 11], batch=[21591], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69600], x=[21823, 11], batch=[21823], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68948], x=[21639, 11], batch=[21639], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68648], x=[21555, 11], batch=[21555], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69160], x=[21699, 11], batch=[21699], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68812], x=[21600, 11], batch=[21600], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69148], x=[21695, 11], batch=[21695], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68588], x=[21537, 11], batch=[21537], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69036], x=[21664, 11], batch=[21664], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68976], x=[21647, 11], batch=[21647], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68556], x=[21528, 11], batch=[21528], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68068], x=[21390, 11], batch=[21390], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69256], x=[21726, 11], batch=[21726], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68988], x=[21651, 11], batch=[21651], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69440], x=[21778, 11], batch=[21778], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000081_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 254.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.4256 with wild inference 0.7912\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CCCCC1CC1(N)O', 1), ('COC1CC(C)N1', 5), ('C1CC23CCC2(CC3)O1', 8), ('CCCC1C(C)C1(C)O', 9), ('C1CC2C3COC1C23', 10), ('C=CC(=O)CC(C)CO', 13), ('CCCC1CCC1CC', 14), ('CCC(C)(C)C(O)CN', 21), ('CC1C(NO)C1(C)CO', 23), ('O=CC12OC(O)C1O2', 24), ('CNNC(C)C(C)(C)O', 26), ('CC1CC2C3CC3OC12', 27), ('CC1NCC1(C)C(=N)N', 28), ('CC1COC(C2CO2)C1', 32), ('COC(=O)C(C)CO', 34), ('NCC(O)C12COC1C2', 36), ('CCC(CC)CC=N', 41), ('NC(CCCO)C1CC1', 48), ('CC1(CO)CCN1', 50), ('COCC1C(O)C1CN', 54)]\n",
            "[('CCCCCC1CCC1', 0), ('CC12CC1C2C1C2CC21', 3), ('CC(C)CC12CC(C1)C2', 4), ('CCCCC1CCCC1', 7), ('CCCC(O)CCC=O', 8), ('CCCCCCCCC', 9), ('CCCCNCCCC', 10), ('OC(O)C12CCCC1C2', 12), ('CCCC1CC2CCC12', 13), ('CCCCCCCC', 14), ('CCC1CCCC1=O', 16), ('CCC1CCC(C=O)C1', 17), ('CCCCC1CC2CC12', 18), ('O=C1C2CC(CO)C1C2', 19), ('OCCCCC1C2CC12', 20), ('CCCCC1CC1', 21), ('CCC(C)CC1CCC1', 22), ('CCC(=O)CCCO', 23), ('CCC1CC(=O)C1CC', 25), ('CCC(CC)CCCN', 26)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000081 is: 0.0656 with mean loss 0.0697 with start loss 0.0000 with runtime 13.5111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000082 is: 0.0656 with mean loss 0.0697 with start loss 0.0000 with runtime 13.5027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000083 is: 0.0656 with mean loss 0.0696 with start loss 0.0000 with runtime 13.4072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000084 is: 0.0655 with mean loss 0.0696 with start loss 0.0000 with runtime 13.5248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000085 is: 0.0657 with mean loss 0.0695 with start loss 0.0000 with runtime 13.4047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000086 is: 0.0656 with mean loss 0.0695 with start loss 0.0000 with runtime 13.4816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000087 is: 0.0657 with mean loss 0.0694 with start loss 0.0000 with runtime 13.5044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000088 is: 0.0656 with mean loss 0.0694 with start loss 0.0000 with runtime 13.3941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000089 is: 0.0655 with mean loss 0.0693 with start loss 0.0000 with runtime 13.4824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000090 is: 0.0656 with mean loss 0.0693 with start loss 0.0000 with runtime 13.4234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000091 is: 0.0656 with mean loss 0.0693 with start loss 0.0000 with runtime 13.5148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000092 is: 0.0655 with mean loss 0.0692 with start loss 0.0000 with runtime 13.5065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000093 is: 0.0655 with mean loss 0.0692 with start loss 0.0000 with runtime 13.4553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000094 is: 0.0652 with mean loss 0.0691 with start loss 0.0000 with runtime 13.4338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000095 is: 0.0655 with mean loss 0.0691 with start loss 0.0000 with runtime 13.4423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000096 is: 0.0654 with mean loss 0.0691 with start loss 0.0000 with runtime 13.4135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000097 is: 0.0654 with mean loss 0.0690 with start loss 0.0000 with runtime 13.4080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000098 is: 0.0654 with mean loss 0.0690 with start loss 0.0000 with runtime 13.5197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000099 is: 0.0652 with mean loss 0.0690 with start loss 0.0000 with runtime 13.4267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000100 is: 0.0655 with mean loss 0.0689 with start loss 0.0000 with runtime 13.5035\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000101_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000101_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000101 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69364], x=[21756, 11], batch=[21756], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68792], x=[21594, 11], batch=[21594], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69080], x=[21675, 11], batch=[21675], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69152], x=[21696, 11], batch=[21696], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69296], x=[21738, 11], batch=[21738], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69028], x=[21662, 11], batch=[21662], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68756], x=[21585, 11], batch=[21585], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68920], x=[21629, 11], batch=[21629], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69052], x=[21669, 11], batch=[21669], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69628], x=[21830, 11], batch=[21830], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68428], x=[21490, 11], batch=[21490], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68192], x=[21426, 11], batch=[21426], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68648], x=[21554, 11], batch=[21554], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68496], x=[21510, 11], batch=[21510], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69704], x=[21853, 11], batch=[21853], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68332], x=[21464, 11], batch=[21464], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68964], x=[21643, 11], batch=[21643], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68916], x=[21629, 11], batch=[21629], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68764], x=[21586, 11], batch=[21586], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68880], x=[21621, 11], batch=[21621], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 255.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000101 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69020], x=[21657, 11], batch=[21657], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68668], x=[21559, 11], batch=[21559], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68836], x=[21607, 11], batch=[21607], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68996], x=[21652, 11], batch=[21652], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69120], x=[21688, 11], batch=[21688], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69300], x=[21739, 11], batch=[21739], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68256], x=[21443, 11], batch=[21443], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68660], x=[21558, 11], batch=[21558], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69168], x=[21700, 11], batch=[21700], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69380], x=[21762, 11], batch=[21762], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68720], x=[21575, 11], batch=[21575], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68232], x=[21436, 11], batch=[21436], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69152], x=[21697, 11], batch=[21697], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68340], x=[21466, 11], batch=[21466], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68420], x=[21485, 11], batch=[21485], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68916], x=[21631, 11], batch=[21631], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68924], x=[21632, 11], batch=[21632], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21559, 11], batch=[21559], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68792], x=[21595, 11], batch=[21595], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 254.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.5514 with wild inference 0.9204\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CCC(CO)C12CC1C2', 0), ('CC1CC2NC2(C)C1', 1), ('CC(C)N1CCCC1O', 2), ('O=C1CCCCC2CC12', 4), ('O=C1CC2OC13NC23', 5), ('COCC1C2CN12', 6), ('C=CCCCOCC=O', 7), ('ONC1CC2(CO2)C1O', 8), ('CC1OCC23CCC2C13', 11), ('CC1CC(C(C)O)C1', 13), ('CC(C(=N)CO)C1CC1', 14), ('C1CC2CC34CC23CC14', 16), ('CC(C=N)OC1CCC1', 18), ('CCC12OC13CC2C3=O', 19), ('CC12CC1(CN1CC1)C2', 20), ('OCCC1CCCCC1', 23), ('CCC12CCC13CN3C2', 24), ('CCC1CC2C(C)CC12', 25), ('CC(O)C12CN1CN2C', 26), ('CC(C=N)C1C2CN1C2', 27)]\n",
            "[('CCCC(C)C1CC1', 0), ('C1CC23CC2C32CC12', 1), ('CC1CCC23C4C1C2C43', 2), ('CC12C3C1C21C2CCC321', 3), ('CC1C(O)CC2CCC21', 4), ('CCCC1CC2CCC12', 5), ('CC12CCC13CC1CC123', 6), ('CC(C)C12C3CC1C2C3', 7), ('OC1CC12CC21CCC1', 8), ('C1CC23C1CC21CCC13', 9), ('CCC1CC1CC1CC1', 10), ('OC1C2C3C4C2C32CC142', 12), ('CCCC12CC1CC2C', 13), ('CCC1C2CC12CC', 14), ('C1CC2CC23CCC1C3', 15), ('CCC1CC1C1CC1', 16), ('C1C2CC34CC1C3C2C4', 17), ('CCC12CC(CC1C)C2', 18), ('C1C2CC3(CC13)C1CC21', 19), ('CCCC1C2CC3C1C23', 20)]\n",
            "try to read  aliamolEllisDisc_model_epoch_00000101_010000_wTrue_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "train discriminator: epoch: 00001, loss: 0.5939, loss test: 0.5272, acc: 0.691, acc test: 0.830, time: 1.478\n",
            "train discriminator: epoch: 00011, loss: 0.2777, loss test: 0.2498, acc: 0.883, acc test: 0.892, time: 1.499\n",
            "train discriminator: epoch: 00021, loss: 0.2601, loss test: 0.2431, acc: 0.893, acc test: 0.900, time: 1.457\n",
            "train discriminator: epoch: 00031, loss: 0.2235, loss test: 0.2037, acc: 0.912, acc test: 0.914, time: 1.454\n",
            "train discriminator: epoch: 00041, loss: 0.2171, loss test: 0.2128, acc: 0.914, acc test: 0.913, time: 1.473\n",
            "train discriminator: epoch: 00051, loss: 0.2159, loss test: 0.2038, acc: 0.915, acc test: 0.918, time: 1.502\n",
            "train discriminator: epoch: 00061, loss: 0.2051, loss test: 0.1797, acc: 0.920, acc test: 0.925, time: 1.554\n",
            "train discriminator: epoch: 00069, loss: 0.2068, loss test: 0.1803, acc: 0.919, acc test: 0.924, time: 1.499\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000101 from disc.\n",
            "from 101 to 201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000101 is: 0.0780 with mean loss 0.0691 with start loss 0.0396 with runtime 19.5461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000102 is: 0.0760 with mean loss 0.0692 with start loss 0.0314 with runtime 19.5833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000103 is: 0.0756 with mean loss 0.0692 with start loss 0.0303 with runtime 19.5055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000104 is: 0.0756 with mean loss 0.0693 with start loss 0.0288 with runtime 19.6764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000105 is: 0.0753 with mean loss 0.0694 with start loss 0.0281 with runtime 19.4143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000106 is: 0.0753 with mean loss 0.0694 with start loss 0.0272 with runtime 19.7013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000107 is: 0.0752 with mean loss 0.0695 with start loss 0.0270 with runtime 19.5756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000108 is: 0.0750 with mean loss 0.0695 with start loss 0.0267 with runtime 19.5127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000109 is: 0.0750 with mean loss 0.0696 with start loss 0.0261 with runtime 19.3662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000110 is: 0.0749 with mean loss 0.0696 with start loss 0.0251 with runtime 19.4774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000111 is: 0.0750 with mean loss 0.0697 with start loss 0.0256 with runtime 19.4226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000112 is: 0.0749 with mean loss 0.0697 with start loss 0.0251 with runtime 19.4971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000113 is: 0.0750 with mean loss 0.0697 with start loss 0.0254 with runtime 19.3174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000114 is: 0.0750 with mean loss 0.0698 with start loss 0.0250 with runtime 19.4125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000115 is: 0.0749 with mean loss 0.0698 with start loss 0.0249 with runtime 19.4063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000116 is: 0.0750 with mean loss 0.0699 with start loss 0.0245 with runtime 19.5373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000117 is: 0.0749 with mean loss 0.0699 with start loss 0.0246 with runtime 19.3323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000118 is: 0.0747 with mean loss 0.0700 with start loss 0.0243 with runtime 19.4742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000119 is: 0.0749 with mean loss 0.0700 with start loss 0.0239 with runtime 19.4198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000120 is: 0.0745 with mean loss 0.0700 with start loss 0.0238 with runtime 19.3790\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000121_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000121_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000121 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68784], x=[21593, 11], batch=[21593], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69356], x=[21755, 11], batch=[21755], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69112], x=[21683, 11], batch=[21683], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68248], x=[21440, 11], batch=[21440], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68856], x=[21612, 11], batch=[21612], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68520], x=[21516, 11], batch=[21516], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69172], x=[21702, 11], batch=[21702], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68840], x=[21609, 11], batch=[21609], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68564], x=[21529, 11], batch=[21529], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68808], x=[21600, 11], batch=[21600], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68804], x=[21598, 11], batch=[21598], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68900], x=[21626, 11], batch=[21626], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69044], x=[21666, 11], batch=[21666], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68980], x=[21646, 11], batch=[21646], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69032], x=[21663, 11], batch=[21663], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68852], x=[21613, 11], batch=[21613], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68972], x=[21645, 11], batch=[21645], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21525, 11], batch=[21525], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69324], x=[21745, 11], batch=[21745], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68392], x=[21481, 11], batch=[21481], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 257.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000121_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000121_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000121 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68884], x=[21621, 11], batch=[21621], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69156], x=[21699, 11], batch=[21699], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68596], x=[21539, 11], batch=[21539], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69344], x=[21749, 11], batch=[21749], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68912], x=[21628, 11], batch=[21628], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68940], x=[21636, 11], batch=[21636], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21603, 11], batch=[21603], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68740], x=[21580, 11], batch=[21580], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69480], x=[21790, 11], batch=[21790], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69204], x=[21712, 11], batch=[21712], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69064], x=[21671, 11], batch=[21671], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69248], x=[21723, 11], batch=[21723], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69372], x=[21759, 11], batch=[21759], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69372], x=[21757, 11], batch=[21757], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68836], x=[21607, 11], batch=[21607], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68880], x=[21620, 11], batch=[21620], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68920], x=[21631, 11], batch=[21631], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69032], x=[21662, 11], batch=[21662], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69232], x=[21719, 11], batch=[21719], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69200], x=[21711, 11], batch=[21711], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000121_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 256.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.2022 with wild inference 0.172\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CC12OCN1C2C=CO', 0), ('CC1NC(=CN)OCO1', 4), ('CC(C)NC1CCC1N', 7), ('O=CC=CN=COC=O', 19), ('OC12CCC1CNO2', 21), ('C1=C(C2=NCC3OC23)O1', 40), ('CN1C2CN2C1(N)CN', 49), ('CC1N=c2c3c(cn21)N=3', 50), ('OCC=CCC1C=N1', 52), ('CC(=N)NCN=CCO', 56), ('NCNC=C1N=CCO1', 66), ('NC1CC12CNC2=O', 76), ('CN1CC2CC3(NO3)C21', 81), ('NC1COC2(N)CN2C1', 83), ('OC1CCN1C1=COC1', 85), ('CC1OC2C(N)C(C)C12', 91), ('CC1NC=NC1(O)C=N', 95), ('NC12C=NN3C(=CN1)C32', 99), ('N=CC(O)C1OC12C=N2', 103), ('CCC(CO)C12N=C1N2', 105)]\n",
            "[('CNC(N)C1NCCN1', 26), ('C1NC2N3C14NCC23N4', 30), ('c1c2nc(C3CCN3)n1-2', 34), ('O=CCC1C(=O)C1=O', 36), ('C1=CC2=NC2=NN=N1', 40), ('N=C=CC=C1NC=CN1', 50), ('C1=C2NC3NC(N2)N13', 52), ('O=CC=CC(O)O', 58), ('N=CN(C1CN1)C1CN1', 64), ('N=C=CN1C2N3CNC213', 84), ('NCC1NCC(N)CN1', 104), ('C1=CNC2C3NC(N1)C23', 113), ('CC1NCC2CC(N)N21', 123), ('O=C(O)CN1CC1O', 133), ('CN1C2NC3CN3C1N2', 138), ('NCC1=NC=NN=CN1', 141), ('N=CC1COC2(CN2)C1', 142), ('O=C1NC12CC(O)N2', 143), ('N=CCNC12NC(N1)N2', 145), ('NC(N)CCN1CC1N', 147)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000121 is: 0.0748 with mean loss 0.0701 with start loss 0.0243 with runtime 19.4026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000122 is: 0.0746 with mean loss 0.0701 with start loss 0.0239 with runtime 19.4084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000123 is: 0.0746 with mean loss 0.0701 with start loss 0.0238 with runtime 19.3258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000124 is: 0.0747 with mean loss 0.0702 with start loss 0.0237 with runtime 19.3622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000125 is: 0.0748 with mean loss 0.0702 with start loss 0.0237 with runtime 19.3492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000126 is: 0.0747 with mean loss 0.0703 with start loss 0.0236 with runtime 19.3513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000127 is: 0.0746 with mean loss 0.0703 with start loss 0.0234 with runtime 19.3438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000128 is: 0.0746 with mean loss 0.0703 with start loss 0.0238 with runtime 19.4124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000129 is: 0.0747 with mean loss 0.0704 with start loss 0.0234 with runtime 19.2175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000130 is: 0.0746 with mean loss 0.0704 with start loss 0.0234 with runtime 19.3602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000131 is: 0.0744 with mean loss 0.0704 with start loss 0.0234 with runtime 19.4075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000132 is: 0.0747 with mean loss 0.0704 with start loss 0.0238 with runtime 19.4211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000133 is: 0.0745 with mean loss 0.0705 with start loss 0.0233 with runtime 19.2600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000134 is: 0.0746 with mean loss 0.0705 with start loss 0.0236 with runtime 19.3709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000135 is: 0.0745 with mean loss 0.0705 with start loss 0.0232 with runtime 19.4073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000136 is: 0.0744 with mean loss 0.0706 with start loss 0.0236 with runtime 19.3935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000137 is: 0.0744 with mean loss 0.0706 with start loss 0.0231 with runtime 19.3336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000138 is: 0.0744 with mean loss 0.0706 with start loss 0.0230 with runtime 19.3653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000139 is: 0.0743 with mean loss 0.0706 with start loss 0.0233 with runtime 19.2315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000140 is: 0.0745 with mean loss 0.0707 with start loss 0.0228 with runtime 19.5150\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000141_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000141_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000141 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68392], x=[21483, 11], batch=[21483], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68520], x=[21518, 11], batch=[21518], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68744], x=[21581, 11], batch=[21581], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69408], x=[21770, 11], batch=[21770], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68800], x=[21598, 11], batch=[21598], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69268], x=[21729, 11], batch=[21729], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68764], x=[21585, 11], batch=[21585], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68904], x=[21627, 11], batch=[21627], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69408], x=[21770, 11], batch=[21770], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68776], x=[21591, 11], batch=[21591], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69256], x=[21726, 11], batch=[21726], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69012], x=[21657, 11], batch=[21657], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68736], x=[21578, 11], batch=[21578], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68952], x=[21639, 11], batch=[21639], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69100], x=[21682, 11], batch=[21682], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69044], x=[21666, 11], batch=[21666], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68116], x=[21403, 11], batch=[21403], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69528], x=[21802, 11], batch=[21802], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68180], x=[21422, 11], batch=[21422], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68068], x=[21390, 11], batch=[21390], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:23<00:00, 41.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 260.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000141_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000141_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000141 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68960], x=[21642, 11], batch=[21642], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69428], x=[21773, 11], batch=[21773], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68480], x=[21504, 11], batch=[21504], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68924], x=[21632, 11], batch=[21632], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68936], x=[21635, 11], batch=[21635], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68744], x=[21581, 11], batch=[21581], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68676], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68728], x=[21577, 11], batch=[21577], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69076], x=[21676, 11], batch=[21676], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68880], x=[21620, 11], batch=[21620], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68632], x=[21551, 11], batch=[21551], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68584], x=[21536, 11], batch=[21536], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68688], x=[21564, 11], batch=[21564], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69308], x=[21741, 11], batch=[21741], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69100], x=[21682, 11], batch=[21682], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68264], x=[21445, 11], batch=[21445], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68652], x=[21555, 11], batch=[21555], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68680], x=[21563, 11], batch=[21563], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69540], x=[21806, 11], batch=[21806], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68556], x=[21529, 11], batch=[21529], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000141_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 257.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.2557 with wild inference 0.4924\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CC1(O)OC1(C#N)C=N', 0), ('COC(O)CN(C)OO', 3), ('N#CCCOC1CO1', 6), ('N=C(O)CC1CNC1N', 15), ('COOCCC1CCO1', 18), ('CC1N=CC1N(C)C=O', 23), ('NC1(O)C2CN2C2CN21', 25), ('C=C=CNC(C)(O)O', 27), ('COCCNCOC=O', 33), ('NC(CO)COC=O', 36), ('C=C=CC1(O)OC1C=N', 43), ('NCOCCC1CC1N', 45), ('N=CC(O)(CO)COO', 54), ('CCN1CC1OC=C=O', 69), ('OOON=C1CCC=N1', 76), ('OC1OC2C3CNC132', 77), ('NC12CNCC(N1)C2O', 79), ('CC1(CCC=O)NCO1', 80), ('N=C1C2C(N)CNC12O', 82), ('COC1NOCCC1C', 83)]\n",
            "[('O=CN1CC1OC=CO', 0), ('O=CC1=COC=CCO1', 5), ('NC12COC(O1)C2C=O', 6), ('CC1OC=COC1CO', 8), ('C1OC2OC3(O2)OC3O1', 9), ('CC(N)C1(O)COCN1', 10), ('O=CC(CO)CNCO', 11), ('COCC1OCC12CO2', 12), ('OCC(O)OC(O)CO', 13), ('O=C1CCCNCNC1', 14), ('O=C(O)C(O)CCO', 15), ('O=CCCCC(=O)O', 16), ('C=CCOC(=O)OCO', 17), ('OCCC1OCOCO1', 18), ('C=C(C(O)O)C1OC1=O', 20), ('OCCNC1(CO)CO1', 21), ('C=COC1CC1OCO', 26), ('COCN1CC2NC21O', 28), ('O=C1COCO1', 32), ('O=C1CC(=O)C(=O)O1', 34)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000141 is: 0.0744 with mean loss 0.0707 with start loss 0.0227 with runtime 19.5378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000142 is: 0.0744 with mean loss 0.0707 with start loss 0.0228 with runtime 19.3539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000143 is: 0.0745 with mean loss 0.0708 with start loss 0.0230 with runtime 19.3218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000144 is: 0.0744 with mean loss 0.0708 with start loss 0.0226 with runtime 19.4438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000145 is: 0.0745 with mean loss 0.0708 with start loss 0.0224 with runtime 19.3983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000146 is: 0.0743 with mean loss 0.0708 with start loss 0.0227 with runtime 19.3560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000147 is: 0.0744 with mean loss 0.0708 with start loss 0.0227 with runtime 19.3820\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000148 is: 0.0743 with mean loss 0.0709 with start loss 0.0227 with runtime 19.3879\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000149 is: 0.0743 with mean loss 0.0709 with start loss 0.0231 with runtime 19.4027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000150 is: 0.0743 with mean loss 0.0709 with start loss 0.0224 with runtime 19.4709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000151 is: 0.0743 with mean loss 0.0709 with start loss 0.0228 with runtime 19.5756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000152 is: 0.0744 with mean loss 0.0710 with start loss 0.0230 with runtime 19.4159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000153 is: 0.0745 with mean loss 0.0710 with start loss 0.0223 with runtime 19.4558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000154 is: 0.0742 with mean loss 0.0710 with start loss 0.0224 with runtime 19.3940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000155 is: 0.0742 with mean loss 0.0710 with start loss 0.0224 with runtime 19.4503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000156 is: 0.0743 with mean loss 0.0710 with start loss 0.0225 with runtime 19.4126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000157 is: 0.0742 with mean loss 0.0711 with start loss 0.0224 with runtime 19.4249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000158 is: 0.0741 with mean loss 0.0711 with start loss 0.0223 with runtime 19.3629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000159 is: 0.0744 with mean loss 0.0711 with start loss 0.0229 with runtime 19.4010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000160 is: 0.0742 with mean loss 0.0711 with start loss 0.0222 with runtime 19.4348\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000161_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000161_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000161 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68224], x=[21435, 11], batch=[21435], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69204], x=[21711, 11], batch=[21711], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68460], x=[21502, 11], batch=[21502], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68468], x=[21502, 11], batch=[21502], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68492], x=[21508, 11], batch=[21508], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68904], x=[21627, 11], batch=[21627], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69312], x=[21742, 11], batch=[21742], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69224], x=[21718, 11], batch=[21718], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68816], x=[21602, 11], batch=[21602], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69480], x=[21790, 11], batch=[21790], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69252], x=[21725, 11], batch=[21725], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69204], x=[21712, 11], batch=[21712], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68768], x=[21586, 11], batch=[21586], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68972], x=[21647, 11], batch=[21647], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68832], x=[21607, 11], batch=[21607], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69176], x=[21703, 11], batch=[21703], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69028], x=[21663, 11], batch=[21663], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68460], x=[21502, 11], batch=[21502], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68952], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68700], x=[21570, 11], batch=[21570], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 260.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000161_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000161_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000161 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68964], x=[21644, 11], batch=[21644], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69320], x=[21744, 11], batch=[21744], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68632], x=[21550, 11], batch=[21550], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68772], x=[21588, 11], batch=[21588], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69036], x=[21663, 11], batch=[21663], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69028], x=[21659, 11], batch=[21659], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68964], x=[21644, 11], batch=[21644], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68484], x=[21508, 11], batch=[21508], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68528], x=[21521, 11], batch=[21521], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68712], x=[21571, 11], batch=[21571], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68344], x=[21467, 11], batch=[21467], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69332], x=[21748, 11], batch=[21748], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68876], x=[21618, 11], batch=[21618], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68860], x=[21614, 11], batch=[21614], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68940], x=[21637, 11], batch=[21637], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21526, 11], batch=[21526], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68684], x=[21564, 11], batch=[21564], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68848], x=[21612, 11], batch=[21612], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69264], x=[21728, 11], batch=[21728], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000161_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:37<00:00, 264.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.1117 with wild inference 0.0173\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('C1OC23CNC(O2)N1C3', 12), ('CN=CC(C=N)CCO', 15), ('OC1NC1C1NCCO1', 18), ('OCC1C2CN1OCN2', 23), ('CC1(O)C2CC1(O)N2', 36), ('CC(C)C(N)NCCN', 50), ('CCNC1CNC1CO', 52), ('C=CC(N)=CCC(=N)N', 53), ('CCN(OC=N)C1CN1', 60), ('N=C1CNC1C(=O)C=O', 65), ('CNC1CC23OC12C3=O', 67), ('CC(C=N)C=CN1CN1', 78), ('CCN(C=O)C1NCO1', 102), ('CC(CC(=O)O)OO', 113), ('CNC(O)CC1CN1C', 116), ('CCN1CCOC1CN', 120), ('O=C1CCOCCN1', 124), ('O=C=NN1CCCC1=O', 126), ('CNC12CC1NCN2C', 141), ('CNCC1(C=O)CN1', 146)]\n",
            "[('CC(CC=N)C(=N)C=O', 24), ('CNCC(=O)C(=O)C=O', 69), ('C=CC(=N)NCCC=O', 106), ('O=CC(=O)C(=O)C=O', 108), ('N=CC(N)COCC=O', 229), ('CC(=O)N(C=O)C(C)=O', 350), ('CC(=N)N=CC(=N)C=O', 384), ('N=CC(CC=O)C(=O)O', 432), ('N=CC(C=N)NC=C=O', 457), ('O=CCOC(=O)C=O', 527), ('N=C(C=O)CC(=O)C=O', 597), ('C=C(C=N)CC(=O)C=O', 637), ('N=C=CCC(N)C=C=N', 724), ('C=C(C=O)C(=O)C=O', 792), ('O=CC(=O)C(=O)C=O', 857), ('CN(C=O)C(=O)C=O', 1008), ('N=CC(C=O)C=C=CO', 1084), ('O=CCC(=O)C(=O)O', 1112), ('C=C(O)C(=N)C(=N)C=O', 1253), ('O=CC(=O)C(=O)CO', 1295)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000161 is: 0.0743 with mean loss 0.0711 with start loss 0.0224 with runtime 19.4813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000162 is: 0.0743 with mean loss 0.0712 with start loss 0.0223 with runtime 19.4566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000163 is: 0.0741 with mean loss 0.0712 with start loss 0.0223 with runtime 19.6268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000164 is: 0.0742 with mean loss 0.0712 with start loss 0.0227 with runtime 19.4611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000165 is: 0.0741 with mean loss 0.0712 with start loss 0.0221 with runtime 19.4133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000166 is: 0.0743 with mean loss 0.0712 with start loss 0.0219 with runtime 19.2815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000167 is: 0.0742 with mean loss 0.0713 with start loss 0.0223 with runtime 19.5081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000168 is: 0.0741 with mean loss 0.0713 with start loss 0.0221 with runtime 19.3977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000169 is: 0.0742 with mean loss 0.0713 with start loss 0.0221 with runtime 19.4917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000170 is: 0.0741 with mean loss 0.0713 with start loss 0.0222 with runtime 19.4429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000171 is: 0.0742 with mean loss 0.0713 with start loss 0.0219 with runtime 19.5463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000172 is: 0.0742 with mean loss 0.0713 with start loss 0.0223 with runtime 19.5513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000173 is: 0.0740 with mean loss 0.0713 with start loss 0.0220 with runtime 19.4423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000174 is: 0.0740 with mean loss 0.0714 with start loss 0.0220 with runtime 19.4873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000175 is: 0.0741 with mean loss 0.0714 with start loss 0.0225 with runtime 19.4582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000176 is: 0.0741 with mean loss 0.0714 with start loss 0.0218 with runtime 19.5201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000177 is: 0.0741 with mean loss 0.0714 with start loss 0.0222 with runtime 19.4893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000178 is: 0.0742 with mean loss 0.0714 with start loss 0.0221 with runtime 19.3991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000179 is: 0.0741 with mean loss 0.0714 with start loss 0.0223 with runtime 19.6156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000180 is: 0.0742 with mean loss 0.0715 with start loss 0.0218 with runtime 19.6119\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000181_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000181_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000181 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68684], x=[21564, 11], batch=[21564], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69204], x=[21711, 11], batch=[21711], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68444], x=[21497, 11], batch=[21497], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69152], x=[21696, 11], batch=[21696], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68308], x=[21458, 11], batch=[21458], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68984], x=[21649, 11], batch=[21649], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69168], x=[21702, 11], batch=[21702], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68864], x=[21616, 11], batch=[21616], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69552], x=[21810, 11], batch=[21810], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68924], x=[21633, 11], batch=[21633], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68892], x=[21624, 11], batch=[21624], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69260], x=[21728, 11], batch=[21728], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69020], x=[21658, 11], batch=[21658], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69044], x=[21667, 11], batch=[21667], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68928], x=[21633, 11], batch=[21633], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68824], x=[21603, 11], batch=[21603], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69304], x=[21740, 11], batch=[21740], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69008], x=[21655, 11], batch=[21655], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68876], x=[21619, 11], batch=[21619], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68912], x=[21629, 11], batch=[21629], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 259.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000181_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000181_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000181 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69104], x=[21683, 11], batch=[21683], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68428], x=[21490, 11], batch=[21490], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68716], x=[21572, 11], batch=[21572], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68552], x=[21527, 11], batch=[21527], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69036], x=[21663, 11], batch=[21663], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68784], x=[21594, 11], batch=[21594], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68988], x=[21650, 11], batch=[21650], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68744], x=[21581, 11], batch=[21581], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69104], x=[21683, 11], batch=[21683], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68756], x=[21584, 11], batch=[21584], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68412], x=[21488, 11], batch=[21488], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69060], x=[21670, 11], batch=[21670], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69076], x=[21674, 11], batch=[21674], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68692], x=[21566, 11], batch=[21566], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69000], x=[21654, 11], batch=[21654], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68748], x=[21582, 11], batch=[21582], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68900], x=[21626, 11], batch=[21626], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68900], x=[21625, 11], batch=[21625], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69140], x=[21693, 11], batch=[21693], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68376], x=[21477, 11], batch=[21477], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000181_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 260.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.1997 with wild inference 0.2435\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('C1NC2C3CC1CON32', 6), ('C=CC1C2=COCN21', 7), ('OOCC=C1C=CC=N1', 9), ('COC1C=NC(C=O)N1', 11), ('NC1OC2C(O)C2C1=O', 21), ('NC1NC2(CCN2)O1', 22), ('C=CC1C(O)C1(O)CO', 32), ('C=CCOC(CO)NC', 36), ('CNCNCCN', 38), ('N=CNC1CC1C(N)O', 41), ('N=CC(CO)C1(N)CO1', 46), ('O=CC1CC(=O)C(O)O1', 47), ('NC1(O)OC2C(CO)C21', 49), ('CN(CO)C(O)O', 50), ('O=CC1C(O)C2OC12O', 51), ('OCC(O)CC(O)NO', 53), ('NC1CC2(CO)OC12O', 67), ('N#CNCCC1NC1=N', 81), ('CC(=O)NONC=CO', 89), ('CCC(C=NC)OC=N', 92)]\n",
            "[('O=C(C=CO)OCCO', 2), ('O=COC1OCC1CO', 4), ('COCC(N)(C=O)CO', 6), ('CC(COCO)C(N)O', 7), ('O=CCC(O)C(=O)CO', 9), ('CC(CO)OC(=O)C=O', 13), ('O=C=CCC(=O)OC=O', 21), ('C=C(C=O)OC1OC1O', 27), ('O=CC(O)N1CC1C=O', 32), ('N=CC1C(O)COC1O', 33), ('O=CCCOC(=O)O', 35), ('O=CC(=O)CC(=O)O', 40), ('CNC(CC=O)OC=O', 49), ('CC1(O)CC(O)(O)C1O', 57), ('CC1OC(=O)C=CC1=O', 62), ('O=CC(O)C1OCC1O', 64), ('O=CCOCCOC=O', 68), ('N=C1CC(=O)CC1C=O', 73), ('N=C1C(O)NC1N1CC1', 77), ('CC(=O)C(O)C1CCN1', 78)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000181 is: 0.0742 with mean loss 0.0715 with start loss 0.0220 with runtime 19.3973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000182 is: 0.0741 with mean loss 0.0715 with start loss 0.0219 with runtime 19.4473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000183 is: 0.0740 with mean loss 0.0715 with start loss 0.0217 with runtime 19.4175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000184 is: 0.0741 with mean loss 0.0715 with start loss 0.0221 with runtime 19.3799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000185 is: 0.0743 with mean loss 0.0715 with start loss 0.0219 with runtime 19.2973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000186 is: 0.0741 with mean loss 0.0715 with start loss 0.0215 with runtime 19.4464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000187 is: 0.0741 with mean loss 0.0716 with start loss 0.0217 with runtime 19.3215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000188 is: 0.0742 with mean loss 0.0716 with start loss 0.0218 with runtime 19.4148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000189 is: 0.0741 with mean loss 0.0716 with start loss 0.0223 with runtime 19.5236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000190 is: 0.0739 with mean loss 0.0716 with start loss 0.0220 with runtime 19.5063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000191 is: 0.0739 with mean loss 0.0716 with start loss 0.0219 with runtime 19.4035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000192 is: 0.0740 with mean loss 0.0716 with start loss 0.0217 with runtime 19.6233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000193 is: 0.0739 with mean loss 0.0716 with start loss 0.0216 with runtime 19.2696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000194 is: 0.0740 with mean loss 0.0716 with start loss 0.0216 with runtime 19.5247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000195 is: 0.0740 with mean loss 0.0717 with start loss 0.0219 with runtime 19.4340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000196 is: 0.0740 with mean loss 0.0717 with start loss 0.0217 with runtime 19.5479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000197 is: 0.0740 with mean loss 0.0717 with start loss 0.0216 with runtime 19.4401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000198 is: 0.0739 with mean loss 0.0717 with start loss 0.0215 with runtime 19.4003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000199 is: 0.0740 with mean loss 0.0717 with start loss 0.0221 with runtime 19.5146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000200 is: 0.0739 with mean loss 0.0717 with start loss 0.0217 with runtime 19.4992\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000201_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000201_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000201 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68592], x=[21539, 11], batch=[21539], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68732], x=[21578, 11], batch=[21578], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68860], x=[21614, 11], batch=[21614], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68852], x=[21613, 11], batch=[21613], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68292], x=[21451, 11], batch=[21451], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68896], x=[21624, 11], batch=[21624], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68832], x=[21606, 11], batch=[21606], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68700], x=[21569, 11], batch=[21569], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68472], x=[21504, 11], batch=[21504], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69068], x=[21670, 11], batch=[21670], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69100], x=[21683, 11], batch=[21683], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68796], x=[21596, 11], batch=[21596], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68152], x=[21415, 11], batch=[21415], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68664], x=[21559, 11], batch=[21559], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68696], x=[21566, 11], batch=[21566], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69008], x=[21656, 11], batch=[21656], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68468], x=[21503, 11], batch=[21503], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68836], x=[21606, 11], batch=[21606], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68856], x=[21611, 11], batch=[21611], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69152], x=[21696, 11], batch=[21696], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 261.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000201 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69052], x=[21668, 11], batch=[21668], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69456], x=[21783, 11], batch=[21783], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68520], x=[21518, 11], batch=[21518], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68824], x=[21604, 11], batch=[21604], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69336], x=[21749, 11], batch=[21749], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69044], x=[21667, 11], batch=[21667], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68824], x=[21604, 11], batch=[21604], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68268], x=[21447, 11], batch=[21447], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68344], x=[21467, 11], batch=[21467], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69172], x=[21702, 11], batch=[21702], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68272], x=[21449, 11], batch=[21449], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68472], x=[21505, 11], batch=[21505], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68792], x=[21595, 11], batch=[21595], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69284], x=[21733, 11], batch=[21733], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68816], x=[21602, 11], batch=[21602], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68740], x=[21578, 11], batch=[21578], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68512], x=[21514, 11], batch=[21514], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69236], x=[21720, 11], batch=[21720], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69072], x=[21674, 11], batch=[21674], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68988], x=[21649, 11], batch=[21649], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 256.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac correct graphs:  0.0987 with wild inference 0.0243\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CN1C=COC1', 3), ('N=C1OC(O)OC=C1O', 13), ('CN=C1CC(CO)C1O', 20), ('CC(C)(C=O)NC1CO1', 31), ('CC(C)C(=O)C1NN1O', 36), ('N=CCC1=NC2=NCC12', 52), ('O=CNCCC(=O)CO', 68), ('CCN=CC(C)ONC', 77), ('OC1N=CC2C=CC21O', 89), ('NC1=CC2=COCOC12', 102), ('CC(C)(O)C(=O)C(N)O', 105), ('O=CC1C(=O)CCC1O', 109), ('NC1CC2(CCN1)CN2', 116), ('CN=C(C)OCCCN', 142), ('OCC1N=CCCN1', 153), ('C=CC(O)=NCOC=O', 161), ('CC(O)N1C=CCO1', 169), ('COC1(O)CCOC1', 170), ('O=C1NC=NC2=C(O)N12', 174), ('CC1CCOC(N)=N1', 179)]\n",
            "[('N=CC1(C(=O)C=O)CC1', 39), ('O=CC(=O)C=O', 84), ('c1c2c3nc-3n3n-2c1-3', 96), ('O=C1N=Nc2c3nc-3n21', 106), ('O=CC1C(=O)C1=O', 156), ('N=C(O)CCC=CC=O', 214), ('c1nc2nc3c1n1c-2c31', 269), ('c1nc2ncc-2n2nc1-2', 278), ('COC(O)C(=O)C=O', 288), ('c1cc2c3c4n(n1)n4n23', 324), ('CNC(=O)OC=O', 326), ('O=CC(=O)CC(=O)O', 344), ('n1c2nc3c1c=2n1nc31', 422), ('NC=CC(=O)C(N)C=O', 485), ('O=CC(=O)C(O)C=O', 513), ('N=CC(C=N)CC(N)=O', 578), ('O=CC1NC(=O)C1O', 581), ('CN(C=O)C(=O)C=O', 663), ('C1=NN=C2C=C2N=N1', 743), ('O=CCCOC(=O)C=O', 796)]\n",
            "try to read  aliamolEllisDisc_model_epoch_00000201_010000_wTrue_generated.pickle\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "train discriminator: epoch: 00001, loss: 0.6438, loss test: 0.6029, acc: 0.501, acc test: 0.495, time: 1.494\n",
            "train discriminator: epoch: 00011, loss: 0.1022, loss test: 0.0953, acc: 0.985, acc test: 0.988, time: 1.513\n",
            "train discriminator: epoch: 00021, loss: 0.0422, loss test: 0.0334, acc: 0.990, acc test: 0.995, time: 1.603\n",
            "train discriminator: epoch: 00031, loss: 0.0263, loss test: 0.0241, acc: 0.993, acc test: 0.994, time: 1.467\n",
            "train discriminator: epoch: 00041, loss: 0.0213, loss test: 0.0226, acc: 0.993, acc test: 0.991, time: 1.464\n",
            "train discriminator: epoch: 00051, loss: 0.0180, loss test: 0.0127, acc: 0.994, acc test: 0.996, time: 1.482\n",
            "train discriminator: epoch: 00061, loss: 0.0169, loss test: 0.0164, acc: 0.994, acc test: 0.996, time: 1.474\n",
            "train discriminator: epoch: 00069, loss: 0.0166, loss test: 0.0155, acc: 0.994, acc test: 0.995, time: 1.516\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000201 from disc.\n",
            "from 201 to 301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 156/419 [00:07<00:12, 20.97it/s]--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 255, in _read_packet_bytes\n",
            "    data = self._sock.recv(self._bufsize)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
            "    resp = self._sock_client.read_server_response(timeout=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 285, in read_server_response\n",
            "    data = self._read_packet_bytes(timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 259, in _read_packet_bytes\n",
            "    raise SockClientClosedError\n",
            "wandb.sdk.lib.sock_client.SockClientClosedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
            "    msg = self._read_message()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
            "    raise MessageRouterClosedError\n",
            "wandb.sdk.interface.router.MessageRouterClosedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 77, in message_loop\n",
            "    logger.warning(\"message_loop has been closed\")\n",
            "Message: 'message_loop has been closed'\n",
            "Arguments: ()\n",
            " 82%|████████▏ | 342/419 [00:16<00:03, 21.65it/s]Exception in thread ChkStopThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "Exception in thread IntMsgThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "        self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 285, in check_stop_status\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "self._loop_check_status(    \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n",
            "self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 299, in check_internal_messages\n",
            "    local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 727, in deliver_stop_status\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n",
            "    return self._deliver_stop_status(status)    local_handle = request()\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_stop_status\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 743, in deliver_internal_messages\n",
            "    return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 428, in _deliver_record\n",
            "    return self._deliver_internal_messages(internal_message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 481, in _deliver_internal_messages\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "        interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 428, in _deliver_record\n",
            "        handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "        self.send_server_request(server_req)interface._publish(record)\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "        self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "100%|██████████| 419/419 [00:19<00:00, 21.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000201 is: 0.0714 with mean loss 0.0717 with start loss 0.0174 with runtime 19.9262\n",
            "{'epoch': 201, 'loss': 0.07137954350658704, 'mean_loss': 0.07169666526795361, 'start_loss': 0.01743150526004219, 'runtime': 19.926249742507935}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000202 is: 0.0693 with mean loss 0.0717 with start loss 0.0085 with runtime 19.5790\n",
            "{'epoch': 202, 'loss': 0.06933084683301625, 'mean_loss': 0.07167502548800994, 'start_loss': 0.008516529724468657, 'runtime': 19.57903218269348}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000203 is: 0.0692 with mean loss 0.0717 with start loss 0.0079 with runtime 19.4281\n",
            "{'epoch': 203, 'loss': 0.06923299355694673, 'mean_loss': 0.0716626358040727, 'start_loss': 0.007932434994882965, 'runtime': 19.428083896636963}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000204 is: 0.0691 with mean loss 0.0716 with start loss 0.0076 with runtime 19.6593\n",
            "{'epoch': 204, 'loss': 0.0691037491532954, 'mean_loss': 0.07164958662419685, 'start_loss': 0.0075573566006296505, 'runtime': 19.659281730651855}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000205 is: 0.0689 with mean loss 0.0716 with start loss 0.0074 with runtime 19.4313\n",
            "{'epoch': 205, 'loss': 0.06893956997300674, 'mean_loss': 0.07163570162018003, 'start_loss': 0.007365791730556041, 'runtime': 19.43133568763733}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000206 is: 0.0688 with mean loss 0.0716 with start loss 0.0072 with runtime 19.5730\n",
            "{'epoch': 206, 'loss': 0.0688276787450746, 'mean_loss': 0.07162166357160774, 'start_loss': 0.007220075250689945, 'runtime': 19.57295274734497}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000207 is: 0.0691 with mean loss 0.0716 with start loss 0.0071 with runtime 19.5348\n",
            "{'epoch': 207, 'loss': 0.06905730835079862, 'mean_loss': 0.0716104926356504, 'start_loss': 0.007091591890394546, 'runtime': 19.5348379611969}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000208 is: 0.0688 with mean loss 0.0716 with start loss 0.0070 with runtime 19.5909\n",
            "{'epoch': 208, 'loss': 0.06876731298526033, 'mean_loss': 0.07159557275462217, 'start_loss': 0.006985132479128874, 'runtime': 19.5908682346344}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000209 is: 0.0687 with mean loss 0.0716 with start loss 0.0069 with runtime 19.4647\n",
            "{'epoch': 209, 'loss': 0.06873551071543682, 'mean_loss': 0.07158186723657, 'start_loss': 0.0068510054629562795, 'runtime': 19.46470332145691}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000210 is: 0.0688 with mean loss 0.0716 with start loss 0.0068 with runtime 19.5739\n",
            "{'epoch': 210, 'loss': 0.0687586998918176, 'mean_loss': 0.07156865979237956, 'start_loss': 0.00680008170812842, 'runtime': 19.573851108551025}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000211 is: 0.0686 with mean loss 0.0716 with start loss 0.0067 with runtime 19.3833\n",
            "{'epoch': 211, 'loss': 0.06856438881208618, 'mean_loss': 0.07155364297519634, 'start_loss': 0.006715887472331346, 'runtime': 19.383328199386597}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000212 is: 0.0686 with mean loss 0.0715 with start loss 0.0067 with runtime 19.7089\n",
            "{'epoch': 212, 'loss': 0.06859029268485833, 'mean_loss': 0.07153991659006753, 'start_loss': 0.006695051448584172, 'runtime': 19.708930730819702}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000213 is: 0.0687 with mean loss 0.0715 with start loss 0.0067 with runtime 19.5669\n",
            "{'epoch': 213, 'loss': 0.06868553936019149, 'mean_loss': 0.07152708342469756, 'start_loss': 0.006658810882680207, 'runtime': 19.566942930221558}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000214 is: 0.0687 with mean loss 0.0715 with start loss 0.0066 with runtime 19.6163\n",
            "{'epoch': 214, 'loss': 0.06866070181842636, 'mean_loss': 0.07151369815086406, 'start_loss': 0.0066383077673000555, 'runtime': 19.61631155014038}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000215 is: 0.0684 with mean loss 0.0715 with start loss 0.0065 with runtime 19.4557\n",
            "{'epoch': 215, 'loss': 0.06840661989618316, 'mean_loss': 0.07149820893345889, 'start_loss': 0.00649938053064724, 'runtime': 19.455676078796387}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000216 is: 0.0686 with mean loss 0.0715 with start loss 0.0065 with runtime 19.7809\n",
            "{'epoch': 216, 'loss': 0.06863774560160739, 'mean_loss': 0.07148614775168628, 'start_loss': 0.006540616620265321, 'runtime': 19.780900955200195}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000217 is: 0.0683 with mean loss 0.0715 with start loss 0.0065 with runtime 19.5167\n",
            "{'epoch': 217, 'loss': 0.06829992558158099, 'mean_loss': 0.07147005623483636, 'start_loss': 0.00647041149246273, 'runtime': 19.51669979095459}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000218 is: 0.0684 with mean loss 0.0715 with start loss 0.0064 with runtime 19.5678\n",
            "{'epoch': 218, 'loss': 0.06842269911152936, 'mean_loss': 0.07145676267304837, 'start_loss': 0.006401919027977136, 'runtime': 19.56784749031067}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000219 is: 0.0684 with mean loss 0.0714 with start loss 0.0064 with runtime 19.4780\n",
            "{'epoch': 219, 'loss': 0.06835901986158549, 'mean_loss': 0.07144245759584743, 'start_loss': 0.006373661851425942, 'runtime': 19.478031396865845}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:19<00:00, 21.35it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-35-8d00efad9023>\", line 33, in train_base_model\n",
            "    save_model(model_base, optimizer, loss_list, epoch_i+1, upload=epoch_i % 100 == 0 and epoch_i>9) #todo really +1?\n",
            "  File \"<ipython-input-15-aca0c5002a0f>\", line 29, in save_model\n",
            "    torch.save({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 440, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 315, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 288, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileWriter(str(name)))\n",
            "RuntimeError: File aliamolEllisDisc_model_epoch_00000221.pth cannot be opened.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-43-d69f129b14bc>\", line 19, in main\n",
            "    return start_experiments()\n",
            "  File \"<ipython-input-36-300e5b4661b2>\", line 13, in start_experiments\n",
            "    model_base = train_base_model(dataloader_base, epoch_num = 301, model_disc=model_disc)\n",
            "  File \"<ipython-input-35-8d00efad9023>\", line 52, in train_base_model\n",
            "    raise e\n",
            "  File \"<ipython-input-35-8d00efad9023>\", line 33, in train_base_model\n",
            "    save_model(model_base, optimizer, loss_list, epoch_i+1, upload=epoch_i % 100 == 0 and epoch_i>9) #todo really +1?\n",
            "  File \"<ipython-input-15-aca0c5002a0f>\", line 29, in save_model\n",
            "    torch.save({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 440, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 315, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 288, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileWriter(str(name)))\n",
            "RuntimeError: File aliamolEllisDisc_model_epoch_00000221.pth cannot be opened.\n",
            "Exception in thread Thread-13 (_run_job):\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-43-d69f129b14bc>\", line 19, in main\n",
            "  File \"<ipython-input-36-300e5b4661b2>\", line 13, in start_experiments\n",
            "  File \"<ipython-input-35-8d00efad9023>\", line 52, in train_base_model\n",
            "  File \"<ipython-input-35-8d00efad9023>\", line 33, in train_base_model\n",
            "  File \"<ipython-input-15-aca0c5002a0f>\", line 29, in save_model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 440, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 315, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 288, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileWriter(str(name)))\n",
            "RuntimeError: File aliamolEllisDisc_model_epoch_00000221.pth cannot be opened.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-43-d69f129b14bc>\", line 14, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3120, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
            "    wandb.finish(exit_code=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 3852, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 419, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 360, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1925, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 1932, in _finish\n",
            "    with telemetry.context(run=self) as tel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
            "    self._run._telemetry_callback(self._obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 743, in _telemetry_callback\n",
            "    self._telemetry_flush()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 754, in _telemetry_flush\n",
            "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
            "    self._publish(rec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000220 is: 0.0685 with mean loss 0.0714 with start loss 0.0065 with runtime 19.6298\n",
            "{'epoch': 220, 'loss': 0.06849026678214494, 'mean_loss': 0.07142975064137383, 'start_loss': 0.006454479576673065, 'runtime': 19.629839420318604}\n",
            "save\n",
            "An error occurred during training: \n",
            " File aliamolEllisDisc_model_epoch_00000221.pth cannot be opened.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x2000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABkEAAAYvCAYAAAA3bFgWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADlzUlEQVR4nOz9e3Dk+V0f/L67dR1Jc790r9e7O3sZafYyxmDAZSgq5GTBBaccIA8nHEJwvBVcKcp1CrLHVeCTxIBD7BMuDj4UVU6cOJBK1QlPEVJQD4RLnISEy7EJfsDj9a60t9ld7640t50ZSTMjjaQ+f3S3ZtY7kro16m519+tVNfX7efb7G31m/vS7Pt93oVKpVAIAAAAAANBjip0eAAAAAAAAoBWEIAAAAAAAQE8SggAAAAAAAD1JCAIAAAAAAPQkIQgAAAAAANCThCAAAAAAAEBPEoIAAAAAAAA9abDTAzRibW0tr732Wvbu3ZtCodDpcQAAAAAAgA6qVCqZn5/P2972thSLG+97dEUI8tprr+Wee+7p9BgAAAAAAMAu8sorr+Ttb3/7hv+9K0KQvXv3Jqn+Zfbt29fhaQAAAAAAgE66cuVK7rnnnvX8YCNdEYLUr8Dat2+fEAQAAAAAAEiSLSs0FKMDAAAAAAA9SQgCAAAAAAD0JCEIAAAAAADQk7qiEwQAAAAAALrN6upqbty40ekxutLQ0FAGBgbu+M8RggAAAAAAwA6qVCqZnZ3NpUuXOj1KVztw4EDK5fKW5eebEYIAAAAAAMAOqgcgx44dy9jY2B39n/j9qFKp5OrVqzl79myS5K677tr2nyUEAQAAAACAHbK6uroegBw+fLjT43StPXv2JEnOnj2bY8eObftqLMXoAAAAAACwQ+odIGNjYx2epPvV/w3vpFdFCAIAAAAAADvMFVh3bif+DYUgAAAAAABATxKCAAAAAAAAPUkIAgAAAAAA7Kjjx4/nl37plzo9RgY7PQAAAAAAANB53/7t3553vvOdOxJe/Pmf/3nGx8fvfKg7JAQBAAAAAAC2VKlUsrq6msHBraOFo0ePtmGirbkOCwAAAAAAWqhSqeTq8kpHflUqlYZm/MAHPpA/+qM/yqc+9akUCoUUCoX86q/+agqFQv7zf/7Pede73pWRkZH88R//cZ5//vl8z/d8T0qlUiYmJvJN3/RN+S//5b+86c/72uuwCoVC/vW//tf5vu/7voyNjeXEiRP57d/+7Z38Z74tmyAAAAAAANBC126s5pGP/n5HfvZXPvbejA1vHQV86lOfyszMTB577LF87GMfS5I89dRTSZKf/MmfzC/8wi/kgQceyMGDB/PKK6/ku7/7u/PP/tk/y8jISP7dv/t3ed/73pfp6ence++9G/6Mn/mZn8nP/dzP5ed//ufzy7/8y/mhH/qhvPTSSzl06NDO/GVvwyYIAAAAAAD0uf3792d4eDhjY2Mpl8spl8sZGBhIknzsYx/Ld3zHd+TBBx/MoUOH8nVf93X5B//gH+Sxxx7LiRMn8k//6T/Ngw8+uOVmxwc+8IH84A/+YB566KF8/OMfz8LCQr7whS+09O9lEwQAAAAAAFpoz9BAvvKx93bsZ9+pb/zGb3zT/15YWMhP//RP53d+53fy+uuvZ2VlJdeuXcvLL7+86Z/zjne8Y/19fHw8+/bty9mzZ+94vs0IQQAAAAAAoIUKhUJDV1LtVuPj42/63x/+8Ifzh3/4h/mFX/iFPPTQQ9mzZ0++//u/P8vLy5v+OUNDQ2/634VCIWtrazs+7626918dAAAAAADYMcPDw1ldXd3y3J/8yZ/kAx/4QL7v+74vSXUz5MyZMy2ebnt0ggAAAAAAADl+/Hg+//nP58yZMzl//vyGWxonTpzIb/7mb+Yv//Iv81d/9Vf5O3/n77R8o2O7hCAAAAAAAEA+/OEPZ2BgII888kiOHj26YcfHJz/5yRw8eDDf8i3fkve9731573vfm2/4hm9o87SNKVQqlUqnh9jKlStXsn///ly+fDn79u3r9DgAAAAAAHBb169fz4svvpj7778/o6OjnR6nq232b9lobmATBAAAAAAA6ElCEAAAAAAAoCcJQQAAAAAAgJ4kBAEAAAAAAHqSEAQAAAAAAOhJQhAAAAAAAKAnCUEAAAAAAICeJAQBAAAAAAB6khAEAAAAAADoSUIQAAAAAAAg3/7t354f//Ef37E/7wMf+EC+93u/d8f+vO0QggAAAAAAAD1JCAIAAAAAAH3uAx/4QP7oj/4on/rUp1IoFFIoFHLmzJl8+ctfznd913dlYmIipVIpP/zDP5zz58+vf/cbv/EbOXXqVPbs2ZPDhw/n8ccfz+LiYn76p386v/Zrv5bf+q3fWv/z/vt//+9t/3sNtv0nAgAAAABAP6lUkhtXO/Ozh8aSQmHLY5/61KcyMzOTxx57LB/72Meqnw4N5Zu/+ZvzIz/yI/kX/+Jf5Nq1a/mJn/iJ/O2//bfzX//rf83rr7+eH/zBH8zP/dzP5fu+7/syPz+f//k//2cqlUo+/OEP5+mnn86VK1fyb//tv02SHDp0qKV/1dsRggAAAAAAQCvduJp8/G2d+dn/r9eS4fEtj+3fvz/Dw8MZGxtLuVxOkvzsz/5svv7rvz4f//jH18999rOfzT333JOZmZksLCxkZWUlf+tv/a3cd999SZJTp06tn92zZ0+WlpbW/7xOEIIAAAAAAABv8Vd/9Vf5b//tv2ViYuIt/+3555/Pd37nd+Zv/I2/kVOnTuW9731vvvM7vzPf//3fn4MHD3Zg2tsTggAAAAAAQCsNjVU3Mjr1s7dpYWEh73vf+/LP//k/f8t/u+uuuzIwMJA//MM/zJ/+6Z/mD/7gD/LLv/zL+Uf/6B/l85//fO6///47mXrHCEEAAAAAAKCVCoWGrqTqtOHh4ayurq7/72/4hm/If/yP/zHHjx/P4ODt44RCoZBv/dZvzbd+67fmox/9aO677778p//0n/Lkk0++5c/rhGJHfzoAAAAAALArHD9+PJ///Odz5syZnD9/Ph/60Idy8eLF/OAP/mD+/M//PM8//3x+//d/P0888URWV1fz+c9/Ph//+Mfzv/7X/8rLL7+c3/zN38y5c+fy8MMPr/95X/rSlzI9PZ3z58/nxo0bbf87CUEAAAAAAIB8+MMfzsDAQB555JEcPXo0y8vL+ZM/+ZOsrq7mO7/zO3Pq1Kn8+I//eA4cOJBisZh9+/blf/yP/5Hv/u7vzuTkZP7xP/7H+cVf/MV813d9V5Lkgx/8YKampvKN3/iNOXr0aP7kT/6k7X+nQqVSqbT9pzbpypUr2b9/fy5fvpx9+/Z1ehwAAAAAALit69ev58UXX8z999+f0dHRTo/T1Tb7t2w0N7AJAgAAAAAA9CQhCAAAAAAA0JOEIAAAAAAAQE8SggAAAAAAAD1JCAIAAAAAAPQkIQgAAAAAAOywtbW1To/Q9Xbi33BwB+YAAAAAAACSDA8Pp1gs5rXXXsvRo0czPDycQqHQ6bG6SqVSyfLycs6dO5disZjh4eFt/1lCEAAAAAAA2CHFYjH3339/Xn/99bz22mudHqerjY2N5d57702xuP1LrYQgAAAAAACwg4aHh3PvvfdmZWUlq6urnR6nKw0MDGRwcPCOt2iEIAAAAAAAsMMKhUKGhoYyNDTU6VH6mmJ0AAAAAACgJwlBAAAAAACAniQEAQAAAAAAepIQBAAAAAAA6ElCEAAAAAAAoCcJQQAAAAAAgJ4kBAEAAAAAAHqSEAQAAAAAAOhJQhAAAAAAAKAnCUEAAAAAAICeJAQBAAAAAAB6khAEAAAAAADoSUIQAAAAAACgJwlBulSlUsn/4//7f+bxT/5Rzl653ulxAAAAAABg1xGCdKlCoZCnXruc584u5JnZ+U6PAwAAAAAAu44QpItNlfYmSWbmhCAAAAAAAPC1hCBdbLIWgkzbBAEAAAAAgLcQgnSxqbJNEAAAAAAA2IgQpItNrl+HtZC1tUqHpwEAAAAAgN1FCNLFjh8ey/BgMddurOarb1zr9DgAAAAAALCrCEG62OBAMQ8dnUiSTLsSCwAAAAAA3kQI0uXqvSDTs1c6PAkAAAAAAOwuQpAuV+8FmZ5b6PAkAAAAAACwuwhButxUuXod1sys67AAAAAAAOBWQpAuV98Eef7cQpZX1jo8DQAAAAAA7B5CkC5394E9GR8eyMpaJWcuLHZ6HAAAAAAA2DWEIF2uUChkcr0c3ZVYAAAAAABQJwTpASdrIcjMnBAEAAAAAADqhCA9oN4L8oxNEAAAAAAAWCcE6QFTJZsgAAAAAADwtYQgPaDeCfLyxau5urzS4WkAAAAAAGB3EIL0gCMTIzk8PpxKJXnu7EKnxwEAAAAAgF1BCNIj6r0g03pBAAAAAAAgiRCkZ0yV9YIAAAAAAMCthCA9oh6CTM+5DgsAAAAAABIhSM+4eR3WlQ5PAgAAAAAAu4MQpEdMliaSJHNXlnLp6nKHpwEAAAAAgM4TgvSIvaNDufvAniTJjCuxAAAAAABACNJL6tsg08rRAQAAAABACNJLJmvl6DOzQhAAAAAAABCC9JCTtRDEJggAAAAAAAhBespkqRaCzM6nUql0eBoAAAAAAOgsIUgPefDoRIqF5PK1Gzk7v9TpcQAAAAAAoKOEID1kdGggx4+MJ6lugwAAAAAAQD8TgvSYqdqVWDN6QQAAAAAA6HNCkB5zay8IAAAAAAD0MyFIj5kq2wQBAAAAAIBECNJzboYgC1lbq3R4GgAAAAAA6BwhSI+579BYhgeLuXZjNa+8cbXT4wAAAAAAQMcIQXrM4EAxDx2dSKIXBAAAAACA/iYE6UF6QQAAAAAAQAjSkyZL1RBkem6hw5MAAAAAAEDnCEF60FS5eh3WjOuwAAAAAADoY0KQHjRV3pckef7cQpZX1jo8DQAAAAAAdIYQpAe9bf9oJkYGs7JWyZkLi50eBwAAAAAAOkII0oMKhUImS9UrsZ5xJRYAAAAAAH1KCNKjpsrVcnS9IAAAAAAA9CshSI+aLFVDkOk5IQgAAAAAAP1JCNKjpmohyIwQBAAAAACAPiUE6VGTteuwXr54NVeXVzo8DQAAAAAAtJ8QpEcdmRjJkYnhVCrJc2cXOj0OAAAAAAC0nRCkh633gihHBwAAAACgDwlBepgQBAAAAACAfiYE6WFTtV6QaeXoAAAAAAD0ISFID6tvgswIQQAAAAAA6ENCkB42WZpIksxdWcqlq8sdngYAAAAAANpLCNLD9o4O5e4De5IkM3MLHZ4GAAAAAADaSwjS4/SCAAAAAADQr4QgPa7eCzI9e6XDkwAAAAAAQHsJQXrcVLnaCzIz6zosAAAAAAD6ixCkx61vgszNp1KpdHgaAAAAAABoHyFIj3vw6ESKheTytRs5O7/U6XEAAAAAAKBthCA9bnRoIMePjCdJpmeVowMAAAAA0D+EIH1gqnYl1sycEAQAAAAAgP4hBOkDU+VaL4hNEAAAAAAA+ogQpA9M3VKODgAAAAAA/UII0gcmyzevw1pbq3R4GgAAAAAAaA8hSB+479BYhgeLuX5jLa+8cbXT4wAAAAAAQFsIQfrA4EAxDx2dSKIXBAAAAACA/iEE6RNTt1yJBQAAAAAA/UAI0ifqIcj03EKHJwEAAAAAgPYQgvSJqVJtE8R1WAAAAAAA9AkhSJ+YrG2CPH9uIcsrax2eBgAAAAAAWk8I0ifetn80EyODWVmr5MXzi50eBwAAAAAAWk4I0icKhUImSxNJkmnl6AAAAAAA9AEhSB+pl6PrBQEAAAAAoB8IQfrIZK0c3SYIAAAAAAD9QAjSR9Y3QYQgAAAAAAD0ASFIH5mqbYK8fPFqri6vdHgaAAAAAABoLSFIHzk8MZIjE8OpVJJn5xY6PQ4AAAAAALSUEKTP6AUBAAAAAKBfCEH6TD0EmZkVggAAAAAA0NuEIH2mXo5uEwQAAAAAgF4nBOkz65sgQhAAAAAAAHqcEKTPTJYmkiRzV5Zy6epyh6cBAAAAAIDWEYL0mb2jQ7n7wJ4kybReEAAAAAAAepgQpA/Ve0FciQUAAAAAQC8TgvShei+IcnQAAAAAAHqZEKQPTZWrvSAzswsdngQAAAAAAFpHCNKHbt0EqVQqHZ4GAAAAAABaQwjShx48OpGBYiGXr93I2fmlTo8DAAAAAAAtIQTpQ6NDAzl+eCxJMj2rFwQAAAAAgN4kBOlTU+XalVhCEAAAAAAAepQQpJtVKsnFF5O1taY/vbUXBAAAAAAAepEQpFtVKskvTiX/n3cmb7zY9OdTtRBkRggCAAAAAECPEoJ0q0Ih2fe26vvs6aY/nyzfDEHW1io7ORkAAAAAAOwKQpBuVnqs+pz7ctOf3ndoLMODxVy/sZZX3ri6w4MBAAAAAEDnCUG6Wfkd1eds8yHI4EAxJ45NJFGODgAAAABAb9pWCPIrv/IrOX78eEZHR/Pud787X/jCFzY9f+nSpXzoQx/KXXfdlZGRkUxOTuZ3f/d3tzUwtyhvfxMk0QsCAAAAAEBvG2z2g1//9V/Pk08+mU9/+tN597vfnV/6pV/Ke9/73kxPT+fYsWNvOb+8vJzv+I7vyLFjx/Ibv/Ebufvuu/PSSy/lwIEDOzF/fys9Wn1efiW5ejEZO9TU5/VekGdsggAAAAAA0IOaDkE++clP5oMf/GCeeOKJJMmnP/3p/M7v/E4++9nP5id/8iffcv6zn/1sLl68mD/90z/N0NBQkuT48eOb/oylpaUsLS2t/+8rV640O2Z/GN2fHLg3ufRyMvdUcv+3NfW5TRAAAAAAAHpZU9dhLS8v5y/+4i/y+OOP3/wDisU8/vjj+bM/+7PbfvPbv/3bec973pMPfehDKZVKeeyxx/Lxj388q6urG/6cT3ziE9m/f//6r3vuuaeZMftL6VT1uY0rseqbIC+cW8zyytpOTgUAAAAAAB3XVAhy/vz5rK6uplQqven3S6VSZmdnb/vNCy+8kN/4jd/I6upqfvd3fzf/5J/8k/ziL/5ifvZnf3bDn/ORj3wkly9fXv/1yiuvNDNmf6n3gmyjHP1t+0czMTKYlbVKXjy/uMODAQAAAABAZzV9HVaz1tbWcuzYsfyrf/WvMjAwkHe961159dVX8/M///P5qZ/6qdt+MzIykpGRkVaP1htK9XL0001/WigUMlmayBdfvpTpuflM1TZDAAAAAACgFzS1CXLkyJEMDAxkbm7uTb8/NzeXcrl822/uuuuuTE5OZmBgYP33Hn744czOzmZ5eXkbI/Mm9U2Qs88kqytNfz5V3pckmVGODgAAAABAj2kqBBkeHs673vWufO5zn1v/vbW1tXzuc5/Le97zntt+863f+q157rnnsrZ2s3NiZmYmd911V4aHh7c5NusOHE+GJ5LVpeTCs01/PlWaSJI8IwQBAAAAAKDHNBWCJMmTTz6Zz3zmM/m1X/u1PP300/nRH/3RLC4u5oknnkiSvP/9789HPvKR9fM/+qM/mosXL+bHfuzHMjMzk9/5nd/Jxz/+8XzoQx/aub9FPysWb16JtY1ekHo5+sycEAQAAAAAgN7SdCfID/zAD+TcuXP56Ec/mtnZ2bzzne/M7/3e762Xpb/88sspFm9mK/fcc09+//d/P//wH/7DvOMd78jdd9+dH/uxH8tP/MRP7Nzfot+VH0te+f/VekH+b019OlWqhiAvX7yaq8srGRtueU0MAAAAAAC0RaFSqVQ6PcRWrly5kv379+fy5cvZt29fp8fZff7Xv03+jx9PHvy/JD/8n5r+/Bt/9g9zfmE5v/Whb83X3XNgx8cDAAAAAICd1Ghu0PR1WOxC5VPV5zauw0qSydo2yLQrsQAAAAAA6CFCkF5w7OEkhWTxbLJwtunPp+q9IMrRAQAAAADoIUKQXjA8nhx+sPo+e7rpz6dsggAAAAAA0IOEIL2i9Fj1Odf8lViTtU2QaZsgAAAAAAD0ECFIryjXQpBt9IKcODaRJDk7v5Q3Fpd3cioAAAAAAOgYIUivKL+j+tzGJsje0aHcfWBPkmTGlVgAAAAAAPQIIUivqF+HdX4mWVlq+vP1cnQhCAAAAAAAPUII0iv2vS3ZczBZW0nOPdP055PK0QEAAAAA6DFCkF5RKNzcBpk93fTnJ+ubILMLOzkVAAAAAAB0jBCkl5RPVZ/bKEe/dROkUqns5FQAAAAAANARQpBeUt8E2UY5+gNHxzNQLOTytRuZu9J8pwgAAAAAAOw2QpBeUr7lOqwmtzlGhwZy/PBYEr0gAAAAAAD0BiFILzl6MikOJtcvJVdebfrzqfVeECEIAAAAAADdTwjSSwZHkiOT1fc77AUBAAAAAIBuJwTpNfVy9LnTTX86VQtBZoQgAAAAAAD0ACFIr6mXo29jE2T9Oqy5+aytNdcpAgAAAAAAu40QpNfcWo7epPsOj2d4sJjrN9byyhtXd3gwAAAAAABoLyFIrynVrsO6+EKyvNjUpwPFQk4cm0iSPKMcHQAAAACALicE6TUTR5OJUpJKMveVpj9f7wURggAAAAAA0OWEIL2o3guyjXL0yVovyLRydAAAAAAAupwQpBeV76AcvXSzHB0AAAAAALqZEKQX1XtB5rYRgtQ2QV44t5jllbWdnAoAAAAAANpKCNKL6psgc08la80FGXftH83ekcGsrFXy4vnmitUBAAAAAGA3EYL0osMnkoGRZHkhuXSmqU8LhcJ6L8gzs1daMBwAAAAAALSHEKQXDQwmxx6uvm+jF2RSLwgAAAAAAD1ACNKr1svRTzf96VRpIkkyPbuwkxMBAAAAAEBbCUF61R2Uo9evw7IJAgAAAABANxOC9Kr1TZDmQ5Cp2nVYL1+8mqvLKzs5FQAAAAAAtI0QpFeVHq0+L7+cXLvU1KeHJ0ZyZGIkSfLsnCuxAAAAAADoTkKQXrXnYLL/nur73FNNfz5VrvWCuBILAAAAAIAuJQTpZaXalVjb6QWpXYk1PSsEAQAAAACgOwlBetl6L8jppj+t94IoRwcAAAAAoFsJQXpZ+VT1uZ1NkLJNEAAAAAAAupsQpJfVr8M6+3SyutLUpyeOVTtBzs4v5Y3F5Z2eDAAAAAAAWk4I0ssO3p8MTyQr15MLzzX16d7Rodx9YE8SV2IBAAAAANCdhCC9rFhMjj1Sfd/GlVgny3pBAAAAAADoXkKQXncH5ejrvSBCEAAAAAAAupAQpNfVe0G2sQkyVVKODgAAAABA9xKC9LryqepztvkQZPKWEKRSqezkVAAAAAAA0HJCkF537JEkhWRhNlk839SnDxwdz0CxkCvXVzJ3Zak18wEAAAAAQIsIQXrdyERy6P7qe5O9IKNDAzl+eCyJXhAAAAAAALqPEKQf1K/E2k4vSK0cfUYvCAAAAAAAXUYI0g9K2+8FmSrtS2ITBAAAAACA7iME6Qflx6rPJq/DSpKp8kSSZEYIAgAAAABAlxGC9INSLQQ5P52sNFdwPlmqXYc1N5/VtcpOTwYAAAAAAC0jBOkH+9+ejO5P1laSc9NNfXrf4fEMDxZz/cZaXrl4tUUDAgAAAADAzhOC9INC4WYvSJPl6APFQk4cq16JpRcEAAAAAIBuIgTpF+u9INspR69diTUrBAEAAAAAoHsIQfpFvRdkbjvl6NUQxCYIAAAAAADdRAjSL27dBKk0V3A+Wb5Zjg4AAAAAAN1CCNIvjj6cFAaSaxeT+deb+rR+HdYL5xazvLLWiukAAAAAAGDHCUH6xdBocmSy+t5kL8hd+0ezd2QwK2uVvHB+oQXDAQAAAADAzhOC9JP1K7G+1NRnhUJh/UqsaeXoAAAAAAB0CSFIP1kvR29uEyRJJkt6QQAAAAAA6C5CkH5yazl6k6ZKE0mS6VnXYQEAAAAA0B2EIP2kdKr6vPh8sny1qU+nyvuS2AQBAAAAAKB7CEH6yd5SMn40qawlZ59u6tPJ2ibIyxev5urySiumAwAAAACAHSUE6TfrvSCnm/rs8MRIjkyMJElm5lyJBQAAAADA7icE6Td30gtSrm6DzMy6EgsAAAAAgN1PCNJvyu+oPueaD0EmS3uTJNN6QQAAAAAA6AJCkH5TumUTZG2tqU+naiGIcnQAAAAAALqBEKTfHDmRDAwny/PJpZea+nSyXNsEcR0WAAAAAABdQAjSbwaGkqMnq+9NXolVvw7r7PxS3lhc3unJAAAAAABgRwlB+lH5VPXZZDn6xMhg3n5wTxJXYgEAAAAAsPsJQfpRvRdkG+XoU8rRAQAAAADoEkKQflSul6OfbvpTvSAAAAAAAHQLIUg/qm+CXHopuX6lqU/rmyCuwwIAAAAAYLcTgvSjsUPJvrdX3+eeaurTejn69Ox8KpXKTk8GAAAAAAA7RgjSr8rb6wV58Nh4BoqFXLm+krkrSy0YDAAAAAAAdoYQpF/Vr8Sa/VJTn40MDuT+I+NJlKMDAAAAALC7CUH61Xo5enObIMnNXpDp2eb6RAAAAAAAoJ2EIP2qdKr6PPt0srba1Kc3e0EWdnoqAAAAAADYMUKQfnXo/mRoLFm5llx4vqlPp8oTSZIZ12EBAAAAALCLCUH6VXEgOfZI9X3udFOf1jdBnj07n9W1yk5PBgAAAAAAO0II0s+22Qty3+HxjAwWc/3GWl65eLUFgwEAAAAAwJ0TgvSzUi0EmWsuBBkoFnKiVL0Sa9qVWAAAAAAA7FJCkH5Wfkf12eQmSHLzSqyZWSEIAAAAAAC7kxCkn5VqnSDzryWLF5r6dKoWgjxjEwQAAAAAgF1KCNLPRvYmB++vvjdbjl62CQIAAAAAwO4mBOl32yxHr2+CvHh+MUsrqzs9FQAAAAAA3DEhSL8rnao+myxHv2v/aPaODGZlrZIXzy+2YDAAAAAAALgzQpB+t81NkEKhsH4l1rQrsQAAAAAA2IWEIP2uVAtBzj2TrCw39elUvRdEOToAAAAAALuQEKTfHbg3GdmfrN1Izs809Wm9F2R6dqEVkwEAAAAAwB0RgvS7QiEpPVp9b7IXZLIegsxd2empAAAAAADgjglBSMq1cvTZ0019NlmaSJK8cvFaFpdWdnoqAAAAAAC4I0IQbpajN7kJcnhiJEcmRpIkz551JRYAAAAAALuLEISb5eizp5NKpalPp8rVbZCZWeXoAAAAAADsLkIQkmMPJ4VicvVCMj/b1KdTpX1Jkuk5IQgAAAAAALuLEIRkaE9y+ET1vckrsdY3QYQgAAAAAADsMkIQqsq3XInVhMnS3iTJtOuwAAAAAADYZYQgVJW2V45+ohaCnJ1fyhuLyzs9FQAAAAAAbJsQhKryqepztrkQZGJkMG8/uCeJXhAAAAAAAHYXIQhV9U2QC88mN6419elUbRtELwgAAAAAALuJEISqveVk7EhSWUvOPt3Up5NlvSAAAAAAAOw+QhCqCoWb5ehN9oKcLNsEAQAAAABg9xGCcFP9SqzZ0019Nlm6uQlSqVR2eioAAAAAANgWIQg3bbMc/YGj4xkoFnLl+kpmr1xvwWAAAAAAANA8IQg31TdB5p5KmtjoGBkcyP1HxpPoBQEAAAAAYPcQgnDTkcmkOJQsXU4uvdzUp1MlvSAAAAAAAOwuQhBuGhxOjp6svjdZjn6zF2Rhp6cCAAAAAIBtEYLwZuV6OXpzIchUeSKJTRAAAAAAAHYPIQhvtt4Lcrqpz6bK+5Ikz56dz+pa430iAAAAAADQKkIQ3qx8qvpschPk3kNjGRks5vqNtbxy8WoLBgMAAAAAgOYIQXizegjyxovJUuNXWw0UCzlRql6J9cysK7EAAAAAAOg8IQhvNnYo2fu26vvcU019Wi9H1wsCAAAAAMBuIAThrdbL0ZvsBamFINNCEAAAAAAAdgEhCG+1Xo7eXC/IZLm2CeI6LAAAAAAAdgEhCG+1vgnSXAhyshaCvHh+MUsrqzs9FQAAAAAANEUIwluVauXoZ7+SrDUeZpT3jWbv6GBW1ip58fxii4YDAAAAAIDGCEF4q8MPJoN7khtXk4svNvxZoVC42QviSiwAAAAAADpMCMJbFQeSYw9X3+eaK0ev94IIQQAAAAAA6DQhCLdXrl2J1WQvSH0TZGZOCAIAAAAAQGcJQbi9eggy11wIMlm/DksIAgAAAABAhwlBuL3SY9XnbHPXYU3VrsN65eK1LC6t7PRUAAAAAADQMCEIt1d6tPq88mpy9WLDnx0aH87RvSNJkmfPLrRiMgAAAAAAaIgQhNsb3ZccuK/63uSVWOu9IMrRAQAAAADoICEIG9tmObpeEAAAAAAAdgMhCBur94I0uwlSnkiSTNsEAQAAAACgg4QgbKy8vXJ0myAAAAAAAOwGQhA2Vt8EOfdMsnqj4c9O1EKQc/NLubi43IrJAAAAAABgS0IQNnbgvmRkX7K6nJx/tuHPJkYG8/aDe5IkM7ZBAAAAAADoECEIGysWk9Kj1fcmr8Q6Wa5ugwhBAAAAAADoFCEIm1svR99mL4hydAAAAAAAOkQIwubWy9G/3NRnU2UhCAAAAAAAnSUEYXOlU9XnXHMhyPomyNx8KpXKTk8FAAAAAABbEoKwuWMPJ4VisngumZ9r+LMHjo5noFjI/PWVzF653sIBAQAAAADg9oQgbG54LDn0YPW9iV6QkcGB3H9kPIkrsQAAAAAA6AwhCFvbbi9I7UqsmTkhCAAAAAAA7ScEYWvl7fWC3CxHX9jpiQAAAAAAYEtCELZWL0dvchNk0iYIAAAAAAAdJARha/XrsM7PJDcaLzmvb4LMzM1nda3SiskAAAAAAGBDQhC2tveuZM+hpLKanHu64c/uPTSWkcFillbW8vLFqy0cEAAAAAAA3koIwtYKhW2Vow8UCzlRmkiSTM+6EgsAAAAAgPYSgtCY0vbK0fWCAAAAAADQKUIQGrONTZAkOVnrBZkWggAAAAAA0GZCEBpTqoUgc6eTSuMl5+ubIK7DAgAAAACgzYQgNOboVFIcTK5fTi5/teHPpmqbIC+eX8zSymqrpgMAAAAAgLcQgtCYwZHk6MnqexO9IOV9o9k7OpiVtUpeOLfYouEAAAAAAOCthCA0rtR8L0ihUMiUcnQAAAAAADpACELj1svRv9TUZ5P1cnS9IAAAAAAAtJEQhMatl6M3vgmSxCYIAAAAAAAdIQShceVT1efFF5OlhYY/q5ejTwtBAAAAAABoIyEIjRs/kkyUk1SSs19p+LPJ2ibIKxevZXFppUXDAQAAAADAmwlBaM56L8jphj85ND6co3tHkiTPnm18gwQAAAAAAO6EEITm3GEvyPTslZ2eCAAAAAAAbksIQnPqvSCzzYUgk+shiE0QAAAAAADaQwhCc+ohyNxTydpaw59NlSeSJDPK0QEAAAAAaBMhCM059GAyOJrcWEzeeLHhz9Y3QYQgAAAAAAC0iRCE5gwMJscerr43UY5eD0HOzS/l4uJyKyYDAAAAAIA3EYLQvG2Uo4+PDOaeQ3uSuBILAAAAAID2EILQvG2Wo0+tl6MLQQAAAAAAaD0hCM3bxiZIohcEAAAAAID2EoLQvNKj1eflV5JrbzT82VS5GoLM2AQBAAAAAKANhCA0b8+BZP+91fe5pxr+7NZNkEql0oLBAAAAAADgJiEI21OuXYnVRC/Ig0cnMlgsZP76SmavXG/RYAAAAAAAUCUEYXvq5ehzpxv+ZHiwmPuPjCdRjg4AAAAAQOsJQdieUvObIEkyWe8FUY4OAAAAAECLCUHYnvp1WGefTlZXGv5sqtYL8oxNEAAAAAAAWkwIwvYcOJ4MTySrS8mFZxv+rF6ObhMEAAAAAIBWE4KwPcViUnq0+t7ElVhTteuwnp1byOpapRWTAQAAAABAEiEId6LeC9JEOfq9h8YyOlTM0spaXr54tUWDAQAAAACAEIQ7UW6+HH2gWMiJY9VtkGm9IAAAAAAAtJAQhO0rnao+5xoPQRK9IAAAAAAAtIcQhO0rPZKkkCzMJQvnGv5sqjyRJJkWggAAAAAA0EJCELZveDw5/GD1vYlekPomiOuwAAAAAABoJSEId6bUfC/IVLkagrx4fjFLK6utmAoAAAAAAIQg3KH1cvTGN0HK+0azd3Qwq2uVvHBusUWDAQAAAADQ74Qg3JltlKMXCoVMKUcHAAAAAKDFhCDcmfomyPmZZGWp4c/qV2LpBQEAAAAAoFWEINyZfXcnoweStZXk3DMNf1YPQWyCAAAAAADQKkIQ7kyhkJRrV2I1UY4+WbsOa1oIAgAAAABAiwhBuHOl2pVYTfSC1EOQVy5ey8LSSiumAgAAAACgzwlBuHP1XpDZ0w1/cmh8OEf3jiRJnrUNAgAAAABACwhBuHP167DmvpxUKg1/NlXSCwIAAAAAQOsIQbhzR08mxcHk2hvJlVcb/qxejj49u9CqyQAAAAAA6GNCEO7c4EhyZLL63kQ5uk0QAAAAAABaSQjCzlgvR2+8F2SyvgkiBAEAAAAAoAWEIOyM9XL0xjdBThybSJKcm1/KxcXlVkwFAAAAAEAfE4KwM9Y3QRoPQcZHBnPPoT1JkulZ2yAAAAAAAOwsIQg7o3yq+rzwfLK82PBnekEAAAAAAGgVIQg7Y+JYMn4sSSU5+3TDn02W9IIAAAAAANAaQhB2znovSOPl6FO1cvQZ12EBAAAAALDDhCDsnPqVWE30gtRDkOm5+VQqlVZMBQAAAABAnxKCsHNKtRCkiU2QB45MZLBYyPz1lcxeud6iwQAAAAAA6EdCEHZO/TqsuaeStbWGPhkeLOb+I+NJkmdciQUAAAAAwA4SgrBzDp9IBkaS5YXk0pmGP5vUCwIAAAAAQAsIQdg5A4PJsZPV99kmekFKN3tBAAAAAABgpwhB2Fml5svRJ2shyIwQBAAAAACAHSQEYWfVe0Ga2AQ5WbsO69m5hayuVVoxFQAAAAAAfUgIws4q1cvRTzf8yT2HxjI6VMzSylpevni1RYMBAAAAANBvhCDsrPomyKWXk+uXG/pkoFjIiWO1XhDl6AAAAAAA7BAhCDtrz8Fk/z3V97mnGv6s3gsiBAEAAAAAYKcIQdh59SuxZhu/EmuqPJFEOToAAAAAADtHCMLOKzcfgqxvgghBAAAAAADYIUIQdt56OfqXG/7kZHlfkuTF84tZWlltxVQAAAAAAPQZIQg7r3yq+jz7dLK60tAnpX0j2Tc6mNW1Sl44t9jC4QAAAAAA6BdCEHbewfuTofFk5Xpy8fmGPikUCpkqV6/E0gsCAAAAAMBOEIKw84rFpPRI9X0bvSDPzApBAAAAAAC4c0IQWmMbvSDrmyBCEAAAAAAAdoAQhNao94LMNh6C1DdBpl2HBQAAAADADhCC0Br1EKSZTZBaCPLVN65lYamxQnUAAAAAANiIEITWOPZIkkIy/3qyeL6hTw6OD+fY3pEkybO2QQAAAAAAuENCEFpjZCI5dH/1vYly9PVeECEIAAAAAAB3SAhC62yjHH29F2R2oRUTAQAAAADQR4QgtM42ytGn1svRr7RiIgAAAAAA+ogQhNbZziZI2SYIAAAAAAA7QwhC65RrIci56WRluaFPThybSJKcX1jKhYWlVk0GAAAAAEAfEILQOvvvSUb3J2s3kvPTDX0yPjKYew7tSZLMzNkGAQAAAABg+4QgtE6hkJS20wuyL0kyMzffiqkAAAAAAOgTQhBaq9x8L8hUuXol1rQQBAAAAACAO7CtEORXfuVXcvz48YyOjubd7353vvCFL2x49ld/9VdTKBTe9Gt0dHTbA9Nl6uXos19q+JPJUrUcfWZWCAIAAAAAwPY1HYL8+q//ep588sn81E/9VL74xS/m677u6/Le9743Z8+e3fCbffv25fXXX1//9dJLL93R0HSR+ibI7JeTSqWhT6bK1RBkem4+lQa/AQAAAACAr9V0CPLJT34yH/zgB/PEE0/kkUceyac//emMjY3ls5/97IbfFAqFlMvl9V+lUmnTn7G0tJQrV6686Rdd6ujDSWEguXYxmX+9oU8eODKRwWIh89dX8vrl6y0eEAAAAACAXtVUCLK8vJy/+Iu/yOOPP37zDygW8/jjj+fP/uzPNvxuYWEh9913X+655558z/d8T5566qlNf84nPvGJ7N+/f/3XPffc08yY7CZDo8mRE9X3BsvRhweLuf/IeBK9IAAAAAAAbF9TIcj58+ezurr6lk2OUqmU2dnZ234zNTWVz372s/mt3/qt/Pt//++ztraWb/mWb8lXv/rVDX/ORz7ykVy+fHn91yuvvNLMmOw29V6QudMNfzJZ1gsCAAAAAMCd2VYxejPe85735P3vf3/e+c535q/9tb+W3/zN38zRo0fzL//lv9zwm5GRkezbt+9Nv+hit/aCNOhk6WYvCAAAAAAAbEdTIciRI0cyMDCQubm5N/3+3NxcyuVyQ3/G0NBQvv7rvz7PPfdcMz+ablY6VX3ONR6CrG+CCEEAAAAAANimpkKQ4eHhvOtd78rnPve59d9bW1vL5z73ubznPe9p6M9YXV3N6dOnc9dddzU3Kd2rXAtBLjyX3LjW0CdTtU2QZ+cWsrpWadVkAAAAAAD0sKavw3ryySfzmc98Jr/2a7+Wp59+Oj/6oz+axcXFPPHEE0mS97///fnIRz6yfv5jH/tY/uAP/iAvvPBCvvjFL+bv/t2/m5deeik/8iM/snN/C3a3vaVk/GhSWUvOfqWhT+45NJbRoWKWVtby0oXFFg8IAAAAAEAvGmz2gx/4gR/IuXPn8tGPfjSzs7N55zvfmd/7vd9bL0t/+eWXUyzezFbeeOONfPCDH8zs7GwOHjyYd73rXfnTP/3TPPLIIzv3t2D3Kz2WvPDfktnTyd3v2vL4QLGQE8f25vSrlzMzN58Hjk60YUgAAAAAAHpJoVKp7Pq7hq5cuZL9+/fn8uXLStK71R/84+RPfzn5pg8m/9dfaOiT/+f//lf5j1/8av7h45P5scdPtHhAAAAAAAC6RaO5QdPXYcG2bKMc/aRydAAAAAAA7oAQhPYoP1Z9zj2VNLh8NFkLQaaFIAAAAAAAbIMQhPY4MpkMDCdLV5JLLzX0yVSpGoK8eH4xSyurrZwOAAAAAIAeJAShPQaGkqNT1ffZxq7EKu0byb7RwayuVfL82cUWDgcAAAAAQC8SgtA+TfaCFAqFTOkFAQAAAABgm4QgtE+5FoLMnm74k8mSXhAAAAAAALZHCEL71MvRmwhB1jdBZoUgAAAAAAA0RwhC+5RqIcill5LrVxr6ZMomCAAAAAAA2yQEoX3GDiX77q6+zz3V0Cf167C++sa1LCyttGoyAAAAAAB6kBCE9qpvgzRYjn5wfDjH9o4kSZ61DQIAAAAAQBOEILTXHfSCTOsFAQAAAACgCUIQ2qvJTZDk5pVYekEAAAAAAGiGEIT2Kp+qPue+kqytNvRJvRx9RggCAAAAAEAThCC016EHksE9ycq15OILDX0yuX4d1kIrJwMAAAAAoMcIQWiv4kBSerT63mAvyGRpIklyfmEpFxaWWjUZAAAAAAA9RghC+zVZjj42PJh7D40lSWbmbIMAAAAAANAYIQjtdwfl6HpBAAAAAABolBCE9quXo882HoJMlatXYj0zKwQBAAAAAKAxQhDar94JMv9acvViQ5/YBAEAAAAAoFlCENpvZG9y8Hj1vcFekKlyLQSZnU+lUmnRYAAAAAAA9BIhCJ3RZC/IA0cmMlgsZH5pJa9fvt7CwQAAAAAA6BVCEDqjyV6Q4cFiHjg6niSZdiUWAAAAAAANEILQGeubII1dh5Xc0guiHB0AAAAAgAYIQeiM+ibIuelkZbmhT6ZqIYhNEAAAAAAAGiEEoTMO3JuM7E9Wl5PzMw19MlkrR5+2CQIAAAAAQAOEIHRGoZCUHq2+N1iOXt8EefbsQlbXKq2aDAAAAACAHiEEoXPKtV6Q2cZ6Qe45NJbRoWKWV9by0oXFFg4GAAAAAEAvEILQOevl6I1tggwUCzfL0fWCAAAAAACwBSEInbO+CfLlpNLY9Vb1EGR6dqFVUwEAAAAA0COEIHTOsUeSQjG5ej5ZmGvokymbIAAAAAAANEgIQucM7UkOP1R9n23sSqzJcjUEeWb2SqumAgAAAACgRwhB6Kz1XpDGytHrmyBnLlzN9RurrZoKAAAAAIAeIAShs8qnqs8GN0FK+0ayb3Qwq2uVvHBusYWDAQAAAADQ7YQgdNZ6CNLYJkihUMhUWS8IAAAAAABbE4LQWfXrsC48m9y41tAn9RBkWggCAAAAAMAmhCB01t5yMnY4qawlZ59u6JN6L8jMrBAEAAAAAICNCUHorELhlnL0xnpBJks2QQAAAAAA2JoQhM5rshy9HoJ89Y1rWVhaadVUAAAAAAB0OSEIndfkJsjB8eEc2zuSRDk6AAAAAAAbE4LQeeVaCDL75aRSaeiTejm6XhAAAAAAADYiBKHzjkwlxaFk6XJy+ZWGPpnSCwIAAAAAwBaEIHTe4HBy9GT1vdFekPomiBAEAAAAAIANCEHYHdavxDrd0PH1TZDZhVZNBAAAAABAlxOCsDusl6M3FoKcKE0kSc4vLOXCwlKrpgIAAAAAoIsJQdgdbi1Hb8DY8GDuPTSWRC8IAAAAAAC3JwRhdyidqj7feDFZaizUmKxdiTUzKwQBAAAAAOCthCDsDuOHk713Vd/nvtLQJ1Pl6pVY03N6QQAAAAAAeCshCLtHk70gU+V9SZIZ12EBAAAAAHAbQhB2jyZ7QaZuuQ6rUqm0aioAAAAAALqUEITdo1zrBZlrLAS5/8h4BouFzC+t5PXL11s4GAAAAAAA3UgIwu5RL0ef+0qytrrl8eHBYh44Op4kmXYlFgAAAAAAX0MIwu5x+MFkcE9yYzG5+GJDn0zWrsSanhWCAAAAAADwZkIQdo/iQHLs4ep7o+Xot/SCAAAAAADArYQg7C5NlqNPlmubIK7DAgAAAADgawhB2F1KzZWjn6yFIM+eXcjqWqVVUwEAAAAA0IWEIOwuTW6C3HNwLKNDxSyvrOWlC4stHAwAAAAAgG4jBGF3KT1afV75anL14pbHi8XCejn6jCuxAAAAAAC4hRCE3WV0f3Lg3ur73FMNfVIPQZ5Rjg4AAAAAwC2EIOw+5XdUnw32gkzZBAEAAAAA4DaEIOw+pXovyOmGjk/WytGnbYIAAAAAAHALIQi7T7m5EORkLQQ5c+Fqrt9YbdVUAAAAAAB0GSEIu099E+TcM8nqjS2PH9s7kv17hrK6VskL5xZbPBwAAAAAAN1CCMLuc+C+ZHhvsrqcnH92y+OFQkEvCAAAAAAAbyEEYfcpFpPSo9X3BsvRJ8sTSZJpIQgAAAAAADVCEHanJntB6psgytEBAAAAAKgTgrA71XtBGt0EEYIAAAAAAPA1hCDsTuVT1edsYyHIVLkagrx66Vrmr29dpg4AAAAAQO8TgrA7HXskKRSTxbPJ/NyWxw+MDae0byRJ8uzZhVZPBwAAAABAFxCCsDsNjyWHHqy+zzXWC1K/EmvGlVgAAAAAAEQIwm62Xo7e4JVY9V6QOSEIAAAAAABCEHazZsvRa70gM0IQAAAAAAAiBGE3a7Ycvb4J4josAAAAAAAiBGE3q2+CnJ9Jblzf8viJ0kT1+MJyzi8stXIyAAAAAAC6gBCE3Wvf25I9B5PKanLumS2Pjw0P5t5DY0lciQUAAAAAgBCE3axQaLoXZKreC+JKLAAAAACAvicEYXfbbi/I3EKrJgIAAAAAoEsIQdjd6iFIg5sgk/VNENdhAQAAAAD0PSEIu1v9OqzZLyWVypbH65sgM7PzqTRwHgAAAACA3iUEYXc7OpUUB5Prl5PLX93y+P1HxjNYLGR+aSWvXb7ehgEBAAAAANithCDsboMjyZGp6nsDV2INDxbzwNHxJMrRAQAAAAD6nRCE3a9cvxKrwV6Q9XJ0IQgAAAAAQD8TgrD71XtB5k43dPxk+WYvCAAAAAAA/UsIwu5nEwQAAAAAgG0QgrD7lU5VnxdfSJYXtzw+VdsEefbsQlbXKq2cDAAAAACAXUwIwu43cTSZKCWpJHNf2fL4PQfHMjpUzPLKWs5c2Do0AQAAAACgNwlB6A7l2jZIA70gxWJh/UosvSAAAAAAAP1LCEJ3qJejzzZWjq4XBAAAAAAAIQjdob4J0mA5+slaL8iMEAQAAAAAoG8JQegO9U2QuaeStbUtj69vgrgOCwAAAACgbwlB6A6HH0oGRpIbi8kbL255fKq2CXLmwtVcv7Ha6ukAAAAAANiFhCB0h4HB5NjD1fe5ra/EOrZ3JPv3DGV1rZIXzi22eDgAAAAAAHYjIQjdo1wvR986BCkUCplaL0e/0sqpAAAAAADYpYQgdI9SrRy9gU2QJJksTyRJpmcXWjURAAAAAAC7mBCE7tHEJkiS9U2QmTnl6AAAAAAA/UgIQvco1UKQyy8n1y5teXyqvC9JMj0rBAEAAAAA6EdCELrHngPJ/nur7w1ciTVZql6H9eqla5m/fqOFgwEAAAAAsBsJQeguTVyJdWBsOKV9I0mSZ8/qBQEAAAAA6DdCELpL/UqsudMNHZ+s94K4EgsAAAAAoO8IQegu2yxHf0YIAgAAAADQd4QgdJf6JsjZp5PVlS2PT5ZrmyBzQhAAAAAAgH4jBKG7HLw/GZ5IVpeSC89teby+CSIEAQAAAADoP0IQukuxmBx7pPo+t/WVWCdKEykUkvMLyzm/sNTi4QAAAAAA2E2EIHSf8qnqc3brcvSx4cHce2gsiW0QAAAAAIB+IwSh+9TL0RvYBEmSyfqVWMrRAQAAAAD6ihCE7lNqfBMkudkLMm0TBAAAAACgrwhB6D6lR5IUkoW5ZOHclscny7UQxCYIAAAAAEBfEYLQfYbHk0MPVN/ntt4GqW+CzMwtpFKptHIyAAAAAAB2ESEI3aneCzK7dS/I/UfGMzRQyMLSSl67fL3FgwEAAAAAsFsIQehO9V6QBsrRhweLeeDIRBLl6AAAAAAA/UQIQndqYhMkuaUXRDk6AAAAAEDfEILQnUq1EOT8dLKytOXxqZJNEAAAAACAfiMEoTvtf3syeiBZW0nOTW95fLJWjv6MEAQAAAAAoG8IQehOhUJSrvWCzJ7e8vhU7Tqs584tZGV1rZWTAQAAAACwSwhB6F71K7EaKEe/5+BY9gwNZHllLS9dvNriwQAAAAAA2A2EIHSv9XL0rTdBisVCJvWCAAAAAAD0FSEI3evWTZBKZcvj9V6Q6TkhCAAAAABAPxCC0L2OnkwKA8m1N5Irr215vN4LMiMEAQAAAADoC0IQutfQaHJksvreQC/I+iaI67AAAAAAAPqCEITu1kQvSH0T5MyFq7l+Y7WVUwEAAAAAsAsIQehut/aCbOHY3pHs3zOU1bVKnj+30OLBAAAAAADoNCEI3a18qvqc3ToEKRQKmSrpBQEAAAAA6BdCELpbPQS58FyyvLjl8fqVWNOzNkEAAAAAAHqdEITuNnEsGT+WpJKcfXrL45NlmyAAAAAAAP1CCEL3a6YcvVTfBBGCAAAAAAD0OiEI3a+JcvTJ0kSS5NVL1zJ//UYrpwIAAAAAoMOEIHS/JsrRD4wNp7RvJEkyM6cXBAAAAACglwlB6H7rmyBPJWtrWx6fLOkFAQAAAADoB0IQut+RE8nAcLI8n1x6acvjJ8t6QQAAAAAA+oEQhO43MJQcPVl9b6gXxCYIAAAAAEA/EILQG8rvqD4b6AWZKgtBAAAAAAD6gRCE3lCu9YLMnt7y6EPHJlIoJOcXlnN+YanFgwEAAAAA0ClCEHrDejn61iHI2PBg7j00liSZ0QsCAAAAANCzhCD0hvomyKWXk+uXtzxe7wWZdiUWAAAAAEDPEoLQG/YcTPa9vfo+99SWx6eUowMAAAAA9DwhCL1jvRek8XL0addhAQAAAAD0LCEIvaOJXpB6CDIzt5BKpdLKqQAAAAAA6BAhCL2jiU2Q44fHMzRQyMLSSl67fL3FgwEAAAAA0AlCEHpH6VT1efbpZG1106PDg8U8cGQiSTLjSiwAAAAAgJ4kBKF3HLo/GRpPVq4lF57f8vhk7UqsZ4QgAAAAAAA9SQhC7ygOJKVHqu+zX9ry+FSptgkyJwQBAAAAAOhFQhB6y3o5+ta9IJOl6ibItE0QAAAAAICeJAShtzRRjn6yvC9J8ty5haysrrVyKgAAAAAAOkAIQm+pl6M3sAny9oN7smdoIMsra3np4tUWDwYAAAAAQLsJQegt9U6Q+deTxQubHi0WC5ms94K4EgsAAAAAoOcIQegtI3uTg/dX3+dOb3l8vRdEOToAAAAAQM8RgtB7mugFmSorRwcAAAAA6FVCEHpPE70gNkEAAAAAAHqXEITeU66FIA1sgpysbYKcOb+Y6zdWWzkVAAAAAABtJgSh99Svwzr3TLKyvOnRo3tHcmBsKGuV5PlzC20YDgAAAACAdhGC0Hv235OM7k/WbiTnpzc9WigU1q/EmnElFgAAAABATxGC0HsKhaTURDl6vRdk1iYIAAAAAEAvEYLQm+ohSCPl6GWbIAAAAAAAvUgIQm+q94LMnt7y6M1NECEIAAAAAEAvEYLQm27dBKlUNj1aD0FevXQt89dvtHoyAAAAAADaRAhCbzr2cFIoJlcvJPOzmx7dPzaU8r7RJMnMnF4QAAAAAIBeIQShNw3tSQ6fqL7rBQEAAAAA6EtCEHpX+VT12VAvyEQSvSAAAAAAAL1ECELvaqIcfbJkEwQAAAAAoNcIQehdpdomSAPXYU3VrsOyCQIAAAAA0DuEIPSu+ibIheeSG9c2PfrQsYkUCsmFxeWcX1hqw3AAAAAAALSaEITeNVFKxo4klbXk7Fc2PTo2PJh7D40lSWZsgwAAAAAA9AQhCL2rULilF6SBK7FqvSDTekEAAAAAAHqCEITeVqqFIE30gihHBwAAAADoDUIQelu5Vo7ewCbIZEk5OgAAAABALxGC0NvqIcjcl5NKZdOjNzdBFlLZ4iwAAAAAALufEITedmQyGRhOlq4kl17a9Ojxw+MZGihkYWklr1661qYBAQAAAABoFSEIvW1gKDk6VX3f4kqs4cFiHjgykUQvCAAAAABALxCC0PtKt1yJtYXJcr0XZKGVEwEAAAAA0AZCEHpf+bHqc/b0lkdPrveC2AQBAAAAAOh2QhB6X6kWgjSyCVKqb4IIQQAAAAAAup0QhN5Xrl2H9caZ5PqVTY9O1UKQ584tZGV1rcWDAQAAAADQSkIQet/YoWTv26rvZ7+y6dG3H9yTPUMDWV5Zy0sXr7ZhOAAAAAAAWkUIQn9osBekWCxksjSRxJVYAAAAAADdTghCf6hfiaUXBAAAAACgbwhB6A+lxjZBkmSqXA1BZuaEIAAAAAAA3UwIQn9Y3wT5SrK2uunReggyLQQBAAAAAOhqQhD6w6EHksE9ycq15OILmx6dql2Hdeb8Yq7f2DwwAQAAAABg9xKC0B+KA0npker7FldiHd07kgNjQ1mrJM+fW2jDcAAAAAAAtIIQhP5R7wXZohy9UCisl6PrBQEAAAAA6F5CEPpHvRdkdvMQJLl5JdYzs0IQAAAAAIBuJQShfzS4CZIkk7Vy9BkhCAAAAABA1xKC0D9Kj1afV15Nrl7c9OjJeggypxMEAAAAAKBbCUHoH6P7koPHq+9bbINMHquGIK9eupb56zdaPBgAAAAAAK0gBKG/1K/Emj296bH9Y0Mp7xtNYhsEAAAAAKBbCUHoL02Uo6/3gszpBQEAAAAA6EZCEPrLejn65psgSTJVmkiSTCtHBwAAAADoSkIQ+ku5FoKcm05WN+/6mCxVN0GEIAAAAAAA3UkIQn85cF8ysi9ZXU7Oz2x6dMp1WAAAAAAAXU0IQn8pFJLSo9X3LXpBThzbm0IhubC4nPMLS20YDgAAAACAnSQEof802AuyZ3gg9x0aS5LMuBILAAAAAKDrCEHoP/VekC02QZJbekFciQUAAAAA0HWEIPSf8qnqc/Z0UqlselQvCAAAAABA9xKC0H+OPZIUisnV88nC3KZH65sgz7gOCwAAAACg6whB6D9De5LDD1Xft7gSa30TZHY+lS22RgAAAAAA2F2EIPSnBsvR7z8ynqGBQhaXV/PqpWttGAwAAAAAgJ0iBKE/NViOPjRQzINHJ5LoBQEAAAAA6DZCEPpTqVaOPrd5CJLc7AWZnl1o5UQAAAAAAOwwIQj9qb4Jcv7Z5Mb1TY+u94LYBAEAAAAA6CpCEPrT3ruSPYeSympy7ulNj97cBBGCAAAAAAB0EyEI/alQaLgXZKoWgjx3biErq2utngwAAAAAgB0iBKF/ld9RfW7RC/L2g3syNjyQ5ZW1nLlwtQ2DAQAAAACwE4Qg9K9SfRPk9KbHisVCTpT0ggAAAAAAdBshCP3r1uuwKpVNj06VJpLoBQEAAAAA6CZCEPrXkamkOJQsXU4uv7Lp0UmbIAAAAAAAXUcIQv8aHE6OTlXftypHL1dDkGkhCAAAAABA1xCC0N/qvSBblKNP1TZBzpxfzPUbq62eCgAAAACAHSAEob+VGytHP7p3JAfGhrJWSZ47u9CGwQAAAAAAuFNCEPpbg5sghUJBLwgAAAAAQJcRgtDfyqeqz4svJkubb3ic1AsCAAAAANBVhCD0t/Ejyd67klSSs1/Z9Oj6JsisEAQAAAAAoBtsKwT5lV/5lRw/fjyjo6N597vfnS984QsNffcf/sN/SKFQyPd+7/du58dCa9SvxJr90qbHpsr167B0ggAAAAAAdIOmQ5Bf//Vfz5NPPpmf+qmfyhe/+MV83dd9Xd773vfm7Nmzm3535syZfPjDH863fdu3bXtYaIn1cvTNe0Emj1VDkFcvXcv89RutngoAAAAAgDvUdAjyyU9+Mh/84AfzxBNP5JFHHsmnP/3pjI2N5bOf/eyG36yuruaHfuiH8jM/8zN54IEH7mhg2HENlqPvHxtKed9oEuXoAAAAAADdoKkQZHl5OX/xF3+Rxx9//OYfUCzm8ccfz5/92Z9t+N3HPvaxHDt2LH//7//9hn7O0tJSrly58qZf0DL1cvS5ryRra5senayXo8+6EgsAAAAAYLdrKgQ5f/58VldXUyqV3vT7pVIps7Ozt/3mj//4j/Nv/s2/yWc+85mGf84nPvGJ7N+/f/3XPffc08yY0JxDDyaDo8mNxeSNFzc9enK9F8QmCAAAAADAbretYvRGzc/P54d/+Ifzmc98JkeOHGn4u4985CO5fPny+q9XXnmlhVPS9wYGk2MPV99nT296dLJU3wQRggAAAAAA7HaDzRw+cuRIBgYGMjc396bfn5ubS7lcfsv5559/PmfOnMn73ve+9d9bq103NDg4mOnp6Tz44INv+W5kZCQjIyPNjAZ3pvRY8tr/We0FefR7Nzw2VbIJAgAAAADQLZraBBkeHs673vWufO5zn1v/vbW1tXzuc5/Le97znrecP3nyZE6fPp2//Mu/XP/1N//m38xf/+t/PX/5l3/pmit2j3ovyOzm5egPHZtIoZBcWFzO+YWlNgwGAAAAAMB2NbUJkiRPPvlk/t7f+3v5xm/8xnzzN39zfumXfimLi4t54oknkiTvf//7c/fdd+cTn/hERkdH89hjj73p+wMHDiTJW34fOmo9BNn8Oqw9wwO579BYzly4mpnZ+Rx5yMYSAAAAAMBu1XQI8gM/8AM5d+5cPvrRj2Z2djbvfOc783u/93vrZekvv/xyisWWVo3Azis9Wn1e+Wpy9WIydmjDo5OlvTlz4WqemZ3PtzzUeNcNAAAAAADtVahUKpVOD7GVK1euZP/+/bl8+XL27dvX6XHoVb90Krn0cvL3/o/k/m/b8Ngv/sF0fvm/Ppf/+zfdk//3//aONg4IAAAAAEDSeG5gZQPqSrUrseY27wWZKlfL0aeVowMAAAAA7GpCEKgr13pqtihHnypVQ5CZ2fl0wSIVAAAAAEDfEoJAXakWgsxtXo5+/Mh4hgYKWVxezauXrrVhMAAAAAAAtkMIAnX1TZCzzySrKxseGxoo5sGjE0mSGVdiAQAAAADsWkIQqDtwPBmeSFaXkgvPbnp0snYl1vTsQhsGAwAAAABgO4QgUFcs3rwSa6tekHo5+uyVVk8FAAAAAMA2CUHgVuvl6F/a9Nj6JsicTRAAAAAAgN1KCAK3Wi9H33wT5GRtE+T5swtZWV1r9VQAAAAAAGyDEARuVT5VfW5xHdbdB/ZkbHggy6trOXPhahsGAwAAAACgWUIQuNWxh5MUksWzycLZDY8Vi4WcqF2JNTM336bhAAAAAABohhAEbjU8nhx+sPo+e3rTo1OliSTJ9KwQBAAAAABgNxKCwNdqsBdkvRxdCAIAAAAAsCsJQeBrlWshyBa9IFNl12EBAAAAAOxmQhD4WqVaOfoWmyD1EOTMhcVcv7Ha6qkAAAAAAGiSEAS+VrkWgpyfSW5c3/DY0YmRHBwbylolee7sQpuGAwAAAACgUUIQ+Fr73pbsOZisrSTnntnwWKFQWO8FcSUWAAAAAMDuIwSBr1UoNFyOXr8Sa1oIAgAAAACw6whB4HbqV2JtUY6+vgkyKwQBAAAAANhthCBwO81ugghBAAAAAAB2HSEI3E65FoLMnk4qlQ2PTR6rhiCvXb6eK9dvtGMyAAAAAAAaJASB2zl6MikOJtcvJVde3fDY/rGh3LV/NEnyrF4QAAAAAIBdRQgCtzM4khyZrL432AsyPbvQ6qkAAAAAAGiCEAQ2st4LcnrTY/VekBmbIAAAAAAAu4oQBDZSPlV9NrwJIgQBAAAAANhNhCCwkVvL0TcxVbIJAgAAAACwGwlBYCOl2ibIxReS5cUNjz10bCKFQnJhcTnn5pfaNBwAAAAAAFsRgsBGJo4mE6UklWTuKxse2zM8kPsOjSWxDQIAAAAAsJsIQWAzTZaj6wUBAAAAANg9hCCwmfVekM3L0fWCAAAAAADsPkIQ2Ey9F2Ru8xBksr4JIgQBAAAAANg1hCCwmfomyNxTydrahsfWN0Fm51OpVNoxGQAAAAAAWxCCwGYOn0gGRpLlheTSmQ2PHT8ynqGBQhaXV/PqpWvtmw8AAAAAgA0JQWAzA4PJsYer75v0ggwNFPPg0YkkytEBAAAAAHYLIQhsZb0c/fSmxyZLekEAAAAAAHYTIQhspcFy9KnyzV4QAAAAAAA6TwgCW1nfBNkiBFnfBFlo9UQAAAAAADRACAJbKT1afV5+Obl2acNj9U2Q588uZGV1rQ2DAQAAAACwGSEIbGXPwWT/PdX3uac2PHb3gT0ZGx7I8upazly42qbhAAAAAADYiBAEGlGqXYm1SS9IsVjIifqVWHpBAAAAAAA6TggCjVjvBTm96bGp0kSSZHpOCAIAAAAA0GlCEGhEA5sgSTJV3pckmbEJAgAAAADQcUIQaET5VPV59ulkdWXDY1O167BmbIIAAAAAAHScEAQacfD+ZHgiWbmeXHhuw2OT5ep1WGcuLOb6jdV2TQcAAAAAwG0IQaARxWJy7JHq+yZXYh2dGMnBsaGsVZLnzi60aTgAAAAAAG5HCAKNaqAcvVAoZNKVWAAAAAAAu4IQBBrVcDl6NQSZVo4OAAAAANBRQhBoVL0cfXbzEKS+CTJtEwQAAAAAoKOEINCoY48kKSQLs8ni+Q2PnaxtgszYBAEAAAAA6CghCDRqZCI5dH/1fZNekBO1TZDXLl/Ples32jEZAAAAAAC3IQSBZjTQC7J/z1Du2j+aJHnWlVgAAAAAAB0jBIFmlN9RfW6yCZLc0gsyu9DqiQAAAAAA2IAQBJpRrm2CbFGOPlXvBbEJAgAAAADQMUIQaEb9Oqzz08nK0obH6psgz8xeacdUAAAAAADchhAEmrH/7cno/mRtJTk3veGxqfXrsOZTqVTaNR0AAAAAALcQgkAzCoWkdKr6vkk5+onSRAqF5I2rN3J+YblNwwEAAAAAcCshCDSrgV6Q0aGBHD88nkQvCAAAAABApwhBoFn1XpC505semyxNJKleiQUAAAAAQPsJQaBZt26CbNL3Ue8FsQkCAAAAANAZQhBo1tGHk8JAcu1iMv/6hscmy7VydCEIAAAAAEBHCEGgWUOjyZHJ6vvsxldirW+CzM5nbW3jjREAAAAAAFpDCALbsX4l1sYhyPEj4xkeKGZxeTWvXrrWpsEAAAAAAKgTgsB2rJejf3nDI0MDxTxwdDyJXhAAAAAAgE4QgsB23FqOvokpvSAAAAAAAB0jBIHtKJ2qPi8+nyxf3fDY5C29IAAAAAAAtJcQBLZjbykZP5pU1pKzT294rF6OPj230K7JAAAAAACoEYLAdq33gmxcjl6/Duv5swu5sbrWjqkAAAAAAKgRgsB2NdALcveBPRkbHsjy6lpeurDYpsEAAAAAAEiEILB99V6QuY1DkGKxsN4LMj3rSiwAAAAAgHYSgsB2lWshyOyXk7WNr7q62QuiHB0AAAAAoJ2EILBdR04kA8PJ8nxy6aUNj03WekFmZoUgAAAAAADtJASB7RoYSo6erL5vciVWfRNkxiYIAAAAAEBbCUHgTtx6JdYGJssTSZIzFxZz/cZqO6YCAAAAACBCELgzpceqz002QY5OjOTg2FDWKslzZ5WjAwAAAAC0ixAE7kS5FoLMnt7wSKFQyGS9HF0vCAAAAABA2whB4E7UN0EuvZRcv7LhsZNlvSAAAAAAAO0mBIE7MXYo2Xd39X3uqQ2PTdZCkGkhCAAAAABA2whB4E7Vy9E36QWZql2HNeM6LAAAAACAthGCwJ2qX4k1+6UNj5yohSCvXb6eK9dvtGMqAAAAAIC+JwSBO7Vejr7xJsj+PUO5a/9okuRZV2IBAAAAALSFEATuVKl2HdbZp5O11Q2PTda2QZ5xJRYAAAAAQFsIQeBOHbo/GRpLVq4lF57f8NjJsl4QAAAAAIB2EoLAnSoOJMceqb7Pnd7wWH0TZNp1WAAAAAAAbSEEgZ3QQC/IVG0TZHp2PpVKpR1TAQAAAAD0NSEI7IRSLQSZ2zgEeejYRAqF5I2rN3J+YblNgwEAAAAA9C8hCOyEcq0cfZNNkNGhgRw/PJ4kmXElFgAAAABAywlBYCeUHq0+519LFi9seGyyNJGkeiUWAAAAAACtJQSBnTCyNzl4f/V9k3L0qdLNXhAAAAAAAFpLCAI7paFy9H1JkmnXYQEAAAAAtJwQBHZKqdYLskk5+lS5eh3Ws3PzWVurtGMqAAAAAIC+JQSBndLAJsh9h8czPFDM4vJqXr10rU2DAQAAAAD0JyEI7JRSLQQ590yysnzbI0MDxTxwdDxJMuNKLAAAAACAlhKCwE45cG8ysj9Zu5Gcn9nw2FS5Vo4uBAEAAAAAaCkhCOyUQiEpPVp936QXZLJUC0FmhSAAAAAAAK0kBIGdtN4LcnrDI1NCEAAAAACAthCCwE4qn6o+N9kEqV+H9cK5xdxYXWvHVAAAAAAAfUkIAjupdMsmSKVy2yN3H9iT8eGBLK+u5aULi20cDgAAAACgvwhBYCcdezgpFJOrF5L52dseKRYLObF+JdZCO6cDAAAAAOgrQhDYSUN7ksMnqu+bXYlVD0Hm9IIAAAAAALSKEAR2WgPl6JO1XpAZ5egAAAAAAC0jBIGdVu8FsQkCAAAAANBRQhDYaeVT1efsJiFIbRPkzIXFXL+x2o6pAAAAAAD6jhAEdlp9E+TCs8mNa7c9cmRiOIfGh1OpJM+dVY4OAAAAANAKQhDYaXvLydjhpLKWnH36tkcKhUImSxNJkmm9IAAAAAAALSEEgZ1WKNxyJdbG5ej1XpAZvSAAAAAAAC0hBIFWaKAcfbKsHB0AAAAAoJWEINAKjZSj1zdBXIcFAAAAANASQhBohfVNkKeSSuW2R07UQpDXLl/P5Ws32jUZAAAAAEDfEIJAKxyZTIpDydLl5NLLtz2yf89Q3rZ/NEnyrCuxAAAAAAB2nBAEWmFwODl6svquFwQAAAAAoCOEINAq5dqVWHpBAAAAAAA6QggCrbLeC3J6wyOTJZsgAAAAAACtIgSBVmlkE6R+HdbsfCobFKgDAAAAALA9QhBoldKp6vONF5PrV2575KFjEykUkjeu3si5haU2DgcAAAAA0PuEINAq44eTvW+rvp/9ym2PjA4N5Pjh8STJzOxCuyYDAAAAAOgLQhBopfUrsTbuBZnSCwIAAAAA0BJCEGil9XL0jXtBJmu9IDOzQhAAAAAAgJ0kBIFWaqQc3SYIAAAAAEBLCEGglerl6Ge/kqyt3vbIVHkiSfLs3HzW1irtmgwAAAAAoOcJQaCVDj+YDO5JblxNLr542yP3HR7P8EAxi8urefXStTYPCAAAAADQu4Qg0ErFgeTYw9X3uduXow8NFPPA0fEkybReEAAAAACAHSMEgVZrpBekrBcEAAAAAGCnCUGg1crvqD5nb78JktwMQWaEIAAAAAAAO0YIAq1Wqm2CzG2yCVKqbYK4DgsAAAAAYMcIQaDVSo9Wn1deTa5evO2RyVoI8sK5xdxYXWvXZAAAAAAAPU0IAq02ui85cF/1fYNtkLsP7Mn48ECWV9fy0oXFNg4HAAAAANC7hCDQDuVT1ecG5ejFYiEn1q/EWmjXVAAAAAAAPU0IAu3QVC/IlXZMBAAAAADQ84Qg0A7lWggye3rDI1PlWggypxwdAAAAAGAnCEGgHeqbIOeeSVZv3PZIPQSZmXMdFgAAAADAThCCQDscuC8Z3pusLifnn73tkcnadVhnLizm+o3Vdk4HAAAAANCThCDQDsXilldiHZkYzqHx4VQqyXNnbYMAAAAAANwpIQi0y3o5+u1DkEKhkMnSRJJkelYvCAAAAADAnRKCQLusb4J8ecMjU6V6L4gQBAAAAADgTglBoF1Kp6rPuY1DkMlaOfozNkEAAAAAAO6YEATa5djDSaGYLJ5L5udue+Rk2SYIAAAAAMBOEYJAuwyPJYcerL5v0AtyonYd1uuXr+fytRvtmgwAAAAAoCcJQaCdtugF2Tc6lLftH02SPGsbBAAAAADgjghBoJ1KtRCkgV6QaSEIAAAAAMAdEYJAO5XfUX1usAmSJFO1K7FmlKMDAAAAANwRIQi0U/06rPMzyY3rtz0yWQtBnhGCAAAAAADcESEItNPeu5I9h5LKanLu6dsemapdhzUzN59KpdLO6QAAAAAAeooQBNqpUNiyHP2hYxMpFpI3rt7IuYWlNg4HAAAAANBbhCDQbqVT1ecG5eijQwM5fng8STIzu9CuqQAAAAAAeo4QBNpti02Q5GYvyPScXhAAAAAAgO0SgkC7lWohyNzpZIPOj8l6L4hydAAAAACAbROCQLsdnUqKg8n1y8nlr972yJRNEAAAAACAOyYEgXYbHEmOTFXfN+gFmSpPJElm5uaztnb7bREAAAAAADYnBIFOKNfK0TfoBTl+eDzDA8VcXV7Nq5eutXEwAAAAAIDeIQSBTlgvR//Sbf/z4EAxDx6rboNM6wUBAAAAANgWIQh0wno5+u03QZJkqlQLQfSCAAAAAABsixAEOqF+HdbFF5OlhdsemSxXy9FnhCAAAAAAANsiBIFOGD+STJSTVJKzX7ntkalSNQRxHRYAAAAAwPYIQaBT1ntBTt/2P0/WQpAXzi3mxupau6YCAAAAAOgZQhDolC16Qe4+sCfjwwNZXl3LmfOLbRwMAAAAAKA3CEGgU+q9ILO3D0GKxcJ6L4hydAAAAACA5glBoFPWN0GeStZuf91VvRdkRi8IAAAAAEDThCDQKYcfSgZHkxuLyRsv3vZIvRfEJggAAAAAQPOEINApA4PJsYer7xuUo0/VrsOamVto11QAAAAAAD1DCAKdtEU5en0T5MyFxVy/sdquqQAAAAAAeoIQBDppi3L0IxPDOTQ+nEolee6sbRAAAAAAgGYIQaCTttgEKRQKmSxNJEmeUY4OAAAAANAUIQh0UunR6vPyK8m1N2575GR5X5JkRjk6AAAAAEBThCDQSXsOJPvvrb7PPXXbI/VekGmbIAAAAAAATRGCQKeVa1dibdALMlWuXodlEwQAAAAAoDlCEOi09V6Q07f9zydqmyCvX76ey9dutGsqAAAAAICuJwSBTiufqj5nbx+C7Bsdytv2jyZJnrUNAgAAAADQMCEIdFr9OqyzzySrK7c9MlmuboM8oxcEAAAAAKBhQhDotAPHk+GJZHUpufDsbY9M1UIQvSAAAAAAAI0TgkCnFYtJ6dHq+0bl6LVekGmbIAAAAAAADROCwG6wRTn6ZOnmJkilUmnXVAAAAAAAXU0IArtBvRdkg02Qh45NpFhI3rh6I+cWlto4GAAAAABA9xKCwG5QOlV9zt0+BBkdGsjxw+NJkpnZhXZNBQAAAADQ1YQgsBuUHklSSBbmkoVztz1SvxJrWjk6AAAAAEBDhCCwGwyPJ4ceqL5v1AtSrpejX2nXVAAAAAAAXU0IArtFuXYl1uztQ5CT9RBkznVYAAAAAACNEILAbrFFOXr9Oqxn5+aztlZp11QAAAAAAF1LCAK7xRbl6McPj2V4oJiry6t59dK1Ng4GAAAAANCdhCCwW9Q3Qc7PJCtLb/nPgwPFPHhsIkkyPascHQAAAABgK0IQ2C323Z2MHkjWVpJzz9z2yFSpFoLMCUEAAAAAALYiBIHdolC4pRx9g16QWjn6jBCE/z979x0d53mfCfsedBIAOwmoU4UAVSjLkUvsuCWWrbgXZdfJFif6Ntmsna4UW3Zc4ia5xHGc2M6us86m7G6yu+6xLRfFPXLsyFFEqhBULxbATqIQdeb7YwYgSIISywCDcl3n4Mz7zjuY50Fyjs2TO7/nBgAAAACekBAE5pOOypFYx+kF6a6UozsOCwAAAADgiQlBYD6Z7AXp3Trj4+7KJMi9uwYyNlGcq10BAAAAACxIQhCYT6ZPgpRKxzw+a9WytDbVZ2yilAd2D87x5gAAAAAAFhYhCMwn6zcndQ3JoX3JwUePeVwoFKZ6QZSjAwAAAAA8PiEIzCeNLcm6rvL1ccrRJ3tBevSCAAAAAAA8LiEIzDdTR2LN3AvS1WESBAAAAADgRAhBYL6ZKkc/ziRI5Tisnr6BudoRAAAAAMCCJASB+WZ6OfoMJkOQB/YM5tDoxFztCgAAAABgwRGCwHzTuaX8uufeZHTwmMfr2pqztrUppVJyz07TIAAAAAAAxyMEgfmmbUPSuiFJKdl514wf0QsCAAAAAPDEhCAwH031gsxcjn64F0QIAgAAAABwPEIQmI+eoBdkahKkVwgCAAAAAHA8QhCYjzovL78edxKkLYlJEAAAAACAxyMEgflo8jisvjuSYvGYx5sqkyCPHRjOgaGxudwZAAAAAMCCIQSB+WjtpqS+ORkdSPY/cMzjFS2NOWvVsiRJz07TIAAAAAAAMxGCwHxU35Bs2Fy+7j1eL0j5SCy9IAAAAAAAMxOCwHzVsaX8erxy9M7ykVh6QQAAAAAAZiYEgflqshfkOJMg3ZVeEJMgAAAAAAAzE4LAfNUxWY6+dcbHXR2HJ0FKpdJc7QoAAAAAYMEQgsB8NTkJsv+hZPjAMY8v2tCWukKyb2gsuwZG5nhzAAAAAADznxAE5qtlq5OV55Sv++445nFLY302rm1N4kgsAAAAAICZCEFgPps8Eqt35iOxujv1ggAAAAAAHI8QBOazzscPQab3ggAAAAAAcCQhCMxnU+Xo22Z8PDUJ0jcwVzsCAAAAAFgwhCAwn3VuKb/uvCuZGD/m8eQkyI6+/hSLpbncGQAAAADAvCcEgfls9flJY2syPpzsvfeYxxvXLk9TfV2GRify6P5DNdggAAAAAMD8JQSB+ayuLum4pHw9Qy9IQ31dLtzQlkQ5OgAAAADA0YQgMN89US9IRyUEUY4OAAAAAHAEIQjMd52VEKT3eOXoK5KYBAEAAAAAOJoQBOa7zsvLrzMch5Uk3Z3lSZAekyAAAAAAAEcQgsB8t+GSJIVkoDcZ3H3M466O9iTJvbsGMjZRnOPNAQAAAADMX6cUgnzkIx/Jxo0b09LSkqc//en5/ve/f9zPfupTn8pTnvKUrFq1Kq2trbniiivy13/916e8YVhymtuSNeeXr2eYBjlr1bK0NtVnbKKUB3YPzvHmAAAAAADmr5MOQf7u7/4u1113Xd72trflhz/8YZ70pCfl6quvzs6dO2f8/Jo1a/LmN785t9xyS26//fZce+21ufbaa/PlL3/5tDcPS8bjlKMXCoV0dZanQZSjAwAAAAAcdtIhyAc/+MH80i/9Uq699tpccskl+bM/+7MsX748n/jEJ2b8/POe97y86lWvysUXX5wLL7wwv/Ebv5HLL7883/nOd05787BkdG4pvx6vHL1yJFaPcnQAAAAAgCknFYKMjo7m1ltvzVVXXXX4C+rqctVVV+WWW255wt8vlUq5+eabs3379jznOc857udGRkZy8ODBI35gSXucSZAk6a5MgtwtBAEAAAAAmHJSIcju3bszMTGRjo6OI97v6OhIb2/vcX/vwIEDaWtrS1NTU17ykpfkT/7kT/KCF7zguJ+/4YYbsnLlyqmfc84552S2CYtPZyUE2bU9GR895vHUJIjjsAAAAAAAppxSMfrJam9vz2233ZYf/OAHefe7353rrrsu3/jGN477+euvvz4HDhyY+nn44YfnYpswf608J2lZmRTHkt3bj3k82Qny4N6hHBqdmOvdAQAAAADMSw0n8+F169alvr4+fX19R7zf19eXzs7O4/5eXV1dLrrooiTJFVdckbvuuis33HBDnve85834+ebm5jQ3N5/M1mBxKxTKR2I9+N1yL8hkR0jFurbmrG1typ7B0dyzcyBbzl5Zo40CAAAAAMwfJzUJ0tTUlCuvvDI333zz1HvFYjE333xznvGMZ5zw9xSLxYyMjJzM0sBUOfrWGR93VY7E2u5ILAAAAACAJCc5CZIk1113XX7+538+T3nKU/K0pz0tH/rQhzI4OJhrr702SfLa1742Z511Vm644YYk5X6PpzzlKbnwwgszMjKSL37xi/nrv/7rfOxjH6vuXwKL3VQ5+swhSHdne265b49eEAAAAACAipMOQV7zmtdk165deetb35re3t5cccUVuemmm6bK0h966KHU1R0eMBkcHMzrX//6PPLII1m2bFk2b96cv/mbv8lrXvOa6v0VsBRMlqP3bktKpfIRWdNMToLc3SsEAQAAAABIkkKpVCrVehNP5ODBg1m5cmUOHDiQFStW1Ho7UBtjw8l7zkxKE8l1dyUrzjzi8a0P7ss1H/vHdK5oyffe9PwabRIAAAAAYPadaG5wUp0gQA01tiTrNpWve7cd87iro6386OBwDgyNzeXOAAAAAADmJSEILCSP0wvS3tKYs1YtS5L07HQkFgAAAACAEAQWkum9IDOYnAbZrhcEAAAAAEAIAgtKx5bya99xQpDOcjl6T58QBAAAAABACAILyeQkyJ57ktGhYx53d5RDEJMgAAAAAABCEFhY2jqS1vVJqZjsvOuYx12TIUhff0ql0lzvDgAAAABgXhGCwEJSKDxuOfpFG9pSV0j2D41lV//IHG8OAAAAAGB+EYLAQvM45egtjfXZuK41SXkaBAAAAABgKROCwELzBOXoekEAAAAAAMqEILDQTE6C9N2RzND7MdkL0mMSBAAAAABY4oQgsNCs60rqm5KRg8n+B4953N05WY4+MNc7AwAAAACYV4QgsNDUNybru8vXM/SCTE6C7OjrT7F47KQIAAAAAMBSIQSBhehxekE2rl2epoa6DI1O5JF9h+Z4YwAAAAAA84cQBBaiyV6Q3q3HPGqor8tF69uSJNv1ggAAAAAAS5gQBBaizsokyAwhSHK4F0Q5OgAAAACwlAlBYCHqqEyC7H8wGT54zOPJXpDtvUIQAAAAAGDpEoLAQrR8TbLirPJ13x3HPO7uLB+HZRIEAAAAAFjKhCCwUE1Og8xQjj45CXLvroGMTRTnclcAAAAAAPOGEAQWqscpRz9r1bK0NTdkbKKU+3cPzvHGAAAAAADmByEILFSPMwlSKBTS1VE+EksvCAAAAACwVAlBYKHq3FJ+7bszKU4c87i7s3wkll4QAAAAAGCpEoLAQrXmgqRhWTJ+KNl73zGPJ3tBTIIAAAAAAEuVEAQWqrr6pOOS8vUMvSDdHSZBAAAAAIClTQgCC9nkkVgzhCBdleOwHtw7lEOjxx6XBQAAAACw2AlBYCF7nHL0dW3NWdvalFIpuWfnwBxvDAAAAACg9oQgsJBNTYIcG4Ikh3tB7u49OFc7AgAAAACYN4QgsJB1XFp+7f9RMrT3mMfdnXpBAAAAAIClSwgCC1lze7J6Y/l6pnL0Sgiyvc9xWAAAAADA0iMEgYXucXpBJo/D6uk1CQIAAAAALD1CEFjoHqcXpKujrfzo4HAODI3N5a4AAAAAAGpOCAIL3dQkyLHHYbW3NOasVcuSJD07TYMAAAAAAEuLEAQWus5KCLJrezI+eszjyWmQ7Y7EAgAAAACWGCEILHSrzkuaVyQTo8nunmMed3euSCIEAQAAAACWHiEILHSFwuOWo3d3ViZB+oQgAAAAAMDSIgSBxWDySKzeY3tBujrakyQ9ff0plUpzuSsAAAAAgJoSgsBi8DiTIBeub0tdIdk/NJZd/SNzvDEAAAAAgNoRgsBiMDUJsi05atqjpbE+G9e1JnEkFgAAAACwtAhBYDHYcElSqEuGdicDfcc87q4ciaUcHQAAAABYSoQgsBg0LkvWXlS+7j32SKzpvSAAAAAAAEuFEAQWi6lekGPL0Td3mgQBAAAAAJYeIQgsFp1byq+9x4YgXZ2TkyADKRZLxzwHAAAAAFiMhCCwWEyFIMceh3XemuVpaqjLobGJPLLv0BxvDAAAAACgNoQgsFhMHoe1Z0cydmTQ0VBfl4vWtyVJtusFAQAAAACWCCEILBbtncnytUmpmOy865jH3Z3K0QEAAACApUUIAotFoTCtHP3YI7G6OpSjAwAAAABLixAEFpPH6QXp7qwchyUEAQAAAACWCCEILCaPMwnS3bkiSXLvroGMjhfnclcAAAAAADUhBIHFpLMSgvRuS0qlIx6dubIlbc0NGS+W8sCewRpsDgAAAABgbglBYDFZ153UNSYjB5IDDx/xqFAopKvDkVgAAAAAwNIhBIHFpKEpWb+5fN279ZjH3Z3lcvSePiEIAAAAALD4CUFgsZl+JNZRujrKIYhJEAAAAABgKRCCwGIzVY4+wyRIh0kQAAAAAGDpEILAYvM4kyCTx2E9uHcoQ6Pjc7krAAAAAIA5JwSBxaZjS/l13/3JyJETH2vbmrOurSmlUnLPzoEabA4AAAAAYO4IQWCxaV2btJ9Rvu6785jHekEAAAAAgKVCCAKL0eP0gnTpBQEAAAAAlgghCCxGJ9ALsr3PcVgAAAAAwOImBIHFaGoS5NgQZGoSxHFYAAAAAMAiJwSBxajz8vJr3x1JceKIR10dbUmS3oPDOTA0Ntc7AwAAAACYM0IQWIzWXpg0LEvGhpK99x/xqL2lMWetWpYk2a4XBAAAAABYxIQgsBjV1ScbLi5fz1COfrgXRAgCAAAAACxeQhBYrB6nHF0vCAAAAACwFAhBYLHq2FJ+naEcvbuz3AtiEgQAAAAAWMyEILBYncgkSF9/SqXSXO4KAAAAAGDOCEFgseq4tPx68JFkaO8Rjy5c35a6QrJ/aCy7+kdqsDkAAAAAgNknBIHFqmVlsurc8nXfHUc+aqzPxnWtSRyJBQAAAAAsXkIQWMwepxdkc2f5SKztytEBAAAAgEVKCAKLWWclBOndesyjyV4QIQgAAAAAsFgJQWAxmypHPzYE6Z5Wjg4AAAAAsBgJQWAx66iEILvuTibGjnjU1TkZggykWCzN9c4AAAAAAGadEAQWs1XnJU3tycRosnvHEY/OW7M8TQ11OTQ2kUf2HarRBgEAAAAAZo8QBBazurqk49Ly9VHl6A31dblofVuSZLsjsQAAAACARUgIAovd4/WCdE6Wox+cyx0BAAAAAMwJIQgsdpO9IEdNgiTTQpC+gbncEQAAAADAnBCCwGLXuaX82jtDCNJRKUfvdRwWAAAAALD4CEFgsdtwcZJCMrgz6e874lFXZRLk3l0DGR0v1mBzAAAAAACzRwgCi11Ta7L2ovJ135G9IGeubElbc0PGi6U8sGewBpsDAAAAAJg9QhBYCqbK0Y88EqtQKKSroy1Jst2RWAAAAADAIiMEgaXgBMrRe/qEIAAAAADA4iIEgaXgBMrR7zYJAgAAAAAsMkIQWAomJ0F29yRjw0c86jIJAgAAAAAsUkIQWApWnJksW52UJpJddx/xaHIS5KG9QxkaHa/F7gAAAAAAZoUQBJaCQuG4vSBr25qzrq0ppVJyz86BGmwOAAAAAGB2CEFgqXicXpCuyjTIdr0gAAAAAMAiIgSBpeI4kyDJ4RBELwgAAAAAsJgIQWCpmJoEuT0plY541F0pR9/e5zgsAAAAAGDxEILAUrG+O6lrSIYPJAceOeLRVAjSe7AWOwMAAAAAmBVCEFgqGpqTdd3l66OOxNq0oa389sGR7B8aneudAQAAAADMCiEILCWdlV6Qo8rR21sac9aqZUmSHkdiAQAAAACLhBAElpKpcvStxzw63AuiHB0AAAAAWByEILCUHGcSJEm6OsohSE+vEAQAAAAAWByEILCUdGwpv+69LxkdPOJRd2e5F8QkCAAAAACwWAhBYClpW5+0dSQpJX13HvFoahKkrz+lUqkGmwMAAAAAqC4hCCw1k70gvbcf8faF69tSX1fI/qGx7OwfqcHGAAAAAACqSwgCS01n5UisviN7QVoa67Nx7fIkyXa9IAAAAADAIiAEgaVmMgSZoRy9u/PwkVgAAAAAAAudEASWmsnjsPruSIrFIx5N9oKYBAEAAAAAFgMhCCw1ay9K6puTscFk3/1HPOruMAkCAAAAACweQhBYauobkg0Xl6+P6gXpmjoOayDFYmmudwYAAAAAUFVCEFiKOitHYh3VC7JxbWuaGupyaGwiD+8bqsHGAAAAAACqRwgCS1FHpRz9qEmQ+rpCNm1oS6IXBAAAAABY+IQgsBQdZxIk0QsCAAAAACweQhBYijoqIciBh5JD+454NNkLsr1vYK53BQAAAABQVUIQWIqWrUpWnlu+7rvjiEdTkyCOwwIAAAAAFjghCCxVxzkSa3IS5N5dAxkdL871rgAAAAAAqkYIAkvV5JFYfVuPePvMlS1pb27IeLGUB/YM1mBjAAAAAADVIQSBpeo4kyCFQmFqGuRuR2IBAAAAAAuYEASWqslJkJ13JRPjRzzq0gsCAAAAACwCQhBYqlafnzS1JRMjyZ57jnjU3dGWJNneJwQBAAAAABYuIQgsVXV1yYZLytd9M5ej9whBAAAAAIAFTAgCS9lUL8iR5ejdleOwHto7lKHR8aN/CwAAAABgQRCCwFLWuaX8elQIsratOevamlIqJffsHKjBxgAAAAAATp8QBJayjkoIctRxWMnhcvTtytEBAAAAgAVKCAJLWcclSQrJQF8ysOuIR92dQhAAAAAAYGETgsBS1tSarLmgfN03cy/IduXoAAAAAMACJQSBpW6qHP3II7G6KpMgPUIQAAAAAGCBEoLAUnecXpBNG9rKbx8cyf6h0bneFQAAAADAaROCwFJ3nEmQ9pbGnLVqWZKkp29grncFAAAAAHDahCCw1HVUQpDd25PxkSMeTZWjOxILAAAAAFiAhCCw1K08O2lZmRTHk13bj3g0GYL09ApBAAAAAICFRwgCS12hkHReXr7u3XrEo+6OyiSIEAQAAAAAWICEIMDhI7GOKkfv6jh8HFapVJrrXQEAAAAAnBYhCDCtHP3ISZAL1remvq6QA4fGsrN/ZIZfBAAAAACYv4QgwJGTINMmPloa67Nx7fIkjsQCAAAAABYeIQiQrN+cFOqTQ/uSgz864tFUOXqfEAQAAAAAWFiEIEDS2JKs6ypfH68XxCQIAAAAALDACEGAsuP0gmzuPFyODgAAAACwkAhBgLLpvSDTTE6C9PT1p1gsHf1bAAAAAADzlhAEKJuaBDkyBDlvbWuaGuoyPFbMw/uGarAxAAAAAIBTIwQByjovL7/uuScZHZx6u76ukE0b2pLoBQEAAAAAFhYhCFDWtiFp3ZCklOy864hH3dOOxAIAAAAAWCiEIMBhxylH75oqRx+Y6x0BAAAAAJwyIQhw2HHK0acmQRyHBQAAAAAsIEIQ4LDOLeXXo8rRuyuTIPfuGsjoeHGudwUAAAAAcEqEIMBhU5MgdyTFw2HHGStb0t7ckPFiKffvHjzOLwMAAAAAzC9CEOCwdZuS+qZktD/Z/+DU24VCYVoviCOxAAAAAICFQQgCHFbfmKzfXL4+qhekSy8IAAAAALDACEGAI031gmw94u3ujrYkJkEAAAAAgIVDCAIc6Tjl6JPHYfUIQQAAAACABUIIAhxpqhz96EmQcgjy0N6hDI2Oz/WuAAAAAABOmhAEOFJnJQTZ/1AyfGDq7bVtzVnX1pxSKdnRN1CjzQEAAAAAnDghCHCkZauTFWeXr/vuOOJRd6deEAAAAABg4RCCAMeanAY5uhekciRWT68QBAAAAACY/4QgwLGeoBfEJAgAAAAAsBAIQYBjHW8SpLMyCSIEAQAAAAAWACEIcKyOLeXXnXcmE+NTb08eh9V3cCT7h0ZrsTMAAAAAgBMmBAGOteb8pHF5Mj6c7L136u225oacvXpZkmS7XhAAAAAAYJ4TggDHqqtPOi4tX/fO3AviSCwAAAAAYL4TggAzmypHn7kXRDk6AAAAADDfCUGAmR2nHH1qEqR3YK53BAAAAABwUoQgwMwmy9GPngTpODwJUiqV5npXAAAAAAAnTAgCzKzjkvJr/2PJ4J6pty9Y35r6ukIOHBrLzv6RGm0OAAAAAOCJCUGAmTW3J6vPL1/3HS5Hb2msz8a1y5Mk23v1ggAAAAAA85cQBDi+4/SCbO5ckUQIAgAAAADMb0IQ4PhOoBcEAAAAAGC+EoIAxzc1CbL1iLe7O9uSJD1CEAAAAABgHhOCAMfXWZkE2bU9GR+dentyEqSnrz/FYqkWOwMAAAAAeEJCEOD4Vp6TtKxMimPJ7u1Tb5+3tjVNDXUZHivm4X1DNdwgAAAAAMDxCUGA4ysUko5jy9Hr6wrZtKF8JJZydAAAAABgvhKCAI9vMgQ5qhy9e9qRWAAAAAAA85EQBHh8xy1HL4cgd5sEAQAAAADmKSEI8PimT4KUDpegd3WaBAEAAAAA5jchCPD4NlycFOqSoT1Jf+/U25PHYd23azCj48Va7Q4AAAAA4LiEIMDja1yWrN1Uvp7WC3LGypa0NzdkvFjK/bsHa7Q5AAAAAIDjE4IAT2yqF+T2qbcKhcLUkVjbHYkFAAAAAMxDQhDgiXVuKb/2bjvi7a7KkVg9ytEBAAAAgHlICAI8sY5KCNJ3ZAiy2SQIAAAAADCPCUGAJzZ5HNaee5KxQ1NvT06CbDcJAgAAAADMQ0IQ4Im1dSTL1yWlYrLzzqm3uzrakiQP7R3K0Oh4rXYHAAAAADAjIQjwxAqFaeXoh4/EWtvWnHVtzUmSHX0DtdgZAAAAAMBxCUGAE9NRCUGO6gXp7ixPg+gFAQAAAADmGyEIcGI6K+XovUeGIJO9ID16QQAAAACAeUYIApyY6ZMgpdLU292T5egmQQAAAACAeUYIApyYdV1JfVMycjDZ/+DU292dlRDEJAgAAAAAMM8IQYAT09CUrO8uX087EmtTZRJkZ/9I9g2O1mJnAAAAAAAzEoIAJ66j0gsyrRy9rbkhZ69eliTpcSQWAAAAADCPCEGAE9dZ6QXp3XrE25O9IEIQAAAAAGA+EYIAJ256Ofo0XZ3K0QEAAACA+UcIApy4zspxWPseSIYPTr09NQnSO1CDTQEAAAAAzEwIApy45WuS9jPL1zvvnHq7q+PwJEipVKrFzgAAAAAAjiEEAU7ODL0gF25oTX1dIQcOjaXv4EiNNgYAAAAAcCQhCHByZugFaW6oz/nrWpPoBQEAAAAA5g8hCHByJntBpk2CJNN7QYQgAAAAAMD8IAQBTs5kCNJ3Z1KcmHp7ei8IAAAAAMB8IAQBTs6aC5KGZcn4oWTvfVNvd3e2JUl6hCAAAAAAwDwhBAFOTl190nFJ+XrakViTkyA9ff0pFku12BkAAAAAwBGEIMDJm6Ec/by1rWluqMvwWDEP7xuq0cYAAAAAAA4TggAnb6oc/XAIUl9XyKaO8pFYdytHBwAAAADmASEIcPJmmARJph2JJQQBAAAAAOYBIQhw8jouLb8efDQZ2jv1dnclBNmuHB0AAAAAmAeEIMDJa1mRrDqvfD29HL3zcDk6AAAAAECtCUGAUzPZCzLtSKzJSZD7dg1mdLxYi10BAAAAAEwRggCnZoZy9DNWtqS9pSHjxVLu3z1Yo40BAAAAAJQJQYBTM1WOfvg4rEKhoBcEAAAAAJg3hCDAqemshCC7ticTY1NvT/aCbO89WItdAQAAAABMEYIAp2bVeUnzimRiNNndM/X21CRI70CtdgYAAAAAkEQIApyqQiHpuLR8Pa0XpKsSgvQ4DgsAAAAAqDEhCHDqZugF6epoS5I8tHcoQ6PjtdgVAAAAAEASIQhwOiZ7QaZNgqxta866tuYkyY4+R2IBAAAAALUjBAFOXceW8mvv1qRUmnq7u7M8DbLdkVgAAAAAQA0JQYBTt+HipFCXDO1OBvqm3u7uWJEk2d4rBAEAAAAAakcIApy6puXJ2ovK19OOxJqcBFGODgAAAADUkhAEOD0zlqO3JzEJAgAAAADUlhAEOD0zlKNvqoQgO/tHsm9wtBa7AgAAAAAQggCnabIcve9wCNLW3JCzVy9L4kgsAAAAAKB2hCDA6ZmcBNm9Ixkbnnq7uzINIgQBAAAAAGpFCAKcnvYzkmVrktJEsuuuqbe7Oyu9IEIQAAAAAKBGhCDA6SkUZuwFmQpBlKMDAAAAADUiBAFO32QvSO/Wqbe6Og6HIKVSqRa7AgAAAACWOCEIcPo6jy1Hv2B9a+rrCjk4PJ6+gyM12hgAAAAAsJQJQYDTN/04rMrUR3NDfc5f15pELwgAAAAAUBunFIJ85CMfycaNG9PS0pKnP/3p+f73v3/cz3784x/Ps5/97KxevTqrV6/OVVdd9bifBxagdd1JXWMyciA58PDU292VI7F69IIAAAAAADVw0iHI3/3d3+W6667L2972tvzwhz/Mk570pFx99dXZuXPnjJ//xje+kZ/7uZ/L17/+9dxyyy0555xz8sIXvjCPPvroaW8emCcampL13eXraeXoU70gJkEAAAAAgBo46RDkgx/8YH7pl34p1157bS655JL82Z/9WZYvX55PfOITM37+f/7P/5nXv/71ueKKK7J58+b8+Z//eYrFYm6++ebT3jwwj3RUjsSa1gvS3VmZBBGCAAAAAAA1cFIhyOjoaG699dZcddVVh7+gri5XXXVVbrnllhP6jqGhoYyNjWXNmjXH/czIyEgOHjx4xA8wz031gmydemt6CDJRLNViVwAAAADAEnZSIcju3bszMTGRjo6OI97v6OhIb2/vCX3HG97whpx55plHBClHu+GGG7Jy5cqpn3POOedktgnUwgyTIOeuWZ7mhroMjxXz8N6hGm0MAAAAAFiqTqkY/VTdeOON+du//dt8+tOfTktLy3E/d/311+fAgQNTPw8//PBxPwvME51byq97709Gysdf1dcVsqmjLYleEAAAAABg7p1UCLJu3brU19enr6/viPf7+vrS2dn5uL/7gQ98IDfeeGO+8pWv5PLLL3/czzY3N2fFihVH/ADzXOu6pK0zSSnpu3Pq7cly9J5eIQgAAAAAMLdOKgRpamrKlVdeeUSp+WTJ+TOe8Yzj/t773ve+vPOd78xNN92UpzzlKae+W2B+m5wG6ZvWC1IJQUyCAAAAAABz7aSPw7ruuuvy8Y9/PH/5l3+Zu+66K6973esyODiYa6+9Nkny2te+Ntdff/3U59/73vfmLW95Sz7xiU9k48aN6e3tTW9vbwYGBqr3VwDzw1Q5+uFekK5p5egAAAAAAHOp4WR/4TWveU127dqVt771rent7c0VV1yRm266aaos/aGHHkpd3eFs5WMf+1hGR0fzMz/zM0d8z9ve9ra8/e1vP73dA/PLDOXomyshyH27BjM6XkxTw5xWEQEAAAAAS9hJhyBJ8qu/+qv51V/91RmffeMb3zji/oEHHjiVJYCFaOo4rDuTYjGpq0vnipa0tzSkf3g89+0eyOZOHT8AAAAAwNzw/5INVM+aC5OGlmRsMNl3f5KkUCgc7gVRjg4AAAAAzCEhCFA99Q3JhovL172Hy9H1ggAAAAAAtSAEAaprhl6Qw5MgA7XYEQAAAACwRAlBgOqa7AXpPRyCdHWYBAEAAAAA5p4QBKiuyUmQacdhdVeOw3po71CGRsdrsSsAAAAAYAkSggDV1VkJQQ4+kgztTZKsaW3K+vbmJElPnyOxAAAAAIC5IQQBqqtlZbLq3PJ13x1Tb0/2gvT0OhILAAAAAJgbQhCg+joqvSB9x/aCbNcLAgAAAADMESEIUH2TR2JNK0fv7mxLohwdAAAAAJg7QhCg+ibL0fsOl6NPTYI4DgsAAAAAmCNCEKD6JidBdt6dTIwnSTZVQpCd/SPZNzhaq50BAAAAAEuIEASovlUbk6a2ZGIk2bMjSdLW3JBz1ixL4kgsAAAAAGBuCEGA6qurSzouLV9P7wVRjg4AAAAAzCEhCDA7OreUX3tvn3pLLwgAAAAAMJeEIMDsmCpHnzYJ0lkOQRyHBQAAAADMBSEIMDumJkEOhyDTJ0FKpVItdgUAAAAALCFCEGB2bLg4SSEZ3JkM7EySXLC+NfV1hRwcHk/fwZHa7g8AAAAAWPSEIMDsaGpN1l5Yvu7dmiRpbqjP+etakyhHBwAAAABmnxAEmD2P1wuiHB0AAAAAmGVCEGD2dFZCkGm9IN2VXpC7hSAAAAAAwCwTggCzp6NSjt53bDl6j+OwAAAAAIBZJgQBZs/kJMiu7cnYcJLDx2Ht2NmfiWKpVjsDAAAAAJYAIQgwe1aclSxbnZQmkl13J0nOXbM8zQ11GR4r5uG9QzXeIAAAAACwmAlBgNlTKBxTjl5fV8imjrYkyXZHYgEAAAAAs0gIAsyuzkovSO8MvSDK0QEAAACAWSQEAWbXUZMgSbK50gtyt0kQAAAAAGAWCUGA2TVZjt67NSmVi9BNggAAAAAAc0EIAsyu9ZuTuoZkeH9y8NEkSXdlEuT+3YMZGZ+o4eYAAAAAgMVMCALMrobmZF1X+brSC9K5oiXtLQ0ZL5Zy/+7BGm4OAAAAAFjMhCDA7JvqBdmaJCkUCumuHIm13ZFYAAAAAMAsEYIAs296L0hFV+VIrB7l6AAAAADALBGCALOvc0v5tXIcVpJs7pycBBmoxY4AAAAAgCVACALMvo5KCLL3vmS03AHSNXkcVt/BWu0KAAAAAFjkhCDA7Gtbn7R1JCklfXcmORyCPLz3UAZHxmu4OQAAAABgsRKCAHPjqHL0Na1NWd/enCTZsdORWAAAAABA9QlBgLkxVY5+uBekuzIN0tOrHB0AAAAAqD4hCDA3JntB+g6HIId7QYQgAAAAAED1CUGAuTE5CdJ3R1IsJkm6O9uSJD1CEAAAAABgFghBgLmxdlNS35yMDiT7H0iSdHeuSJJsdxwWAAAAADALhCDA3KhvSDZsLl/3lsvRN20oT4Ls7B/JvsHRWu0MAAAAAFikhCDA3Oms9IJUytFbmxtyzpplSfSCAAAAAADVJwQB5s4M5ejdlXJ0vSAAAAAAQLUJQYC5M1mO3ns4BOmqhCB6QQAAAACAahOCAHOn49Ly64GHkkP7kyTdnSZBAAAAAIDZIQQB5s6y1cnKc8rXfXckOXISpFQq1WpnAAAAAMAiJAQB5lZH5UisSi/Ihevb0lBXyMHh8fQdHKnhxgAAAACAxUYIAsytqV6QrUmSpoa6nL+uNUlyd+/BWu0KAAAAAFiEhCDA3DpqEiRJuvSCAAAAAACzQAgCzK3OLeXXvjuTifEkSfdUL8hArXYFAAAAACxCQhBgbq0+P2lsTSZGkj33JDlcjm4SBAAAAACoJiEIMLfq6pKOS8vXlSOxuivHYe3Y2Z+JYqlWOwMAAAAAFhkhCDD3jipHP3fN8rQ01mV4rJiH9w7VcGMAAAAAwGIiBAHm3lHl6PV1hWzaUJ4GubvXkVgAAAAAQHUIQYC5N1mO3rtt6i29IAAAAABAtQlBgLm34ZIkhWSgNxncnSTp7mxLkmwXggAAAAAAVSIEAeZec1uy5vzydaUXZGoSxHFYAAAAAECVCEGA2jiqF6S7sxyC3L97MCPjE7XaFQAAAACwiAhBgNqY6gUpT4J0rmhJe0tDxoul3L97sIYbAwAAAAAWCyEIUBtHlaMXCoVsrkyDbHckFgAAAABQBUIQoDYmj8PavT0ZH0lyuBdECAIAAAAAVIMQBKiNlWcnLSuT4niya3uSw70gPX1CEAAAAADg9AlBgNooFJKOypFYlXL0qUkQIQgAAAAAUAVCEKB2OitHYvUeGYI8vPdQBkfGa7UrAAAAAGCREIIAtTPZC9K3NUmyprUp69ubkyQ7dg7UalcAAAAAwCIhBAFqZ/okSKmUJOmuTIP0KEcHAAAAAE6TEASonfUXJ4X65NDepP+xJIfL0fWCAAAAAACnSwgC1E5jS7JuU/m6t3wk1uQkyHaTIAAAAADAaRKCALXVuaX8WglBukyCAAAAAABVIgQBamuqHH1bkmTThrYkya7+kewdHK3VrgAAAACARUAIAtTW9HL0JK3NDTlnzbIkSY9pEAAAAADgNAhBgNrqqByHtffeZHQoyeFeECEIAAAAAHA6hCBAbbV3JK3rk1Ix2XlXkqS7Uzk6AAAAAHD6hCBA7U31glTK0U2CAAAAAABVIAQBau+oXpDJSZC7e/tTKpVqtSsAAAAAYIETggC1N9kL0lueBLlgXVsa6grpHx5P78HhGm4MAAAAAFjIhCBA7XVWQpC+O5JiMU0NdTl/XWsSvSAAAAAAwKkTggC1t25TUt+UjPYn+x9MknR16gUBAAAAAE6PEASovfrGZP3m8nVfpRekUo6+vXegVrsCAAAAABY4IQgwP0weiXVUObpJEAAAAADgVAlBgPmh47Ly61GTID19/Zkolmq1KwAAAABgAROCAPNDZyUE6d2aJDlnzfK0NNZlZLyYh/YO1XBjAAAAAMBCJQQB5ofJSZD9DybDB1NfV8imDZO9II7EAgAAAABOnhAEmB+Wr0lWnFW+7rsjSdLVoRcEAAAAADh1QhBg/ug48kis7s62JMl2IQgAAAAAcAqEIMD80bml/NpXDkGmJkEchwUAAAAAnAIhCDB/TJWjb0uSbO5ckSS5f/dgRsYnarUrAAAAAGCBEoIA80dHZRJk511JcSIdK5qzoqUh48VS7ts1WNu9AQAAAAALjhAEmD/WnJ80Lk/GDyV77k2hUEh3p3J0AAAAAODUCEGA+aOuPtlwSfn6qF6Q7XpBAAAAAICTJAQB5pejekFMggAAAAAAp0oIAswvHZUQpK8cgkxNgghBAAAAAICTJAQB5pfOSjn65CRIJQR5eO+hDI6M12pXAAAAAMACJAQB5peOS8uv/T9KBvdkdWtTNrQ3J0l27Byo4cYAAAAAgIVGCALML83tyerzy9eVcvTJXpDtvQdrtSsAAAAAYAESggDzz1Hl6FO9IL0mQQAAAACAEycEAeafjkovSN+RvSA9ytEBAAAAgJMgBAHmn6MnQSaPwxKCAAAAAAAnQQgCzD8dlRBk193J+Gg2bWgr3/aPZO/gaA03BgAAAAAsJEIQYP5ZdW7SvDIpjiW7e9La3JBz1yxP4kgsAAAAAODECUGA+adQSDouLV/3HVmOLgQBAAAAAE6UEASYn6Z6QbYmSbo7y0di3d0rBAEAAAAATowQBJifOo4MQaYmQYQgAAAAAMAJEoIA81PnlvJr37akVEp3ZzkE2d7Xn1KpVMONAQAAAAALhRAEmJ82XJwU6pKhPUl/by5Y15aGukL6h8fTe3C41rsDAAAAABYAIQgwPzUuS9ZuKl/3bUtTQ13OX9eaJNnuSCwAAAAA4AQIQYD565hy9EovSJ8QBAAAAAB4YkIQYP6aLEfv25Yk6a6Uo99tEgQAAAAAOAFCEGD+mixH7y2HIF0mQQAAAACAkyAEAeavyUmQPTuSsUNTkyA7+gYyUSzVcGMAAAAAwEIgBAHmr/bOZPnapFRMdt6Vc9YsT0tjXUbGi3lo71CtdwcAAAAAzHNCEGD+KhQOT4P0bk19XSGbNpSnQbbrBQEAAAAAnoAQBJjfJntBKuXoXR16QQAAAACAEyMEAea3o8rRN1fK0bcLQQAAAACAJyAEAea3yeOw+u5ISqV0dToOCwAAAAA4MUIQYH5b15XUNSYjB5L9D6W7chzW/bsHMzI+UePNAQAAAADzmRAEmN8ampL1m8vXfdvSsaI5K1oaMlEs5b5dg7XdGwAAAAAwrwlBgPmvs3IkVu+2FAqFdHcqRwcAAAAAnpgQBJj/pnpBtiZJujr0ggAAAAAAT0wIAsx/0yZBkmSzSRAAAAAA4AQIQYD5r2NL+XXf/cnwwcOTIEIQAAAAAOBxCEGA+a91bdJ+Zvl6551TIcjDew9lYGS8hhsDAAAAAOYzIQiwMEwdibU1q1ubsqG9OUmywzQIAAAAAHAcQhBgYZgqRy/3gnTrBQEAAAAAnoAQBFgYjipHn+oF6R2o1Y4AAAAAgHlOCAIsDJPl6DvvTIoT6e4wCQIAAAAAPD4hCLAwrL0waViWjA0le++fOg5ruxAEAAAAADgOIQiwMNTVJxsuLl/3bc2mjrYkya7+kewdHK3hxgAAAACA+UoIAiwcU70gW7O8qSHnrlmeJNneaxoEAAAAADiWEARYOCZ7QY4qR9cLAgAAAADMRAgCLBydlRCkrxyCdHeWj8TSCwIAAAAAzEQIAiwcHZeWXw8+mgztPTwJ4jgsAAAAAGAGQhBg4WhZkaw6r3zdty3dneUQZHtff0qlUg03BgAAAADMR0IQYGHpPNwLcsG6tjTUFdI/PJ7eg8O13RcAAAAAMO8IQYCFpeOy8mvftjQ11OWC9a1JkrsdiQUAAAAAHEUIAiwsnZUQpHdrkugFAQAAAACOSwgCLCyTkyC77k4mxtLdcbgXBAAAAABgOiEIsLCsOi9pak8mRpPdPemqlKP3CEEAAAAAgKMIQYCFpa5u2pFY26YmQXb0DWSiWKrhxgAAAACA+UYIAiw8U+XoW3PumuVpaazLyHgxD+0dqu2+AAAAAIB5RQgCLDzTJkHq6gpT5ejblaMDAAAAANMIQYCFp2NL+bVvW5IIQQAAAACAGQlBgIVnw8VJoS4Z3JX09031gihHBwAAAACmE4IAC0/T8mTNheXrvq3p6qxMgghBAAAAAIBphCDAwjStF2RyEuT+3YMZGZ+o4aYAAAAAgPlECAIsTB2VEKRvWzpWNGdFS0MmiqXct2uwtvsCAAAAAOYNIQiwMHVWytF7t6ZQKGRz54okekEAAAAAgMOEIMDCNBmC7N6RjA2nq7MtSbK9VwgCAAAAAJQJQYCFqf2MZNmapDSR7LprqhdECAIAAAAATBKCAAtToXBEOXrXZAjiOCwAAAAAoEIIAixcHZUjsfoOhyCP7DuUgZHxGm4KAAAAAJgvhCDAwjVtEmR1a1M2tDcnSXaYBgEAAAAAIgQBFrKOSgjStzUpldLdWZ4G6RGCAAAAAAARggAL2frupK4hGT6QHHhkWjn6QI03BgAAAADMB0IQYOFqaE7WdZev+7alq3OyHP1gDTcFAAAAAMwXQhBgYZvqBdlqEgQAAAAAOIIQBFjYOreUX3u3ZlNHW5Jk98BI9gyM1HBTAAAAAMB8IAQBFrapcvRtWd7UkHPXLE+S9PSZBgEAAACApU4IAixsk5Mge+9PRgbSVTkSq6evv4abAgAAAADmAyEIsLC1rkvaOpOUkp13ZvNUOboQBAAAAACWOiEIsPBNK0fvqoQgPb1CEAAAAABY6oQgwMI3rReku+PwJEipVKrhpgAAAACAWhOCAAvfZC9I77acv641DXWF9A+P57EDw7XdFwAAAABQU0IQYOGbmgS5I011yQXrW5PoBQEAAACApU4IAix8ay9K6puTscFk3/3p6tALAgAAAAAIQYDFoL4h6bikfN279YheEAAAAABg6RKCAIvD9HL0zsokiBAEAAAAAJY0IQiwOEwrR58MQXb0DWSiWKrhpgAAAACAWhKCAIvDtEmQc1YvT0tjXUbGi3lwz2Bt9wUAAAAA1IwQBFgcOi4tvx54OHUj+w+XozsSCwAAAACWLCEIsDgsW5WsPLd83XfHVAiyvXegdnsCAAAAAGpKCAIsHp2VI7F6t6XbJAgAAAAALHlCEGDxmOoF2ZquSjn6diEIAAAAACxZQhBg8ZiaBNmazZUQ5P7dgxkZn6jhpgAAAACAWhGCAItH55by6867s6G1PiuXNWaiWMp9uwZruy8AAAAAoCaEIMDisWpj0tSWTIyksOeeqV6Q7b2OxAIAAACApUgIAiwedXVJx6Xl695t6epsS6IXBAAAAACWKiEIsLhMK0efnATpMQkCAAAAAEuSEARYXKbK0bela/I4LJMgAAAAALAkCUGAxaWjUo7ety3dneUQ5JF9hzIwMl7DTQEAAAAAtSAEARaXjkuSFJKBvqwq7k/HiuYkyQ7TIAAAAACw5AhBgMWlqTVZc0H5unfr4SOx9IIAAAAAwJIjBAEWn8lekL5tU+XoekEAAAAAYOkRggCLT2elF6R3W7oqvSA9QhAAAAAAWHKEIMDiM70cfeo4rIEabggAAAAAqAUhCLD4TB6Htbsnm9Y2plBIdg+MZM/ASG33BQAAAADMKSEIsPisOCtpWZUUx7P8wD05d83yJElPn2kQAAAAAFhKhCDA4lMoHNkL0qEXBAAAAACWIiEIsDh1VI7EmtYLcnevEAQAAAAAlhIhCLA4TfaC9G5NV6dJEAAAAABYioQgwOLUcTgE6d7QliTp6e1PqVSq4aYAAAAAgLkkBAEWp/Wbk0J9Mrw/5zftT0NdIf0j43nswHCtdwYAAAAAzBEhCLA4NbYk67uTJE2778wF61uTJNsdiQUAAAAAS4YQBFi8psrRt6a7c0WS8pFYAAAAAMDSIAQBFq+pcvRt6e4o94KYBAEAAACApUMIAixeU5Mg29LV0Z4k2W4SBAAAAACWDCEIsHh1bim/7rk3m9fWJ0l27BzIRLFUw00BAAAAAHNFCAIsXm0bktYNSUo5e/SBtDTWZXS8mAf3DNZ6ZwAAAADAHBCCAItbpRekbufhI7F69IIAAAAAwJIgBAEWt8lekN6t03pBBmq4IQAAAABgrghBgMWt8/Lya9+2bO40CQIAAAAAS4kQBFjcKsdhpe+OdG1oTZJsF4IAAAAAwJIgBAEWt7WbkvrmZHQglyzblyS5f/dgRsYnarwxAAAAAGC2CUGAxa2+IdmwOUmydmB7Vi5rzESxlHt3DtZ4YwAAAADAbBOCAItfx5YkSaHvjnR36AUBAAAAgKVCCAIsfpO9IL3b0tXZlkQvCAAAAAAsBUIQYPHrmCxH35ruzhVJkp5eIQgAAAAALHZCEGDxm5wE2f9QLlldSmISBAAAAACWAiEIsPgtW52sODtJ0pUHkiSP7DuUgZHxGm4KAAAAAJhtQhBgaegsl6O379+ejhXNSZSjAwAAAMBiJwQBloapcvSt6epoT5L88dd2pO/gcA03BQAAAADMJiEIsDRMlaNvy3/88fPSUFfIN3t25aoPfjP/+/sPpVQq1XZ/AAAAAEDVnVII8pGPfCQbN25MS0tLnv70p+f73//+cT97xx135JprrsnGjRtTKBTyoQ996FT3CnDqKsdhZeddeeHmdfn8rz0rTzp7ZfqHx3P9p7bm5z7+vdy/e7C2ewQAAAAAquqkQ5C/+7u/y3XXXZe3ve1t+eEPf5gnPelJufrqq7Nz584ZPz80NJQLLrggN954Yzo7O097wwCnZPX5SWNrMj6c7L03F5+xIp96/U/k919ycZY11ud79+3N1R/6Vj76jXsyNlGs9W4BAAAAgCo46RDkgx/8YH7pl34p1157bS655JL82Z/9WZYvX55PfOITM37+qU99at7//vfnZ3/2Z9Pc3HzaGwY4JXV1Sccl5everUmS+rpCfvHZF+Qrv/WcPHvTuoyOF/O+m7bnFX/63Wx95EANNwsAAAAAVMNJhSCjo6O59dZbc9VVVx3+grq6XHXVVbnllluqtqmRkZEcPHjwiB+A0zatF2S6c9Ysz1/9f0/LH/6bJ2XV8sbc+djBvOIj38l7vnhXDo1O1GCjAAAAAEA1nFQIsnv37kxMTKSjo+OI9zs6OtLb21u1Td1www1ZuXLl1M8555xTte8GlrDOSgjSu+2YR4VCIddceXa+dt1z8/InnZliKflv37ovV3/oW/nuPbvneKMAAAAAQDWcUjH6bLv++utz4MCBqZ+HH3641lsCFoOOSjl65Tismaxra86Hf+7J+e8//5ScsbIlD+0dyr//83/K7/7ff82BobE52igAAAAAUA0nFYKsW7cu9fX16evrO+L9vr6+qpaeNzc3Z8WKFUf8AJy2jkuSFJKB3mTw8ac7nn9xR7563XPz2mecl0Ih+b+3PpLnf/Cb+cLtj6VUKs3NfgEAAACA03JSIUhTU1OuvPLK3HzzzVPvFYvF3HzzzXnGM55R9c0BVFVze7Lm/PL140yDTGprbsg7XnFZ/u8vPyMXbWjL7oGR/Mr/+mH+81/fmt4Dw7O8WQAAAADgdJ30cVjXXXddPv7xj+cv//Ivc9ddd+V1r3tdBgcHc+211yZJXvva1+b666+f+vzo6Ghuu+223HbbbRkdHc2jjz6a2267Lffcc0/1/gqAE3WccvTH85SNa/KFX39Wfv35m9JYX8hX7+zLCz74zfzN9x5MsWgqBAAAAADmq5MOQV7zmtfkAx/4QN761rfmiiuuyG233Zabbrppqiz9oYceymOPPTb1+R/96Ed58pOfnCc/+cl57LHH8oEPfCBPfvKT84u/+IvV+ysATlTnZC/IiYcgSdLcUJ/rXtCVv/+1Z+eKc1alf2Q8v/+ZbfnZ//a93LtrYBY2CgAAAACcrkJpARxuf/DgwaxcuTIHDhzQDwKcnru/mPztz5UnQl733VP6ioliKX91ywN5/5e3Z2h0Ik0Ndfn1n7oov/zcC9NYf9LZMgAAAABwkk40N/B/rQOWls7KcVi7tifjo6f0FfV1hVz7E+fnK7/1nDy3a31Gx4v5wFd68rI/+U7+9eH91dsrAAAAAHBahCDA0rLynKRlZVIcS3ZvP62vOnv18vyPa5+aD73miqxe3pi7e/vzqo9+N+/8+zszNDpepQ0DAAAAAKdKCAIsLYXC4XL0730sGR06za8r5JVPPitfu+65eeUVZ6ZYSv77d+7PC//oW/lWz64qbBgAAAAAOFVCEGDpedLPll9v+5/Jn/1E8uA/nvZXrm1rzod+9sn5i2ufmrNWLcsj+w7ltZ/4fn77//xr9g2e2rFbAAAAAMDpEYIAS8+PvTb59/8vaT8z2Xtf8hcvTr70hmR08LS/+ie7N+Qrv/Wc/MIzN6ZQSD75w0dy1Qe/mc/9649SKpWqsHkAAAAA4EQVSgvg/yp3oi3vACdl+EDy5Tcn//LX5fvVG5NXfCTZ+KyqfP0PH9qXN37y9vT0DSRJnr95Q975ysty5qplVfl+AAAAAFiqTjQ3EIIA3PO15HO/nhx8tHz/tP+cPP9tSXPbaX/16HgxH/vGvfnTr+/I2EQpbc0NecNPd+ffP/281NUVTvv7AQAAAGApEoIAnIzhg8lX35Lc+j/K96vOS17xp8n5z6nK1+/o688bP7U1tz64L0ly5Xmr895rtuSiDe1V+X4AAAAAWEqEIACn4t5/KE+FHHi4fP/UX0yu+oOqTIUUi6X8zT89mPd+6e4Mjk6kqb4uv/pTF+W/PPfCNDWoaAIAAACAEyUEAThVwweTr70t+edPlO9XnZu8/E+SC55Xla9/dP+h/P6nt+br23clSbo62nLjNZfnx85dXZXvBwAAAIDFTggCcLru+0by2V9LDjxUvr/y2uQF70haTv8/h0qlUj5/+2P5g8/dkT2DoykUkl945sb8zgu709rccNrfDwAAAACLmRAEoBpG+pOvvT35wZ+X71eek7z8w8mFP1WVr983OJp3fuHOfOqH5VL2s1Yty7tfdVme172hKt8PAAAAAIuREASgmu7/VvLZX032P1i+/7GfT174rqpMhSTJN3t25U2f2ppH9x9KkrzqyWflLS+9JGtam6ry/QAAAACwmAhBAKptZCC5+R3J9/9r+X7F2cnL/zi56KqqfP3gyHg++NWe/MV370+xlKxpbcrbXnZJXv6kM1MoFKqyBgAAAAAsBkIQgNnywHeSz/5Ksu+B8v2T/2Ny9buTlpVV+frbHt6fN37y9tzd258keV73+rzrlZfl7NXLq/L9AAAAALDQCUEAZtPoYHLzO5N/+rMkpaT9zORlf5x0vbA6Xz9ezH/71r358M33ZHSimOVN9fm9q7vzH5+xMfV1pkIAAAAAWNqEIABz4cF/LE+F7L2vfH/Fvy9PhSxbXZWvv2fnQK7/1O35wQP7kiRPPndV3nvN5enqaK/K9wMAAADAQiQEAZgro0PJP7wr+d5HU54KOSN56YeS7p+uytcXi6X8r+8/lBu/dHcGRsbTWF/I6593UV7/kxemuaG+KmsAAAAAwEIiBAGYaw/9U/LZ1yd77infX/6zyYturNpUyGMHDuUtn9mWr921M0myaUNbbrzm8lx5XnW+HwAAAAAWCiEIQC2MHUq+/u7klo8kpWLS1pm89I+SzS+uyteXSqV8Yetjefvn7sjugdEUCslrf/y8/O5Pb05bc0NV1gAAAACA+U4IAlBLD38/+czrkz07yvdb/m3yovcmy9dU5ev3D43m3V+4K//31keSJGeubMm7XnVZfmpzR1W+HwAAAADmMyEIQK2NHUq+cUPyj39Sngpp3VCeCrn4pVVb4js7duf6T9+eh/ceSpK8/Eln5m0vuyRr25qrtgYAAAAAzDdCEID54pF/Lk+F7N5evr/sZ5IXvS9pXVuVrx8aHc+HvrYjf/7t+1IsJauXN+YtL70kr3ryWSkUClVZAwAAAADmEyEIwHwyNpx8873Jdz9UmQpZn7zkD5NLXlG1JW5/ZH/e8Mmtueuxg0mSZ29al/e8akvOWbO8amsAAAAAwHwgBAGYjx69NfnMryS77irfX/qq5MUfSFrXVeXrxyaK+W/fui9/fPOOjI4Xs6yxPr9zdXd+4ZkbU19nKgQAAACAxUEIAjBfjY8k33xf8p0/SkoTyfJ1yUs+UA5EquS+XQN546e25vv3702SPOmcVXnvNVuyudN/hgIAAACw8AlBAOa7H/1LuStk553l+0tekbz4D5O29VX5+mKxlL/9wcO54Yt3pX9kPA11hbzueRfmV37yorQ01ldlDQAAAACoBSEIwEIwPpp86/3Jdz6YFMeTZWsqUyGvTqpUat53cDhv+cy2fOXOviTJhetbc+M1l+epG9dU5fsBAAAAYK4JQQAWksf+tdwV0re1fL/5pclLPpi0d1RtiS9tfSxv/dwd2dU/kiT5jz9+Xn7vp7vT3tJYtTUAAAAAYC4IQQAWmvHR8kTIt95fmQpZnbzo/cmWn6naVMiBobG854t35e/++eEkSeeKlrzrlZflqkuqF7YAAAAAwGwTggAsVL1bk8+8rvyaJN0vSV76waS9s2pL/OM9u3P9p7fmwT1DSZKXXH5G3v6yS7O+vblqawAAAADAbBGCACxkE2PJd/4o+eb7kuJY0rIqedH7ksv/bdWmQobHJvJHX+vJn3/7/kwUS1m5rDG//5KL8zNXnp1CldYAAAAAgNkgBAFYDHq3JZ99fbkzJEm6XpS89I+SFWdUbYltjx7IGz55e+740cEkybMuWpf3vGpLzl27vGprAAAAAEA1CUEAFouJseS7f5x848bKVMjK5KdvTJ70c1WbChmfKObPv3N//uirPRkZL6alsS6//YLuXPsTG9NQX1eVNQAAAACgWoQgAItN353lqZAf/Uv5ftMLk5f9cbLizKot8cDuwVz/qa255b49SZLLz16ZG199eS4503/2AgAAADB/CEEAFqOJ8eQfP5x844ZkYjRpXpn89HuSK/591aZCSqVS/s8/P5x3feGu9A+Pp6GukF9+7gX5tZ/alJbG+qqsAQAAAACnQwgCsJjtvLs8FfLoreX7i64qT4WsPLt6Sxwczts+d0e+tK03SXLButa859Vb8uMXrK3aGgAAAABwKoQgAIvdxHjyvY8k//DuZGIkaV6RXP3u5Mn/sWpTIUly07bevPWz27KzfyRJ8nNPOzfXv3hzVrQ0Vm0NAAAAADgZQhCApWJXT3kq5JEflO8v/KnkZR9OVp1TtSUOHBrLjV+6O//7+w8lSTpWNOcdr7gsV1/aWbU1AAAAAOBECUEAlpLiRPK9jyb/8K5kfDhpak9e+M7kyl+o6lTI9+7bk+s/tTX37x5Mkrx4S2fe/vJLs6G9pWprAAAAAMATEYIALEW7dySf/ZXk4X8q31/wvPJUyOrzqrbE8NhEPnzzjvzXb92XiWIpK1oa8uaXXJx/+5RzUqhi4AIAAAAAxyMEAViqihPJP/3X5OZ3JOOHkqa25AXvSK68Nqmrq9oyd/7oYN7wyduz9dEDSZJnXLA2N7x6Szaua63aGgAAAAAwEyEIwFK3597yVMhDt5Tvz39O8vI/SVZvrNoS4xPF/MV3H8gffnV7hseKaW6oy3Uv6Mp/etb5aaivXuACAAAAANMJQQBIisXk+/8t+drby1Mhja3JC/4gecp/qupUyEN7hvKmT2/Nd+7ZnSS59MwVee81l+eys1ZWbQ0AAAAAmCQEAeCwPfcmn/u15MHvlu/Pe1byij9J1lxQtSVKpVL+362P5F1fuCsHDo2lvq6QX3z2+fmtq7rS0lhftXUAAAAAQAgCwJGKxeQHf5587W3J2FDSuDy56u3JU3+pqlMhO/uH8wefvzNfuP2xJMnGtcvznldvyTMvXFe1NQAAAABY2oQgAMxs7/3lqZAHvl2+P/eZySv+NFl7YVWX+eqdfXnLZ7al9+BwkuRnn3pOrn/RxVm5vLGq6wAAAACw9AhBADi+YjG59RPJV96ajA0mDcuS5781efp/qepUyMHhsbzvprvzN997KEmyvr0573j5pXnRljOqtgYAAAAAS48QBIAntu/B5HO/mtz/rfL9OT+evOIjybqLqrrM9+/fmzd+6vbct2swSXL1pR15xysuS8eKlqquAwAAAMDSIAQB4MSUSsmtf5F85S3J6EDS0JL81FuSH39dUle9QvPhsYl85Ov35GPfuDfjxVLaWxryphdfnNc85ZzU1RWqtg4AAAAAi58QBICTs/+hclfIfd8o35/9tOSVH03WbarqMnc9djBv/OTt+ddHDiRJnn7+mtx4zeU5f11rVdcBAAAAYPESggBw8kql5Id/lXz5zclof1LfnPzUm5Nn/GpVp0ImiqX8xXfvzx9+pSeHxibS1FCX37xqU37p2Reksb56nSQAAAAALE5CEABO3f6Hk8//RnLvzeX7s55SngpZ313VZR7eO5Q3fXprvr1jd5LkkjNW5L3XXJ4tZ6+s6joAAAAALC5CEABOT6mU/MvfJF9+UzJysDwV8pPXJ8/4taS+oYrLlPLpf3k07/j7O7N/aCx1heQXn31Bfuuqrixrqt70CQAAAACLhxAEgOo48Gh5KuSer5bvz/yx8lTIhouruszugZG84/N35nP/+qMkyblrlueGV2/JT1y0rqrrAAAAALDwCUEAqJ5SKbntfyU3XZ+MHEjqm5LnvTF55m9UdSokSW6+qy+//5lteezAcJLk31x5dt78kouzanlTVdcBAAAAYOESggBQfQd/lHz+N5MdXy7fn3FFeSqk49KqLjMwMp7333R3/up7D6ZUSta1NecPXn5pXrylM4VCoaprAQAAALDwCEEAmB2lUnL73yVf+r1k+EBS15g89w3Js34zqW+s6lK3Prg3b/jk1tyzcyBJctXFHXnXKy9L58qWqq4DAAAAwMIiBAFgdvX3Jn//W8n2L5bvOy9PXvmxpPOyqi4zMj6Rj3z93nzsG/dkbKKU9uaGvOFFm/PvnnZu6upMhQAAAAAsRUIQAGZfqZRs/X/Jl343ObQvqWtInvN7ybOvq/pUyPbe/rzhk7fntof3J0metnFNbrhmSy5c31bVdQAAAACY/4QgAMyd/r7kC9cld/99+b5zS/KKjyZnXF7VZSaKpfzVLQ/k/V/enqHRiTTV1+XXn39Rfvm5F6axvq6qawEAAAAwfwlBAJhbpVKy7ZPJF383ObS3PBXy7N9Onv07SUNTVZd6ZN9Q3vzpbflmz64kyebO9rz3msvzpHNWVXUdAAAAAOYnIQgAtTGwszwVctfny/cdlyWv+Ehy5hVVXaZUKuWzt/0of/D5O7JvaCx1heTanzg/v/3CrixvaqjqWgAAAADML0IQAGqnVEru+HTyxd9JhvYkhfpyT8hzfjdpaK7qUnsGRvKuL9yVT//Lo0mSs1cvy3tetSXP6Vpf1XUAAAAAmD+EIADU3uDuchByx6fL9xsuKU+FnPVjVV/q69t35vc/vS2P7j+UJHn1j52Vt7zkkqxure5RXAAAAADUnhAEgPnjjs8kX/jtZGh3eSrkWb+ZPPcNVZ8KGRwZz/u/vD1/ecsDKZWSta1NedvLL83LLj8jhUKhqmsBAAAAUDtCEADml8HdyZd+r1yeniTrNyev/Ghy1pVVX+qHD+3LGz95e3r6BpIkz9+8Ie985WU5c9Wyqq8FAAAAwNwTggAwP935uXJx+uCupFCXPPPXk+ddnzS2VHWZ0fFiPvaNe/OnX9+RsYlSWpvq84YXbc5/ePp5qaszFQIAAACwkAlBAJi/hvaWp0K2/t/y/bqu5BUfTc55atWX2tHXnzd+amtufXBfkuTK81bnvddsyUUb2qu+FgAAAABzQwgCwPx39xeSv/+tZKCvPBXyjF9JfvLNSWN1j60qFkv5m396MO/90t0ZHJ1IU31dfuUnL8rrnndhmhrqqroWAAAAALNPCALAwjC0N7np+uT2vy3fr91U7go552lVX+pH+w/l9z+zLf9w984kSVdHW2685vL82Lmrq74WAAAAALNHCALAwrL9S8nnfzMZ6E1SODwV0rS8qsuUSqV8/vbH8gefuyN7BkdTKCS/8MyN+Z0Xdqe1uaGqawEAAAAwO4QgACw8h/YlN70p+df/Vb5fc2Hyio8k5z2j6kvtGxzNO79wZz71w0eTJGetWpZ3v+qyPK97Q9XXAgAAAKC6hCAALFw9X04+/xtJ/2NJCsmPvy75qbdUfSokSb7Vsytv+vTWPLLvUJLklVecmbe+7NKsaW2q+loAAAAAVIcQBICF7dD+5CtvTv7lb8r3q88vT4Vs/ImqLzU4Mp4PfrUnf/Hd+1MsJWtam/LWl16SV1xxZgqFQtXXAwAAAOD0CEEAWBx2fC35/K8nB8vHVuVpv5xc9bakqbXqS9328P688ZO35+7e/iTJ87rX512vvCxnr67+BAoAAAAAp04IAsDiMXwg+crvJz/8q/L96o3Jy/80Of/ZVV9qdLyY//ate/Phm+/J6EQxy5vq87tXd+e1z9iY+jpTIQAAAADzgRAEgMXnnpuTz/16cvCR8v1Tfym56u1Jc1v1l9o5kOs/dXt+8MC+JMmTz12V915zebo62qu+FgAAAAAnRwgCwOI0fDD56luSW/9H+X7VueWpkAueW/WlisVS/tf3H8qNX7o7AyPjaawv5PXPuyiv/8kL09xQX/X1AAAAADgxQhAAFrd7v16eCjnwUPn+Kf8pecEfJM3Vn9R47MChvOUzd+Rrd/UlSS7a0Jb3XrMlV563puprAQAAAPDEhCAALH4j/clX35b8838v3688N3n5h5MLf7LqS5VKpXxxa2/e9rlt2T0wmkIhee2Pn5ff/enNaWtuqPp6AAAAAByfEASApeO+byaf+9Vkf2Uq5MpfSF7wzqSl+v+dsX9oNO/+wl35v7eWe0nOXNmSd73qsvzU5o6qrwUAAADAzIQgACwtIwPJ196e/ODj5fsVZ5enQi56/qws950du/OmT2/NQ3uHkiQvf9KZeevLLsm6tuZZWQ8AAACAw4QgACxN93+7PBWy74Hy/Y+9Nnnhu5KWlVVf6tDoRP7oaz3582/fl2IpWbW8MW95ySV59Y+dlUKhUPX1AAAAACgTggCwdI0OJl/7g+T7/7V8v+Ks5GUfTjZdNSvL3f7I/rzhk1tz12MHkyTP3rQu73nVlpyzZvmsrAcAAACw1AlBAOCB7yaf/ZVk3/3l+yv+Q3L1u5Nlq6q+1NhEMR//9n350Nd2ZHS8mGWN9fmdq7vzC8/cmPo6UyEAAAAA1SQEAYAkGR1K/uGdyfc+lqSUtJ+RvOyPk66rZ2W5+3YN5I2f2prv3783SfKks1fmxmsuz8Vn+O8vAAAAgGoRggDAdA99L/nM65O995bvn/Tvkp9+T7JsddWXKhZL+dsfPJwbvnhX+kfG01BXyOued2F+5ScvSktjfdXXAwAAAFhqhCAAcLTRoeTr705u+UiSUtLWmbzsQ0n3i2Zlub6Dw3nLZ7blK3f2JUkuXN+aG6+5PE/duGZW1gMAAABYKoQgAHA8D/1T8tnXJ3vuKd9f/rPJT9+QLJ+dcOKmbY/lLZ+9I7v6R5Ik/+HHz80bfnpz2lsaZ2U9AAAAgMVOCAIAj2fsUPL19yS3/GlSKiZtHclL/yjZ/JJZWe7A0Fhu+NJd+dsfPJwk6VzRkne98rJcdUnHrKwHAAAAsJgJQQDgRDz8g/JUyO6e8v2Wf5O86H2zNhXyj/fszvWf3poH9wwlSV5y+Rl5+8suzfr25llZDwAAAGAxEoIAwIkaG06+cUPyjx8uT4W0rk9e8sHkkpfPynLDYxP50Nd25OPfvi8TxVJWLmvM77/k4vzMlWenUCjMypoAAAAAi4kQBABO1iO3lqdCdt1dvr/01cmLP5C0rp2V5bY9eiBv+OTtueNHB5MkP3HR2tzwqstz7trls7IeAAAAwGIhBAGAUzE+knzzvcl3PpSUJpLl65KX/GFy6StnZ7mJYv78O/fnj77ak5HxYloa6/LbL+jOtT+xMQ31dbOyJgAAAMBCJwQBgNPx6A+Tz/5KsvPO8v0lryxPhbStn5XlHtg9mOs/tTW33LcnSXL52Stz46svzyVn+u89AAAAgKMJQQDgdI2PJN96f/LtD1amQtaWg5BLX5XMQndHqVTK//nnh/OuL9yV/uHx1NcV8svPuSC//vxNaWmsr/p6AAAAAAuVEAQAquVHt5WnQvq2le8vfnn5iKy2DbOy3M6Dw3nb5+7Il7b1JknOX9eaG169JT9+wex0kwAAAAAsNEIQAKim8dHk23+YfPsDSXE8WbYmefH7k8uumZWpkCS5aVtv3vrZbdnZP5Ik+bmnnZvrX7w5K1oaZ2U9AAAAgIVCCAIAs+Gx25PPvD7p21q+3/zS5CUfTNo7ZmW5A4fGcuOX7s7//v5DSZIN7c155ysvy9WXds7KegAAAAALgRAEAGbLxFi5J+Rb76tMhaxOXvS+ZMu/mbWpkO/dtyfXf2pr7t89mCR50WWd+YNXXJoN7S2zsh4AAADAfCYEAYDZ1ru1PBXSe3v5vvvFyUv/KGmfnSmN4bGJfPjmHfmv37ovE8VSVrQ05M0vuTj/9innpDBL4QsAAADAfCQEAYC5MDGWfOdDyTffmxTHkpaV5amQy18za1Mhd/7oYN7wyduz9dEDSZJnXLA2N7x6Szaua52V9QAAAADmGyEIAMylvjvKUyGP3Va+33R18rIPJSvOnJXlxieK+YvvPpA//Or2DI8V09xQl996QVd+8Vnnp6G+blbWBAAAAJgvhCAAMNcmxpN//OPkGzcmE6NJ88rkp29Irvh3szYV8tCeobzp01vznXt2J0kuPXNF3nvN5bnsrJWzsh4AAADAfCAEAYBa2XlXeSrkRz8s31/0guRlf5ysPGtWliuVSvl/tz6Sd33hrhw4NJb6ukJ+8dnn57eu6kpLY/2srAkAAABQS0IQAKilifHklj9Jvv6eylTIiuTq9yRP/g+zNhWyq38kb//8HfnC7Y8lSc5buzw3vHpLnnnhullZDwAAAKBWhCAAMB/svDv57K8kj/5z+f7C5ycv/3Cy8uxZW/Krd/blLZ/Zlt6Dw0mS1zzlnLzpxRdn5fLGWVsTAAAAYC4JQQBgvihOJLd8JPmHdyUTI0lTe3L1u5If+/lZmwo5ODyW9910d/7mew8lSda3N+cdL780L9pyxqysBwAAADCXhCAAMN/s6ilPhTzy/fL9BT9ZngpZde6sLfmDB/bmDZ+8PfftGkySXH1pR97xisvSsaJl1tYEAAAAmG1CEACYj4oTyfc+lvzDO5Px4aSpLXnhO5Mrr521qZDhsYl85Ov35GPfuDfjxVLamxty/Ysvzs8+9ZzU1c3OmgAAAACzSQgCAPPZ7nvKUyEPf698f/5zkpf/abL6vFlb8u7eg3nDJ7fmXx/enyR5+vlrcsOrt+SC9W2ztiYAAADAbBCCAMB8V5xI/um/Jje/Ixk/lDS2Ji98R3Ll/5fU1c3KkhPFUv7HPz6QD3x5ew6NTaSpoS6/8fxN+c/PuSCN9bOzJgAAAEC1CUEAYKHYc2/y2V9NHvrH8v3GZycv/5NkzfmztuTDe4fypk9vzbd37E6SXHzGirz3mi25/OxVs7YmAAAAQLUIQQBgISkWkx98PPna25OxoaRxeXLVHyRP/cVZmwoplUr59L88mnf8/Z3ZPzSWukLyn551fq57QXeWNdXPypoAAAAA1SAEAYCFaO99yWd/LXnwO+X7834iecWfJmsumLUldw+M5B2fvzOf+9cfJUnOXbM873nVljxr07pZWxMAAADgdAhBAGChKhaTf/7vyVfflowNJg3LkqvenjztP8/aVEiS/MPdffn9T2/Ljw4MJ0n+zZVn580vuTirljfN2poAAAAAp0IIAgAL3b4Hyl0hD3y7fH/uM8tTIWsvnLUlB0bG8/6b7s5ffe/BlErJuramvP3ll+YlW85IoVCYtXUBAAAAToYQBAAWg2IxufUvkq++NRkdKE+FPP8tydP/S1I3e70dtz64N2/45Nbcs3MgSXLVxR155ysvzRkrl83amgAAAAAnSggCAIvJvgeTz/1acv83y/fnPD15xUeSdZtmbcmR8Yl89Ov35qPfuCdjE6W0NTfkDS/anNc85Zw0NczesVwAAAAAT0QIAgCLTamU3Po/kq+8JRntTxpakp/6/eTHXz+rUyHbe/vzhk/entse3p8kaagr5Px1renqaK/8tKWrsz3nrVmehnrhCAAAADD7hCAAsFjtfzj5/K8n9/5D+f7spyav+GiyvmvWlpwolvLXtzyQD//DPdk7ODrjZ5rq63LhhrZyKFIJSLo72nP26mWpq9MnAgAAAFSPEAQAFrNSKfmXv06+/OZk5GBS35z85JuSZ/7arE6FlEql9B4cTk/fQHp6+7O9rz87+vrT0zeQQ2MTM/7Ossb6bOpoy6YN7enubMumSjhyxsoWZesAAADAKRGCAMBScOCR5PO/kdzztfL9WVeWp0I2bJ7TbRSLpTy6/1C29/anZ2d/enrLwcg9uwYyOl6c8XfamxuyadrUSFdHe7o627K+rVk4AgAAADwuIQgALBWlUnLb/0xuelMyciCpb0qed33yzF9P6htqurXxiWIe2juUnsq0yOTkyH27BjNenPmfIKuWN051jXR3tE9NjqxubZrj3QMAAADzlRAEAJaaA48mf/+byY6vlO/PfHJ5KqTjkppuayaj48U8sGcw23vLoUg5HBnIA3sGc5xsJOvamsvHaW1oT3dnOSTZ1NGeFS2Nc7t5AAAAoOaEIACwFJVKyb/+bXLTG5LhylTIc38v+YnfTOrnf1gwPDaRe3cNTE2O9FSO13p476Hj/s6ZK1vK0yKd7dm0oS3dne25aENbljfVdgoGAAAAmD1CEABYyg4+Vp4K6bmpfH/Gk8pTIZ2X1XRbp2pwZDz37Dx8nNb2SkDSe3B4xs8XCsk5q5en66jOkQvWt6alcfaK4wEAAIC5IQQBgKWuVEpu/z/Jl34vGd6f1DWWp0Ke9VsLYirkRBw4NJYdk1Mjff1TP7sHRmf8fF0h2biuNV0b2tPVebh3ZOO61jTW183x7gEAAIBTJQQBAMr6e5O//61k+xfL952XJ6/8aNK5pbb7mkV7BkbS0zeQHTv7K70j5SmSA4fGZvx8Y30hF6xry6bpZeyd7Tl3zfLU1xXmePcAAADAExGCAACHlUrJ1v+XfOl3k0P7krqG5Dm/mzzruqShqda7mxOlUim7+key/ai+kZ7e/gyOTsz4O80Ndblow/QjtcrXZ61aljrhCAAAANSMEAQAOFZ/X/KF65K7/75837EleeVHyp0hS1SpVMqPDgyXQ5G+/kpI0p97dg5keKw44+8sb6ovT4sc1TnSsaI5hYJwBAAAAGabEAQAmFmplNzxqeQLv5Mc2lueCnnWdeXJkCUyFXIiJoqlPLx3aFrXSLl35N5dAxmbmPmfTytaGsqBSGd7uja0VXpH2rOurXmOdw8AAACLmxAEAHh8A7uSL/52cudny/cbLi1PhZz55Nrua54bmyjmwT2D6ekbKPeNVHpHHtgzlInizP+sWtvadEzfSNeG9qxcvjgK6gEAAGCuCUEAgBNzx6eTL/x2MrQnKdQnz/qt5Lm/lzSYXjgZI+MTuW/X4DGTIw/tHcrx/rXVsaL5mL6RTR3taWtumNvNAwAAwAIjBAEATtzg7uSLv1MORJJk/cXJKz+anPVjtd3XInBodCL37ByYFo6UA5JH9x867u+ctWpZORSpTIx0d7bnog1taWmsn8OdAwAAwPwlBAEATt6dny1PhQzuKk+F/MSvJ899Y9LYUuudLTr9w2PZsXOgUsh+OCTZ2T8y4+cLheS8Ncsrhezt5eO1Ottzwbq2NDXUzfHuAQAAoLaEIADAqRnck3zp95Jt/698v667PBVy9lNqu68lYv/QaLlvpK8/O/rKfSM9ff3ZNzQ24+fr6wo5f13r1HFakz8b1y5PQ71wBAAAgMVJCAIAnJ67Pp/8/XXJ4M6kUJc889eS573JVEgNlEql7B4YLYcifUdOjvQPj8/4O031dblgfWu5hH1a78g5q5enrq4wx38BAAAAVJcQBAA4fUN7k5vemNz+d+X7tZuSS1+VtHeWf9omXzck9Y213esSVCqV0ntwuByK9B7uHNmxcyBDoxMz/s6yxvpctKHtcBl7JSQ5c2VLCgXhCAAAAAuDEAQAqJ67v5j8/W8mA33H+UAhWb42aT8jae+ohCMd5fu2jmmhSUfS0DyXO1+SisVSHt1/KD2VyZEdfQPZ3tufe3YNZHS8OOPvtDU3lHtGOtqneke6Otqyvr1ZOAIAAMC8IwQBAKpraG/yL3+d7Hsg6e9LBnqT/t5yMFKc+UimGS1bPUM40jktPKn8NC6btT9lqRqfKOahvUOViZHDvSP37RrMeHHmfxKuWt6Yrg3t6eo8snNkTWvTHO8eAAAADhOCAABzo1hMDu1N+h+bFo48dmRQMnk9MXri39u8shKIHBWOTIUnlSCluW32/rYlYnS8mAf2DGZ7b/9U78iOvoE8sGcwx8lGsq6t+Ygy9u7OtmzqaM+KFseiAQAAMPuEIADA/FIqJYf2VaZHKsFI/2PlSZL+3iPfHz904t/b1HbkNMnxpkyaVySOdTopw2MTuXfXwNTkSE9vf3p29ufhvcf/388ZK1sqx2m1TR2rtamjLcubGuZw5wAAACx2QhAAYGEqlZLhA4fDkYG+GSZLKj9jgyf+vQ3LjpomOWPmKZNlq4UlT2BwZDz37Dx8nNb2SkDSe3D4uL9zzppllWO12qcmSC5c35aWxvo53DkAAACLhRAEAFj8RvqPDUeOmTLpS0YOnPh31jc/Qbl75XXZmqSubvb+tgXowKGx7JicGunrn/rZPTDzMWh1hWTj2tbKkVptlYCkPeeva01jvf/ZAgAAcHxCEACASaNDT3wE10Bv+biuE1XXWAlHZuosmTZl0rouqVva0w57BkbS0zeQHTv7K70j5SmSA4fGZvx8Y30h569rPaKIvaujLeetbU19nSkdAAAAhCAAACdvbLgckBzvCK7J8GRo94l/Z6E+adswwxFcR02ZtG5I6pdOb0apVMqu/pFsP6pvpKe3P4OjEzP+TnNDXS5c35buznLPSHclIDlr1bLUCUcAAACWFCEIAMBsGR9NBndOmyw5zpTJ4K4kJ/pPrULSuv7YcGQqPKlct3UkDU2z+dfVVKlUyo8ODJdDkb7+Su9IeYpkeKw44+8sb6rPpg1th6dGKr0jnStaUtDvAgAAsCgJQQAAam1ivByEHDNNctSUycDOpDTz9MOMlq99/CO4Jl8bW2bvb5tjE8VSHtk3VD5Oa+dAtldCkvt2DWZ0YuZwpL2l4YjjtLo72rOpoz3r2pqEIwAAAAucEAQAYKEoTiRDe44KR2bqL+lLijP3aMyoZdVRhe4zTZl0Jk2ts/anzbaxiWIe3DOYnr6BSkBS7h15YM9QJooz/zN3TWtTNm2YPFarvXKsVltWLV+8EzYAAACLjRAEAGCxKRbL5e3HO4Jr+pTJxMiJf2/zisOByExHcE2+39w+e39blY2MT+S+XYPp6euv/Aykp68/D+0dyvH+9buhvfmIyZGuzvZs2tCW9pbGud08AAAAT0gIAgCwVJVKyfD+xzmCa1p4MjZ04t/b2HrsNMlMUyYtK5N5etzUodGJ3LNzYFo4Ug5IHt1/6Li/c9aqZeVQZCogac9FG9qyrKl+DncOAADAdEIQAAAeX6mUjPRXgpLjHcFVeX+0/8S/t6HlyHBkxv6SzmTZ6nkTlvQPj2XHzoHs6OvP9t6BqWO1dvbPPFFTKCTnrll+eGqkEo5csL41zQ3CEQAAgNkmBAEAoHpGBqYdu/U4Re/DB078O+ubpgUlR0+WTLtevjapq5u9v+1x7B8aLfeN9PVXApLy9Mi+oZm7WerrCtm4dnm5b2RDe7o7yyHJxrWtaaivzd8AAACwGAlBAACYe2OHpoUjvcefMjm098S/s66hHJLMdATX9MCkdX1SN/tTGKVSKbsHRsuhyLS+kZ6+/vQPj8/4O031dVnX1pS2loa0NTektbkh7ZXrtubGtLU0pL3y/uR129Tzyk9LQxoFKQAAAEmEIAAAzGfjI5VA5Ohy98kpk8pkyeCuE//OQl3SuuE4R3BNC0/aNiT11S87L5VK6T04XA5Feg93juzYOZCh0YmqrNHcUJf2lkpYUvmZClMq77dPhSaNRwQo0z+7vKk+hXlyFBkAAMCpEIIAALDwTYwlAzsf/wiu/r5kcGdSKp7glxaS1nXTCt2nHcE11VlSmTxpaD7tP6FYLOXR/Yeyd3A0gyPj6R8Zz8DweAZGpv1U7vuHxzMwMpaBkfEMjkxM3Q+PnejfdmIKhaStadq0yQxTJ+3TgpXDAcqxwUpTg+kUgP+/vbuPkasq/D/+uffO07a7s+1u290uFKharQgt2EIpYPCh2hBCbCRICIYKGKNZsNAYFaPUGEOJhohELKIGTAyCmBSVSEmpWmMsDy3yC6BBUL62sE9tafd5nu49vz/uzOzc2ZnZ2W13Z3f2/Upu7p1zzz1zZunpwH445wAAgJlHCAIAAID5w3P9WSOVluDKnc0kZmU0tJQIR0rMMgk3TN9nk5R2PQ0XhSa5MCVXPpgoCFRSBUFLPmBJazjlyvVO77/+R0L22FJeEyznlQtTxgUrsZAWhB3ZNrNTAAAAAFSn2twgNIN9AgAAAKaH7YwFE5V4njRyvGhmSfEsk+zZTfl7l4y+K/X9s3K7seaCmSXLS2/0Hmn09zexnew5NPZ6gqWpwo6tRQsiWrQgMskfTJAxRom0p8FkOjgbpeB6sCBYKQxb/NkpY69H036YlMp4Op5J6fhw6pT6ZlnSwkj5mSmFy3kF91Qpqh8LKRqa/r1hAAAAAMwNzAQBAAAAihkjjZ7IhiPdlTd6zyRO/f2somDEKQpJikOTwOtKdcJVtlHFezjB165sjWYsjXqWRtKWRjJGw2lpOGNpOC0NpY2G0tJQShpMGQ2mpIGU0UBS6k8Z9SeM+pOehqZjdopjZ5fyctQYDQdnppRZ+qvUpvQLIyFmpwAAAACzFDNBAAAAgKmyLGlBi3+0nVu+njFSoj8YjpTbvyQzWn7fEuNKriu5yen5PNPAkdSYPU6FiTr54MWzQjKWIy97uModtjJylJGtjHGUNrZSucPzj6RnKeXZysiWK0eZlCM36T+Xe97NtpE79xtHx+Xk23az1/n6xlYoFFYoHFY4HFEkElEkHFE4ElY0ElEsElE0GlUsGlE0ElFDLKZYNKIFsagaolEtiEW1oCGmhbGoopGIrKIgaaIZQAAAAABOHSEIAAAAMFWWJTUs8o9lqyeu73mSlyk63Em+Tk/hmaIydyptlGpzEvXLBEBWPgDyg5Wp/7PQKTZQgZs9TsOkn0KebLmWIyNHnu3IWH4YZOywZDuy7JAsJyTLDst2QrJDIdlOWFa1M3iKQ5dpmVU0yZlFTjg788k+vT9MAAAAoAxCEAAAAGCm2LZkRySd2t4ec5Ln+TNeCoMRd7KB0FTCmCraLeqH8TLy3IzcTFpuJp2/Nq5fbrLPGC8jy/jtWV5atnFlGVe2yc5hyZ2t0st92fJkG09S2g9Z5hPLrj44iTRK8Q7/aFo+/jrcUOtPAwAAgFmMEAQAAADA9LNtSbY/E2CWy00qOR0TS1zPaCCZ0vBoUsOjCQ0lkhoZTWok4R+jiaRGk/6RSCSVTKaUSKWUTKaUTKeUSiWVSqWUTqdlvIxC8uTILTi7cizPP8tTWBk5Gnvt33dLPhe2PMUco6htsmdPEdsoYnuKWv79sOUplD3n38+fwyInG/hYxpVVMmBKV1gCzpPclH9U450K92KLpPgZUnx5UUjSkS3r8Je2Y/kxAACAeYkQBAAAAACmiWNbijdEFW+ISiq/WWM1khlXQ4mMhpIZDSYyGk7617nXQ0m/bDCR0clkZqxutjz3eiiZGWs0fWqfL6ch7IzfWD4aUjxiqylmKx6RmiKWmiKWGsPyj4jUGLa0IGS0MCwtDFmK2n6okg9T3HR2351uaaBr7Jy7To9IiZP+0fda+Q460bFAJL58fEgS75Ca2udESAcAAIDJsYwxpedmzyLV7vIOAAAAAKjM84yGUxkNJ10NJdP5AKUwJCkVoAwW10lmlMqUmekxRY5tqTEaGjtiIS2IOIqGHMXCtmLh7DnkKBqyFLdG1eoe0yL3qJrTx9SYOqrGVJ8WJPoUG+1VZLRX4cTxKt/dkhYuDQYjgeDkDH+mSYz/JgUAAJgNqs0NmAkCAAAAAPOIbVtqioXVFAtLip1SW8mM64cpiYwGk+mSwcpwsnSAMlQYvqQyMsZfPqx/NK3+0clOUVmUPd437k5EaS2zTqhd76rdOqF26121W++qwz6hdtsvX6oTCisjDff5R/f/K/tOKWeBRqLLNBprU7KhTamFbcosXC630V+Oy2ruUKhpmWKRiKLZwCYWdhQN2bJtluQCAACYaYQgAAAAAIApiYb8WRotCyOn1I7nGY2k3fxyXmMhSVojKVeJtKdE2lUi4yqZ9sbOaVeJtKtkJnft30ukPSXzdSI6kY6pO9Mm1yu9EIIlTy0azIYkx9VunVCb9a7aNRaatFsnFLdGFHFHFBn5Py0a+b+ynydjbPVqsbrNYvWYFvWaxeo2LTpmt+qEs0QnQ0s0EF4iO7wgH5DkZrlEw44/0yUfoBTcK3iduw7OkikqCzkELwAAYN4jBAEAAAAA1JRdsAxW2zSuNpVxPSUyY+FJLixJpD0lsyFLYdlw2tVraU+HskGLlxhUdLRXsUSfFiR61Zg6qnj6qBalj2qRe0yt3nEtNicVsjydoeM6wyqzFFfGP06MNKrHLFavaVG3aVGv/NCkxyxWj2lVj1msk2qUNPUgI+LYio4LS+yioCV7XUUAkwtpKgUwDsELAACYRQhBAAAAAADzQsix1ejYaoxO438KuxlpqDe/ibvb3yW3/22Zfn8zd2uwW6GhbtluQoutIS22hvRBHSnbXNqKaCC8RCdDS/Wu3apjdquOWi3qVat6vMXq8hbrnUyzRlwrP0sm7Y7NeEm5nlKup0Flpu8zFwk7VjZMyQUjwaCkMGjJ1QnMiCmonysbF9IU1SN4AQAA5RCCAAAAAABwujghqfkM/5DkZI8AY6TESWmgWxrskga6Cq798ESDXdLIcYVNSq2pLrWmuvTesm9qSY3LpKXLpXiHvKblyixsV6qhTYkF7RqNLtNwtE0jdkN++bBkumCZsfySYrnlxIqXFBs/SyZfJ/tsyvXyvUm7RmnX3wtmpoRsa/yslQpLhUVDBaFM0ZJkhfu4FIY0xUFNyLFn7PMBAICpIwQBAAAAAGAmWZbUsNg/2s4tXy+TzM8o8YOR7mxI8s7Y9WC35KX92SdDvVL3y7IlRbJHY2F7kSYp7m/grvgZY9etHVK8Q2rqkBYulezJ/3Lf9UwgIEkWLTuW28clWRCylN7PpURIU7AXTP65dDB4yXjG30smOemuT1kueAnMVpkggClcgmx8vbFZMuVCmjDBCwAAk0YIAgAAAADAbBSKSovP8Y9yPE8aOVYQknSVDk6S/VJqUDo2KB37d/n27JDU2O6HIvHlfjCSPxdch2OBxxzb0oJISAsip+WTV8XzzFiIUnKmStGMlsz4vWCqD2lcJTKeUpnaBi+ObeWXARsLX0rt8+IHKbZtybElx7L8a8uSY49dj5UpeN+yFHL8s1NY19b4snFtKlAWsgvasYvb1Li2bLvofra+ZbHkGQBgaghBAAAAAACYq2zbXwqrcZmkC8rXSw4VhSTvjM0kyQUmw32Sl5EG3vaPShoW+7NJmpYXhSQd2bIOv840/uLati01RBw1RMYtODZtPM8o5XqBoCQRWDYsuMTYRDNaqglpkgXBi+sZDadcDafcGfvMs4VtqUSIUhisqESIEgxwnFJhTMF1vp1S71PUTj7gKQqPnKI+lQ+Axu6HbDtQt3SbKurn+DYdp3QQVdyWbYlQCcC8QggCAAAAAEC9izZK0VXSklXl6wQ2dX+n9D4lA91SZlQaPeEfva+Wby8UGwtEcufi68Y2yQmf/s87TWzbUsz2l6qaKcaMzXgJLB8W2M9lLIDJ7dOSzHhyPSPXM/KMf3aNkecZuZ5KlPnX454pqOuVum+Uf764zYyXbdsUtVPwXmNtV/45eEbyXCNpgoqoSqVQySkMTkrNJAoELCofzIybKaSSs4cCoVGZUCkYSKnMjKai2U0l3qfaGUmWJVmy8jmubVuypEC5JUlFr+2CZ2UpX25ZJZ4vejZQh5AKOK0IQQAAAAAAQNGm7utL18lv6l68mXvhPiX+pu7KJKQTb/lHWdlN3Yv3KYkX7FMSXy5Fm6bhA88NlmXl9xapZ8b4QcjEYYqR52lciBIMVPzQpbgt1y0IfYrqlgpmAveLyvJ98orbHGurdJvBUClT1KcJ2ykTKmWK6hpCpbpgWdlgRQqGKxofothW4b3S4Yqy9e0SAUzu/Qrbzb23SgU1hSGRVTrYUaC+/3zuvUt+jsD1+GeLP4dV4r1L97XwZ1L4uYPvXdXPp/C97cKfT5l2K713iXYL31tFn+MTq9t0VuuC0/gnbP4gBAEAAAAAANWxrIJN3T9Uvl464YcilfYpGezyl98q2NS9rEjT+H1KCkOSU9jUHbODZY39H/44dSYQJGlciFIpVMq4pWYPBdsqHQAFQ6VM0fOlZiSNC4DKhEGZQJDkyXGTctxRhbyEQm5CIS+pkJtQ2B1VyCQVdhMKm4Sinn+OeElFvITCJqmoSSpiEopmr6NKKmaSisk/IiYtScrIkSdbbvbIXWdkyzNj5W5xnfw9J/CcKytYZsaeyQTq5cqc0vVy7ZvgM4X1Ct/f1UT1Cvtq5csyprj/438WrmwZ8ffuTDljUQMhyBQRggAAAAAAgNMrHJNaVvpHOeM2dS+xT8lgt5QcyG7q/rp/lGOH/FkkuX1K8nuWdATPRZu6A/XIsvzN7Wf8F3+eK6VHs8dIwXmkRFnheVRyR6TUSLCs5PWIpnUGSzU5HFldnpElYzmSZctYjkzubDv+WQXldij42vLreIFnbRk58rL3jOWHLn49p+C+X9ez/Da9gnJPtjzLyT+Xu++XFdax/deB+n4o5Lc3Fvp4suVaoWxdS8Y4crPPu0X1PCsYII0FaI5MNgzzjC3XsuQZW8ayZIxkZCTjz/IyUrbMDzWNpPZmvr+mihAEAAAAAADMvElv6l5hn5KhXn9WSf8R/6ikoWX8/iTFy3FN86buQE1kUqXDh5LBRIWwInedKlHPTc7sZ3IiUrhBCi8oOBoKyhrGl0UmqBeKZX/77PqhjpfJXntVlrmS8bLnbHnZssI2qi0r816nUjZRPyuETpaMLJNhZbVTYTmS7YydC68Lz4n7JH2i1r2dkwhBAAAAAADA7FXVpu5pPwiptE/JQJe/T8nou/5RcVP3huDSW4GQJFvW2O7vowKcKmP8P5uBgGG4yrCiOLSoEFx4mZn9XOVCiEBoUSGsCIQWpcKKBsbgTDFmggBnqiFMto1SZePeK9fGVMsqvNeU+1RlmfEm+Pm6kutO/M8hM8MhYx3hbwoAAAAAADC3OWGp+Uz/KMcYafTE+GCkcJ+SgXf8gCQzKr37X/8oy5Ia2yrvUxLv8EMczF2eW+WsiOEqwopRKV2m3kyybCm8cHKzI6qebZFtKxRjNlU9saxs4BSSFK11b+YeYyqENZMIhlrfU+tPMmcRggAAAAAAgPpnWdKCFv+YzKbupTZ2H+zObure4x/6R/n2ovES+5QUhCTxDmnBEjZ1nyxj/BlAk13CqdJSTqXqzfjyTtFTmx1RzWwLJ0xAAcwkyxpb1go1QQgCAAAAAACQM6lN3SvsU5Lb1D13VNzUPSw1tZfYp6Rg75K5tKm7MZOcFTHBUk7lloYyVSwfczpVnB1RZlZErl5k4QRhBcs7AcB04W9WAAAAAACAySjc1L3jwvL1koPBkCS/BFd30abu6eo2dV/QWnmfkniHFFtU+f/yL7W8U8lZEaWCiUpLPs2C5Z1OZXZE2dkWBZtlM3sCAOYkQhAAAAAAAIDpEG2SljZJS99fvs64Td1L7FMy2O1vnD1y3D96XynfXm5T94aW7Gbbxcs7pU7/56yk0vJOkYVlQoriYGKCWRQs7wQAqIAQBAAAAAAAoFYmval7mX1KBrqCm7qr0qbuWRVnR1TY9HrCWRQF4QZr4AMAaowQBAAAAAAAYDarelP30bEZJImT/hJO4/aiYHknAMD8QggCAAAAAABQD8INUst7/AMAAEiS7Fp3AAAAAAAAAAAAYDoQggAAAAAAAAAAgLpECAIAAAAAAAAAAOoSIQgAAAAAAAAAAKhLhCAAAAAAAAAAAKAuEYIAAAAAAAAAAIC6RAgCAAAAAAAAAADqEiEIAAAAAAAAAACoS4QgAAAAAAAAAACgLhGCAAAAAAAAAACAukQIAgAAAAAAAAAA6hIhCAAAAAAAAAAAqEuEIAAAAAAAAAAAoC4RggAAAAAAAAAAgLpECAIAAAAAAAAAAOoSIQgAAAAAAAAAAKhLhCAAAAAAAAAAAKAuEYIAAAAAAAAAAIC6RAgCAAAAAAAAAADqEiEIAAAAAAAAAACoS4QgAAAAAAAAAACgLhGCAAAAAAAAAACAujSlEOSBBx7QOeeco1gspg0bNuiFF16oWP+JJ57Q6tWrFYvFdP755+uPf/zjlDoLAAAAAAAAAABQrUmHII8//ri2b9+uHTt26KWXXtLatWu1efNm9fX1laz/97//Xddff71uueUW/eMf/9CWLVu0ZcsWvfrqq6fceQAAAAAAAAAAgHIsY4yZzAMbNmzQRRddpB//+MeSJM/ztGLFCt122236xje+Ma7+ddddp+HhYT311FP5sksuuUQXXHCBHnzwwZLvkUwmlUwm868HBga0YsUK9ff3Kx6PT6a7AAAAAAAAAACgzgwMDKi5uXnC3GBSM0FSqZQOHTqkTZs2jTVg29q0aZMOHDhQ8pkDBw4E6kvS5s2by9aXpJ07d6q5uTl/rFixYjLdBAAAAAAAAAAAmFwIcuzYMbmuq7a2tkB5W1ubenp6Sj7T09MzqfqSdOedd6q/vz9/HDlyZDLdBAAAAAAAAAAAUKjWHSglGo0qGo3WuhsAAAAAAAAAAGAOm9RMkCVLlshxHPX29gbKe3t71d7eXvKZ9vb2SdUHAAAAAAAAAAA4HSYVgkQiEa1bt0779u3Ll3mep3379mnjxo0ln9m4cWOgviTt3bu3bH0AAAAAAAAAAIDTYdLLYW3fvl1bt27V+vXrdfHFF+u+++7T8PCwbrrpJknSjTfeqDPOOEM7d+6UJG3btk1XXHGF7r33Xl111VV67LHHdPDgQT300EOn95MAAAAAAAAAAAAUmHQIct111+no0aO666671NPTowsuuEB79uzJb35++PBh2fbYBJNLL71Ujz76qL71rW/pm9/8platWqUnn3xS55133un7FAAAAAAAAAAAAEUsY4ypdScmMjAwoObmZvX39ysej9e6OwAAAAAAAAAAoIaqzQ0mtScIAAAAAAAAAADAXEEIAgAAAAAAAAAA6hIhCAAAAAAAAAAAqEuEIAAAAAAAAAAAoC4RggAAAAAAAAAAgLpECAIAAAAAAAAAAOoSIQgAAAAAAAAAAKhLhCAAAAAAAAAAAKAuEYIAAAAAAAAAAIC6RAgCAAAAAAAAAADqEiEIAAAAAAAAAACoS4QgAAAAAAAAAACgLhGCAAAAAAAAAACAukQIAgAAAAAAAAAA6hIhCAAAAAAAAAAAqEuEIAAAAAAAAAAAoC4RggAAAAAAAAAAgLpECAIAAAAAAAAAAOoSIQgAAAAAAAAAAKhLhCAAAAAAAAAAAKAuEYIAAAAAAAAAAIC6RAgCAAAAAAAAAADqEiEIAAAAAAAAAACoS4QgAAAAAAAAAACgLhGCAAAAAAAAAACAukQIAgAAAAAAAAAA6hIhCAAAAAAAAAAAqEuEIAAAAAAAAAAAoC4RggAAAAAAAAAAgLpECAIAAAAAAAAAAOoSIQgAAAAAAAAAAKhLhCAAAAAAAAAAAKAuEYIAAAAAAAAAAIC6FKp1B6phjJEkDQwM1LgnAAAAAAAAAACg1nJ5QS4/KGdOhCCDg4OSpBUrVtS4JwAAAAAAAAAAYLYYHBxUc3Nz2fuWmSgmmQU8z1NXV5eamppkWVatuzMlAwMDWrFihY4cOaJ4PF7r7gBzCuMHmBrGDjA1jB1gahg7wNQxfoCpYewAU1MvY8cYo8HBQXV0dMi2y+/8MSdmgti2rTPPPLPW3Tgt4vH4nP6DBdQS4weYGsYOMDWMHWBqGDvA1DF+gKlh7ABTUw9jp9IMkBw2RgcAAAAAAAAAAHWJEAQAAAAAAAAAANQlQpAZEo1GtWPHDkWj0Vp3BZhzGD/A1DB2gKlh7ABTw9gBpo7xA0wNYweYmvk2dubExugAAAAAAAAAAACTxUwQAAAAAAAAAABQlwhBAAAAAAAAAABAXSIEAQAAAAAAAAAAdYkQBAAAAAAAAAAA1CVCEAAAAAAAAAAAUJcIQWbIAw88oHPOOUexWEwbNmzQCy+8UOsuAbPKX//6V1199dXq6OiQZVl68sknA/eNMbrrrru0fPlyNTQ0aNOmTXrjjTdq01lgFtm5c6cuuugiNTU1admyZdqyZYtef/31QJ1EIqHOzk61traqsbFR11xzjXp7e2vUY2B22LVrl9asWaN4PK54PK6NGzfq6aefzt9n3ADVueeee2RZlm6//fZ8GeMHKO073/mOLMsKHKtXr87fZ+wA5b3zzjv63Oc+p9bWVjU0NOj888/XwYMH8/f5nQEw3jnnnDPue8eyLHV2dkqaX987hCAz4PHHH9f27du1Y8cOvfTSS1q7dq02b96svr6+WncNmDWGh4e1du1aPfDAAyXvf//739f999+vBx98UM8//7wWLlyozZs3K5FIzHBPgdll//796uzs1HPPPae9e/cqnU7rU5/6lIaHh/N17rjjDv3hD3/QE088of3796urq0uf+cxnathroPbOPPNM3XPPPTp06JAOHjyoj3/84/r0pz+t1157TRLjBqjGiy++qJ/+9Kdas2ZNoJzxA5T3oQ99SN3d3fnjb3/7W/4eYwco7cSJE7rssssUDof19NNP65///KfuvfdeLV68OF+H3xkA47344ouB75y9e/dKkq699lpJ8+x7x2DaXXzxxaazszP/2nVd09HRYXbu3FnDXgGzlySze/fu/GvP80x7e7v5wQ9+kC87efKkiUaj5te//nUNegjMXn19fUaS2b9/vzHGHyvhcNg88cQT+Tr/+te/jCRz4MCBWnUTmJUWL15sfv7znzNugCoMDg6aVatWmb1795orrrjCbNu2zRjD9w5QyY4dO8zatWtL3mPsAOV9/etfN5dffnnZ+/zOAKjOtm3bzHvf+17jed68+95hJsg0S6VSOnTokDZt2pQvs21bmzZt0oEDB2rYM2DueOutt9TT0xMYR83NzdqwYQPjCCjS398vSWppaZEkHTp0SOl0OjB+Vq9erbPOOovxA2S5rqvHHntMw8PD2rhxI+MGqEJnZ6euuuqqwDiR+N4BJvLGG2+oo6ND73nPe3TDDTfo8OHDkhg7QCW///3vtX79el177bVatmyZLrzwQv3sZz/L3+d3BsDEUqmUfvWrX+nmm2+WZVnz7nuHEGSaHTt2TK7rqq2tLVDe1tamnp6eGvUKmFtyY4VxBFTmeZ5uv/12XXbZZTrvvPMk+eMnEolo0aJFgbqMH0B65ZVX1NjYqGg0qi996UvavXu3zj33XMYNMIHHHntML730knbu3DnuHuMHKG/Dhg165JFHtGfPHu3atUtvvfWWPvKRj2hwcJCxA1Tw3//+V7t27dKqVav0zDPP6Mtf/rK+8pWv6Je//KUkfmcAVOPJJ5/UyZMn9fnPf17S/Pt3tlCtOwAAAE6Pzs5Ovfrqq4G1pQGU94EPfEAvv/yy+vv79dvf/lZbt27V/v37a90tYFY7cuSItm3bpr179yoWi9W6O8CccuWVV+av16xZow0bNujss8/Wb37zGzU0NNSwZ8Ds5nme1q9fr7vvvluSdOGFF+rVV1/Vgw8+qK1bt9a4d8Dc8Itf/EJXXnmlOjo6at2VmmAmyDRbsmSJHMdRb29voLy3t1ft7e016hUwt+TGCuMIKO/WW2/VU089pT//+c8688wz8+Xt7e1KpVI6efJkoD7jB5AikYje9773ad26ddq5c6fWrl2rH/3oR4wboIJDhw6pr69PH/7whxUKhRQKhbR//37df//9CoVCamtrY/wAVVq0aJHe//7368033+S7B6hg+fLlOvfccwNlH/zgB/PLyfE7A6Cy//3vf3r22Wf1hS98IV823753CEGmWSQS0bp167Rv3758med52rdvnzZu3FjDngFzx8qVK9Xe3h4YRwMDA3r++ecZR5j3jDG69dZbtXv3bv3pT3/SypUrA/fXrVuncDgcGD+vv/66Dh8+zPgBiniep2QyybgBKvjEJz6hV155RS+//HL+WL9+vW644Yb8NeMHqM7Q0JD+85//aPny5Xz3ABVcdtllev311wNl//73v3X22WdL4ncGwEQefvhhLVu2TFdddVW+bL5977Ac1gzYvn27tm7dqvXr1+viiy/Wfffdp+HhYd1000217howawwNDenNN9/Mv37rrbf08ssvq6WlRWeddZZuv/12fe9739OqVau0cuVKffvb31ZHR4e2bNlSu04Ds0BnZ6ceffRR/e53v1NTU1N+7c7m5mY1NDSoublZt9xyi7Zv366WlhbF43Hddttt2rhxoy655JIa9x6onTvvvFNXXnmlzjrrLA0ODurRRx/VX/7yFz3zzDOMG6CCpqam/L5TOQsXLlRra2u+nPEDlPbVr35VV199tc4++2x1dXVpx44dchxH119/Pd89QAV33HGHLr30Ut1999367Gc/qxdeeEEPPfSQHnroIUmSZVn8zgAow/M8Pfzww9q6datCobEoYL597xCCzIDrrrtOR48e1V133aWenh5dcMEF2rNnz7gNm4D57ODBg/rYxz6Wf719+3ZJ0tatW/XII4/oa1/7moaHh/XFL35RJ0+e1OWXX649e/awFjXmvV27dkmSPvrRjwbKH3744fyGZz/84Q9l27auueYaJZNJbd68WT/5yU9muKfA7NLX16cbb7xR3d3dam5u1po1a/TMM8/ok5/8pCTGDXAqGD9AaW+//bauv/56HT9+XEuXLtXll1+u5557TkuXLpXE2AHKueiii7R7927deeed+u53v6uVK1fqvvvu0w033JCvw+8MgNKeffZZHT58WDfffPO4e/Ppe8cyxphadwIAAAAAAAAAAOB0Y08QAAAAAAAAAABQlwhBAAAAAAAAAABAXSIEAQAAAAAAAAAAdYkQBAAAAAAAAAAA1CVCEAAAAAAAAAAAUJcIQQAAAAAAAAAAQF0iBAEAAAAAAAAAAHWJEAQAAAAAAAAAANQlQhAAAAAAAAAAAFCXCEEAAAAAAAAAAEBdIgQBAAAAAAAAAAB16f8D27RlJvPNSEoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 2000x2000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7b0b74642170> (for post_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 433, in _pause_backend\n",
            "    if not self._require_nexus and self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 438, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "start_with_wandb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4UhC4DWeyaRX",
        "outputId": "1d0655b0-de70-4514-c2fc-3f33d144a733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7b0b74642170> (for post_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 433, in _pause_backend\n",
            "    if not self._require_nexus and self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 438, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BjI30ZSDxcbM",
        "outputId": "2a0a67b8-9728-45fc-a5b8-fb00abc7d40f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7b0b74642170> (for post_run_cell):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 433, in _pause_backend\n",
            "    if not self._require_nexus and self.notebook.save_ipynb():  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
            "    runner = Runner(ctx_run, result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\n",
            "    self.events.trigger('post_run_cell', result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/events.py\", line 89, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\", line 104, in adapted\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 438, in _pause_backend\n",
            "    logger.info(\"pausing backend\")  # type: ignore\n",
            "Message: 'pausing backend'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPiZp8EG5tqvcGRTe4oSpxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}