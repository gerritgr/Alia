{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/Alia/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCMM1H64tA7p"
      },
      "source": [
        "# AliaMolecule Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5NrAGm7to1n"
      },
      "source": [
        "#### Project Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "833DrsZU2o7r"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rCeS1g3btmT9"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"AliaMoleculeDesk4\"\n",
        "PATH_PATTERN = \"aliamolEllisDisc\" #aliamol2 is trained on denoised image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z7g6wEvtFrr"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9JUGxi3tEae",
        "outputId": "321606d5-fd6c-4fb5-fac5-146824dc38ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/AliaMoleculeDesk3\n"
          ]
        }
      ],
      "source": [
        "# Load drive\n",
        "\n",
        "import os\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  import wandb # need to do this before chaning cwd\n",
        "except:\n",
        "  os.system(\"pip install wandb\")\n",
        "\n",
        "\n",
        "if USE_COLAB:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W9oArycxtC6J"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "\n",
        "import os\n",
        "import torch\n",
        "torch_version = torch.__version__.split(\"+\")\n",
        "#os.environ[\"TORCH\"] = torch_version[0]\n",
        "#os.environ[\"CUDA\"] = torch_version[1]\n",
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  os.system(\"pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\")\n",
        "  os.system(\"pip install torch-geometric\")\n",
        "\n",
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  os.system(\"pip install rdkit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LU94GR6x1y-"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD1DOMjwx29q",
        "outputId": "67d5b382-d5b1-47de-aa88-9698682d2412"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
        "from PIL import Image # We use PIL to load images\n",
        "import seaborn as sns\n",
        "#import imageio # to generate .gifs\n",
        "import networkx as nx\n",
        "\n",
        "# always good to have\n",
        "import glob, random, os, traceback, time, copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Linear as Lin\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oscW9KW_NOTi"
      },
      "source": [
        "### Load External"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eCNRU4kbNQAJ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"smiles_to_pyg\"):\n",
        "  os.system(\"git clone https://github.com/gerritgr/Alia.git && cp -R Alia/* .\")\n",
        "from smiles_to_pyg.molecule_load_and_convert import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef33eK-2yBVa"
      },
      "source": [
        "#### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3INYZ1OeyDZs"
      },
      "outputs": [],
      "source": [
        "# Diffusion\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 128*2\n",
        "EPOCHS_DISC_MODEL = 70\n",
        "DISC_NOISE=0.3\n",
        "\n",
        "LEARNING_RATE_GEN = 0.001\n",
        "EPOCHS_GEN = 100\n",
        "\n",
        "# Mol Gen\n",
        "NUM_SAMPLES = 500 # how many samples to generate for the trainings set\n",
        "NUM_GRAPHS_TO_GENERATE = 10 # during inference\n",
        "TRAIN_TEST_SPLIT = 0.8\n",
        "\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5 # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False]*5 + [True] * 5\n",
        "NON_EDGES = [True] + [True]*5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUzkUbpyRAP"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V0-ubb5pwu84"
      },
      "outputs": [],
      "source": [
        "def log(d):\n",
        "  try:\n",
        "    import wandb\n",
        "    wandb.log(d)\n",
        "  except:\n",
        "    print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "isR2usjlQr0k"
      },
      "outputs": [],
      "source": [
        "def load_file(filepath):\n",
        "  print(\"try to read \", filepath)\n",
        "  try:\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {str(e)}\")\n",
        "      raise\n",
        "\n",
        "def write_file(filepath, data):\n",
        "  print(\"try to write \", filepath)\n",
        "  with gzip.open(filepath, 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1pb4cD9fMxkl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_dataset(seed=1234):\n",
        "  try:\n",
        "    dataset_train, dataset_test = load_file('dataset.pickle')\n",
        "    return dataset_train, dataset_test\n",
        "  except Exception as e:\n",
        "    print(f\"Could not load dataset due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  dataset = read_qm9()\n",
        "  dataset_all = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  dataset = list()\n",
        "  for g in tqdm(dataset_all):\n",
        "    try:\n",
        "      assert \"None\" not in str(pyg_to_smiles(g))\n",
        "      dataset.append(g)\n",
        "    except:\n",
        "      pass\n",
        "  print(\"Built and clean dataset, length is \", len(dataset), \"old length was\", len(dataset_all))\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset)*TRAIN_TEST_SPLIT + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0,:].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  write_file(\"dataset.pickle\", (dataset_train, dataset_test))\n",
        "  return dataset_train, dataset_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iVaAhhMoySLZ"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "  \"\"\"\n",
        "  Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "  Args:\n",
        "  start (float): The starting value for the beta values. Default is START.\n",
        "  end (float): The ending value for the beta values. Default is END.\n",
        "  timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "  cumulative alpha values (alpha bars).\n",
        "  \"\"\"\n",
        "  betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "  #alphas = 1.0 - betas\n",
        "  #alpha_bars = torch.cumprod(alphas, axis=0)\n",
        "  assert(betas.numel() == TIMESTEPS)\n",
        "  return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-1QHrqCDxdwY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "def visualize_smiles_from_file(filepath):\n",
        "    # Read SMILES from file\n",
        "    with open(filepath, 'r') as file:\n",
        "        smiles_list = [line.strip() for line in file.readlines()]\n",
        "\n",
        "    # Convert SMILES to RDKit Mol objects, filtering out invalid ones\n",
        "    mols = [Chem.MolFromSmiles(smile) for smile in smiles_list[:100]]\n",
        "    mols = [mol for mol in mols if mol is not None]\n",
        "\n",
        "    # Determine grid size\n",
        "    num_mols = len(mols)\n",
        "    cols = 10\n",
        "    rows = min(10, -(-num_mols // cols))  # ceil division\n",
        "\n",
        "    # Create a subplot grid\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(20, 20),\n",
        "                            gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            ax = axs[i, j]\n",
        "            ax.axis(\"off\")  # hide axis\n",
        "            idx = i * cols + j  # index in mols list\n",
        "            if idx < num_mols:\n",
        "                img = Draw.MolToImage(mols[idx], size=(200, 200))\n",
        "                ax.imshow(img)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(filepath + '.jpg', format='jpg', bbox_inches='tight')\n",
        "    plt.close(fig)  # Close the figure after saving to free up memory\n",
        "    try:\n",
        "        time.sleep(0.01)\n",
        "        wandb.log_artifact(filepath + '.jpg', name=f\"jpg_{SWEEP_ID}_{filepath.replace('.','')}\", type=\"smiles_grid_graph\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "\n",
        "# Example usage:\n",
        "# Replace YOUR_FILE_PATH with the path to your SMILES file.\n",
        "# visualize_smiles_from_file(YOUR_FILE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnya1MDuxseM"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O1FxjM0jyd1k"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  try:\n",
        "    deg = load_file('deg.pickle')\n",
        "    deg = deg.to(DEVICE)\n",
        "    return deg\n",
        "  except Exception as e:\n",
        "    print(f\"Could not find degree bin due to error: {str(e)}, generate it now\")\n",
        "  assert(train_dataset is not None)\n",
        "\n",
        "\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "\n",
        "  write_file(\"deg.pickle\", deg.cpu())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=32, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) #tod fix\n",
        "    #out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM+ TIME_FEATURE_DIM #INDICATOR_FEATURE_DIM entries are noise free\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "\n",
        "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    row_num = x_in.shape[0]\n",
        "    t = t.view(-1,TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "    assert(x.numel() > 1 )\n",
        "    assert(x.shape[0] == row_num)\n",
        "\n",
        "    #node_indicator = x_in[:,0] > 0\n",
        "    #node_indicator = x_in[:,0] < 0\n",
        "    #x[node_indicator, NON_NODES] = x_in[node_indicator, NON_NODES]\n",
        "    #x[edge_indicator, NON_EDGES] = x_in[edge_indicator, NON_EDGES]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#model = PNAnet([data])\n",
        "\n",
        "#model(data.x, data.edge_index, torch.ones(data.x.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bSm4qgdXRlo0"
      },
      "outputs": [],
      "source": [
        "#path_pattern = \"aliamol_model_epoch_*.pth\"\n",
        "#sorted(glob.glob(path_pattern))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CvkRRWDcrRqZ"
      },
      "outputs": [],
      "source": [
        "def load_latest_checkpoint(model, optimizer, loss_list, epoch_i, path_pattern=None):\n",
        "  if path_pattern is None:\n",
        "    path_pattern = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(path_pattern))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "    # Assuming model and optim are your initialized model and optimizer\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    loss_list = checkpoint['loss_list']\n",
        "    print(f\"read checkpoint of epoch {epoch_i:08} from disc.\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "def save_model(model, optimizer, loss_list, epoch_i, upload=False):\n",
        "  if epoch_i == 0:\n",
        "    return\n",
        "  save_path = f\"{PATH_PATTERN}_model_epoch_{epoch_i:08}.pth\"\n",
        "\n",
        "  # Save the model state dict and the optimizer state dict in a dictionary\n",
        "  torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'loss_list': loss_list,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, save_path)\n",
        "  if upload:\n",
        "    try:\n",
        "      wandb.log_artifact(save_path, name=f\"src_txt_{SWEEP_ID}_{epoch_i:08}_weightfile\", type=\"weight\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DDm63cFIrG8K"
      },
      "outputs": [],
      "source": [
        "def load_base_model(dataset_train, path_pattern=None):\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  loss_list = None\n",
        "  optimizer = Adam(model_base.parameters(), lr = 0.1)\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0, path_pattern=path_pattern)\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4NRBuWuxUDl"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aP3_DiRvGjKr"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step_wild(model, g, i):\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  #noise_pred = noise_pred.view(row_num, -1)\n",
        "  #x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  #assert(noise_pred.shape == x_with_noise.shape)\n",
        "  #future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  #original_pred = get_pred_from_noise(noise_pred, x_with_noise, future_t)\n",
        "\n",
        "  if t-1>0:\n",
        "    x_with_noise_again, _ = forward_diffusion(original_pred, t-1)\n",
        "    denoised_x[mask] = x_with_noise_again.flatten()\n",
        "  else:\n",
        "    denoised_x[mask] = original_pred.flatten()\n",
        "  return denoised_x\n",
        "\n",
        "\n",
        "\n",
        "  #x_in = g.x[mask].flatten()\n",
        "  #original_pred = get_pred_from_noise(noise_pred, x_in, future_t)\n",
        "  ##original_pred = (x_in - torch.sqrt(1. - alphas_cumprod_t) * noise_pred)/torch.sqrt(alphas_cumprod_t)\n",
        "  #assert(original_pred.shape[0] = x_in.shape[0])\n",
        "  #x = g.x.clone()\n",
        "  #x[mask] = original_pred\n",
        "  #if t-1 <= 0:\n",
        "  #  return x\n",
        "  #x_with_noise_again, _ = forward_diffusion(x, t-1)\n",
        "  #denoised_x[mask] = x_with_noise_again[mask]\n",
        "  #return denoised_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IbcU3sZBxqwh"
      },
      "outputs": [],
      "source": [
        "def denoise_one_step(model, g, i):\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1 # i=0 is full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1,1)\n",
        "\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  noise_pred = get_noise_from_pred(original_pred, x_with_noise, future_t)\n",
        "\n",
        "  values_now = g.x[mask].view(row_num, -1)\n",
        "  values_endpoint = noise_pred.view(row_num, -1)#[mask] network only prdicts noise\n",
        "\n",
        "  assert(values_now.shape == values_endpoint.shape)\n",
        "\n",
        "  # now compute values_one_step_denoised\n",
        "  model_mean = sqrt_recip_alphas_t * (values_now - beta_t * values_endpoint / sqrt_one_minus_alphas_cumprod_t)\n",
        "  values_one_step_denoised = model_mean # if t == 0\n",
        "  if t != 0:\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # in the paper this is in 3.2. note that sigma^2 is variance, not std\n",
        "    posterior_std_t = torch.sqrt(posterior_variance[t])\n",
        "    noise = torch.randn_like(values_now, device = DEVICE)\n",
        "    values_one_step_denoised = model_mean + posterior_std_t * noise\n",
        "\n",
        "  denoised_x = g.x.clone()\n",
        "  denoised_x[mask] = values_one_step_denoised.flatten()\n",
        "  return denoised_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SSHkoX_-xngv"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  g.x_old = g.x.clone()\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  g.x[mask] = torch.randn_like(g.x[mask])\n",
        "  return g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wbvUY6H2xaWb"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples(model, dataset_train, num=100,wild=False):\n",
        "  # Setup\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  dataset_train_start = list()\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "    g = dataset_train_start[-1]\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size = num)\n",
        "\n",
        "  # Inference\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    g = overwrite_with_noise(g)\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS-i-1)\n",
        "      if wild:\n",
        "        x_with_less_noise = denoise_one_step_wild(model, g, i)\n",
        "      else:\n",
        "        x_with_less_noise = denoise_one_step(model, g, i)\n",
        "      g.x = x_with_less_noise\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    graph_list = [g.cpu() for g in graph_list]\n",
        "\n",
        "    print(\"generated graphs \", graph_list[:10])\n",
        "    return graph_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9AAQNu54u5f"
      },
      "source": [
        "#### Frac Correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Na5iiitt4w63"
      },
      "outputs": [],
      "source": [
        "def find_frac_correct(graphs):\n",
        "  correct = 0\n",
        "  smiles_list = list()\n",
        "  for i, g in tqdm(list(enumerate(graphs))):\n",
        "    smiles = pyg_to_smiles(g)\n",
        "    if smiles is not None and '.' not in smiles:\n",
        "      mol = Chem.MolFromSmiles(smiles)\n",
        "      if mol is not None:\n",
        "        correct += 1\n",
        "        smiles_list.append((smiles, i))\n",
        "\n",
        "  frac_correct = correct/len(graphs)\n",
        "  return frac_correct, smiles_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8BWfguzgy5"
      },
      "source": [
        "### Gen many graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q2mkhyZ2xMbc"
      },
      "outputs": [],
      "source": [
        "#!ls aliamol2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SeHCO82gziKT"
      },
      "outputs": [],
      "source": [
        "def gen_graphs(num_per_generation=1000, num_generations=20, wild=False, path_pattern=None):\n",
        "  if path_pattern is None:\n",
        "    path_pattern = PATH_PATTERN+\"_model_epoch_*.pth\" #\"aliamol_model_epoch_*.pth\"\n",
        "  path = sorted(glob.glob(path_pattern))[-1]\n",
        "  num_samples = num_per_generation*num_generations\n",
        "  filepath = path.replace(\".pth\", f'_{num_samples:06d}_w{wild}_generated.pickle')\n",
        "\n",
        "  results = list()\n",
        "  try:\n",
        "    results = load_file(filepath)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  if len(results) == num_per_generation*num_generations:\n",
        "    return results\n",
        "\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  scatter_list = list()\n",
        "  model_base = load_base_model(dataset_base, path_pattern = path)\n",
        "\n",
        "  i = 0\n",
        "  while len(results) < num_samples:\n",
        "    i += 1\n",
        "    num = max(num_per_generation, len(results) - num_samples)\n",
        "    graphs = generate_examples(model_base, dataset_base, num=num, wild=wild)\n",
        "    results = results + graphs\n",
        "    if i % 5 == 0 or len(results) >= num_samples:\n",
        "      write_file(filepath, results)\n",
        "\n",
        "  assert(len(results) == num_per_generation*num_generations)\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "def test_graph_generation(path_pattern=None, wild=False):\n",
        "  generated_graphs = gen_graphs(wild=wild, path_pattern=path_pattern)\n",
        "  return find_frac_correct(generated_graphs) #0.54 #0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X0p9ss6BJ_UM"
      },
      "outputs": [],
      "source": [
        "#test_graph_generation(path_pattern=\"aliamol_model_epoch_00003901.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dJOf1G5O0K"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wEo07bzN4bAP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lfJgXwe15QG4"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=8, depth=4, dropout=0.05, towers=1, normalization=True, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM\n",
        "    assert in_channels == 11\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "    deg = deg.to(DEVICE)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=1, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
        "    #self.pnanet = PNA(in_channels=11, hidden_channels=hidden_channels, out_channels=1, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "    #self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(),Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, batch=None):\n",
        "    #print(\"before: x.shape\",x.shape, \"edge_index.shape\",edge_index.shape)\n",
        "    x = x + torch.randn_like(x)*DISC_NOISE\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    #print(\"after: x.shape\",x.shape, \"edge_index.shape\",edge_index.shape)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    #x = torch.sum(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "91xp2SGvGTSU"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer):\n",
        "  model_disc.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    #print(\"batch.x, batch.edge_index, batch.batch\", batch, batch.x, batch.edge_index, batch.batch)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    #print(\"pred \",pred, \"y \", batch.y)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1ZcRLtjSKIfA"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader):\n",
        "  model_disc.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kaC-s2FMJkPq"
      },
      "outputs": [],
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc)\n",
        "  model_disc = model_disc.to(DEVICE)\n",
        "  weight_path = f\"discriminator_model_{round_i:05}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:05}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = list()\n",
        "  losses_train = list()\n",
        "  losses_test = list()\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr = 0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 1 or epoch_i == EPOCHS_DISC_MODEL-1:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      #print(loss_train,loss_test,acc_train,acc_test,t_train)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:02.4f}, loss test: {loss_test:02.4f}, acc: {acc_train:01.3f}, acc test: {acc_test:01.3f}, time: {t_train:01.3f}\")\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "      plt.clf()\n",
        "      plt.plot(epochs, losses_train, label='train')\n",
        "      plt.plot(epochs, losses_test, label='test')\n",
        "      plt.legend()\n",
        "      plt.savefig(f\"discriminator_model_{round_i:05}.png\")\n",
        "\n",
        "  torch.save({'model_state_dict': model_disc.state_dict(), 'epochs': epochs, \"losses_train\": losses_train, \"losses_test\": losses_test}, weight_path)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RH85qTaDKkF7"
      },
      "outputs": [],
      "source": [
        "def run_disc(round_i=1):\n",
        "  fake_graphs = gen_graphs(wild=True)\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  real_graphs = random.sample(dataset_base, len(fake_graphs))\n",
        "  dataset = list()\n",
        "\n",
        "  for g in fake_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(0.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  for g in real_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(1.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  random.shuffle(dataset)\n",
        "  cut_off = int(len(dataset) * 0.8)\n",
        "  dataloader_train = DataLoader(dataset[:cut_off], batch_size = BATCH_SIZE, shuffle=True)\n",
        "  dataloader_test = DataLoader(dataset[cut_off:], batch_size = BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  model_disc = train_disc_model(dataloader_train, dataloader_test, round_i)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hLHpXu-W6GbJ"
      },
      "outputs": [],
      "source": [
        "#model_disc = run_disc() #0000390 is the last good one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF7pU0QnPQMb"
      },
      "source": [
        "# Forward Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQ5kwb5PTkC",
        "outputId": "25a2b86a-dd8f-44f4-fa1a-928f94a76a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([[ 1.0117],\n",
              "          [ 1.9837],\n",
              "          [-2.7044]], device='cuda:0'),\n",
              "  tensor([[ 1.1752],\n",
              "          [-1.6218],\n",
              "          [-2.7726]], device='cuda:0')),\n",
              " None,\n",
              " (tensor([[-0.4461],\n",
              "          [ 1.1887],\n",
              "          [-0.1109]], device='cuda:0'),\n",
              "  tensor([[-0.4688],\n",
              "          [ 1.1439],\n",
              "          [-0.1784]], device='cuda:0')))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "\n",
        "  if \"class 'int'\" in str(type(future_t)) or \"class 'float'\" in str(type(future_t)):\n",
        "    future_t = torch.tensor([int(future_t)] * row_num).to(DEVICE)\n",
        "\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "  assert(future_t[0] == future_t[1]) #lets assume the belong to the same graph\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # column-wise multiplication, now matrix #todo but we want row wise #.view(row_num,1)\n",
        "  assert(new_node_features_mean.shape == node_features.shape)\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) #this is a col vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) #this is a matrix\n",
        "  assert(new_node_features_mean.shape == new_node_features_std.shape)\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihPbotsmRafu"
      },
      "source": [
        "# Train Jointly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zG8AOy2CfG8F"
      },
      "outputs": [],
      "source": [
        "def get_pred_from_noise(noise_pred, x_with_noise, future_t):\n",
        "\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(1.0-alphabar_t)\n",
        "  x_without_noise = x_with_noise - scaled_noise*noise_pred\n",
        "  x_without_noise = x_without_noise/torch.sqrt(alphabar_t)\n",
        "  return x_without_noise\n",
        "\n",
        "\n",
        "def get_noise_from_pred(original_pred, x_with_noise, future_t):\n",
        "\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(alphabar_t)\n",
        "  noise = x_with_noise - scaled_noise*original_pred\n",
        "  noise = noise / torch.sqrt(1.0-alphabar_t)\n",
        "\n",
        "  return noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MBBNjxFxRZef"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, model_disc=None):\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  loss_list_start = list()\n",
        "  loss_row = nn.MSELoss(reduction='none')\n",
        "\n",
        "  for batch in tqdm(dataloader): #todo batches deactivated\n",
        "    if batch.x.shape[0] < 2:\n",
        "      continue\n",
        "    optimizer.zero_grad()\n",
        "    batch.to(DEVICE)\n",
        "    row_num = batch.x.shape[0]\n",
        "\n",
        "    num_graphs_in_batch = int(torch.max(batch.batch).item()+1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device = DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, batch.batch)\n",
        "    assert(future_t.numel() == row_num)\n",
        "\n",
        "    mask = torch.concat((torch.tensor([False]*row_num, device=DEVICE).view(-1,1), batch.x[:,1:]>-0.5), dim=1) #this only works on original values\n",
        "    x_start_gt = batch.x[mask].view(row_num, FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x_start_gt, future_t)\n",
        "\n",
        "    x_in = batch.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    x_start_pred = model(x_in, future_t, batch.edge_index)\n",
        "    loss = F.mse_loss(x_start_gt, x_start_pred)\n",
        "\n",
        "\n",
        "    #row_num = x_in.shape[0]\n",
        "    #assert(x_with_noise.shape[0] == row_num)\n",
        "   # assert(noise_pred.shape[0] == row_num)\n",
        "    #assert(noise_pred.shape == x_with_noise.shape)\n",
        "    #assert(noise_pred.shape == noise_gt.shape)\n",
        "    #assert(noise_pred.shape == x_start_gt.shape)\n",
        "    #x_start_pred = get_pred_from_noise(noise_pred, x_with_noise, future_t)\n",
        "\n",
        "    #assert(F.mse_loss(get_pred_from_noise(noise_gt, x_with_noise, future_t), x_start_gt) < 0.00001)\n",
        "\n",
        "    #loss = F.mse_loss(noise_gt, noise_pred)\n",
        "    #loss_start = F.mse_loss(x_start_gt, x_start_pred)  #multiply with torch.sqrt(1.0-alphabar_t)  #F.mse_loss(x_start_gt, x_start_pred)  # torch.sum(F.mse_loss(x_start_gt, x_start_pred, dim=1)/future_t) #torch.sum(torch.sum((x_start_gt- x_start_pred)**2,dim=1) / (1+future_t.view(-1,1)))\n",
        "    #loss_agg = loss + 0.5*loss_start\n",
        "\n",
        "    #x_in = batch.x.clone()\n",
        "    #x_in[mask] = x_start_pred.flatten()\n",
        "    #disc_loss = torch.abs(1.0- model_disc(x_in, batch.edge_index, batch=batch.batch))\n",
        "    #disc_loss = torch.mean(disc_loss)\n",
        "    #loss_agg = loss + 0.25*disc_loss\n",
        "\n",
        "    disc_loss = torch.tensor(0.0, device=DEVICE)\n",
        "    if model_disc is not None:\n",
        "      x_in[mask] = x_start_pred.flatten()\n",
        "      disc_loss = torch.mean((1.0- model_disc(x_in, batch.edge_index, batch=batch.batch))**2)\n",
        "      loss += 0.1*disc_loss\n",
        "\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    loss_list_start.append(disc_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  return np.mean(loss_list),np.mean(loss_list_start), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "47jE9PU9bVBC"
      },
      "outputs": [],
      "source": [
        "def log_smiles(smiles, filename):\n",
        "  try:\n",
        "    with open(filename, \"w\") as file:\n",
        "      for string in smiles:\n",
        "        file.write(str(string) + \"\\n\")\n",
        "    wandb.log_artifact(filename, name=f\"src_txt_{SWEEP_ID}_{filename}\", type=\"smiles\")\n",
        "    time.sleep(0.01)\n",
        "    visualize_smiles_from_file(filename)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kQU6xUvvRf6t"
      },
      "outputs": [],
      "source": [
        "def train_base_model(train_loader, epoch_num=EPOCHS_GEN, model_disc=None):\n",
        "  print(\"train base model\")\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE_GEN*0.01) #ok makes no sense\n",
        "  loss_list = list()\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0)\n",
        "\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "  print(\"from\", epoch_start, \"to\", epoch_num)\n",
        "\n",
        "\n",
        "  for epoch_i in range(epoch_start,epoch_num):\n",
        "    try:\n",
        "      loss, loss_start, time_elapsed = train_epoch(model_base, train_loader, optimizer, model_disc=model_disc)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      if epoch_i % 1 == 0 or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #plot_list(loss_list, \"train_base.png\", title=\"train loss base model\", xlabel='epoch', ylabel='loss')\n",
        "        mean_loss = np.mean([y for x,y in loss_list] + [loss])\n",
        "        print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {mean_loss:05.4f} with start loss {loss_start:05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "        log({\"epoch\": epoch_i, \"loss\": loss, \"mean_loss\": mean_loss, \"start_loss\": loss_start, \"runtime\": time_elapsed})\n",
        "\n",
        "      if (epoch_i % 20 == 0 and epoch_i > 0) or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        #graphs = generate_examples(model_base, epoch_i, betas, dataset_train)\n",
        "        #graph_loss_list.append(compute_generation_loss(graphs, None))\n",
        "        #print(f\"generation loss: {graph_loss_list[-1]:06.4f}\")\n",
        "        #plot_base(graph_loss_list, loss_list)\n",
        "        #pass\n",
        "        print(\"save\")\n",
        "        save_model(model_base, optimizer, loss_list, epoch_i+1, upload=epoch_i % 100 == 0 and epoch_i>9) #todo really +1?\n",
        "        time.sleep(0.1)\n",
        "        frac, smiles_list = test_graph_generation(wild=False)\n",
        "        frac_wild, smiles_list_wild = test_graph_generation(wild=True)\n",
        "        print(\"frac correct graphs: \", frac, \"with wild inference\", frac_wild)\n",
        "        log({\"epoch\": epoch_i, \"frac_normal\": frac, \"frac_wild\": frac_wild})\n",
        "        log_smiles(smiles_list, f\"smiles_{epoch_i}_normal.txt\")\n",
        "        log_smiles(smiles_list_wild, f\"smiles_{epoch_i}_wild.txt\")\n",
        "        try:\n",
        "          print(smiles_list[:20])\n",
        "          print(smiles_list_wild[:20])\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          pass\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred during training: \\n\", str(e))\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OBLiBcZLRokF"
      },
      "outputs": [],
      "source": [
        "def start_experiments():\n",
        "  global DISC_NOISE\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 101)\n",
        "\n",
        "  DISC_NOISE = 0.3\n",
        "  model_disc = run_disc(round_i=1)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 201, model_disc=model_disc)\n",
        "\n",
        "  DISC_NOISE = 0.2\n",
        "  model_disc = run_disc(round_i=2)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 301, model_disc=model_disc)\n",
        "\n",
        "  DISC_NOISE = 0.1\n",
        "  model_disc = run_disc(round_i=3)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = 501, model_disc=model_disc)\n",
        "\n",
        "  save_src_file() # do it again\n",
        "  return  model_base\n",
        "\n",
        "\n",
        "#0000390 is the last good one\n",
        "\n",
        "#model_base = start_experiments()# loss in epoch 0000410 is: 0.0486 with mean loss 0.0643 with start loss 1.6791 with runtime 18.3035"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SFXyZBfWMfxo"
      },
      "outputs": [],
      "source": [
        "#!rm aliamol_model_epoch_00004001_010000_generated.pickle aliamol_model_epoch_00004001.pth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpKbb3ArSqg0"
      },
      "source": [
        "### With WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "719HFLnH3Eqm",
        "outputId": "ea271bea-16b9-4300-9048-b17e14a90f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/usr/local/lib/python3.10/dist-packages/wandb']\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "print(wandb.__path__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WF6EmzdCYJSZ"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"AliaMol\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"ENZYMES/besttest_acc\",\n",
        "        \"goal\": \"maximize\",\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"BATCH_SIZE\": {\"values\": [128*2]},\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TkqiydqAtMx7"
      },
      "outputs": [],
      "source": [
        "def save_src_file():\n",
        "  os.system(\"pip list > pip_list.txt 2>&1\")\n",
        "  for txt_file in sorted(glob.glob('*.txt')):\n",
        "    z = \"\".join(filter(str.isalnum, txt_file))\n",
        "    wandb.log_artifact(txt_file, name=f\"src_txt_{SWEEP_ID}_{z}\", type=\"my_dataset_txt\")\n",
        "  for python_file in sorted(glob.glob('*.ipynb')):\n",
        "    z = \"\".join(filter(str.isalnum, python_file))\n",
        "    wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}_{z}\", type=\"my_dataset_ipynb\")\n",
        "  for python_file in sorted(glob.glob('*.py')):\n",
        "    z = \"\".join(filter(str.isalnum, python_file))\n",
        "    wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}_{z}\", type=\"my_dataset_py\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fgG12j-1yQ3X"
      },
      "outputs": [],
      "source": [
        "#! cp ../Insa/api_key.txt api_key.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UoYB0l4fwBUT"
      },
      "outputs": [],
      "source": [
        "#os.system('wandb login --relogin --host=https://api.wandb.ai --key='+get_wand_api_key())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DJDIzKzmtQUJ"
      },
      "outputs": [],
      "source": [
        "def get_wand_api_key():\n",
        "  import sys\n",
        "  IN_COLAB = 'google.colab' in sys.modules\n",
        "  if not IN_COLAB:\n",
        "    os.system(\"cp ~/api_key.txt api_key.txt\")\n",
        "  file_path = 'api_key.txt'\n",
        "  with open(file_path, 'r') as file:\n",
        "      api_key = file.read().strip()\n",
        "  return api_key\n",
        "\n",
        "#wandb.login(key=get_wand_api_key())\n",
        "\n",
        "def main():\n",
        "  with wandb.init() as run:\n",
        "    save_src_file()\n",
        "    for hyper_param_name in sweep_config['parameters']:\n",
        "      globals()[hyper_param_name] = run.config[hyper_param_name]\n",
        "      print(\"set \", hyper_param_name, \"=\", run.config[hyper_param_name])\n",
        "    return start_experiments()\n",
        "\n",
        "def start_with_wandb():\n",
        "  import wandb\n",
        "  global SWEEP_ID, USE_WANDB\n",
        "  USE_WANDB = True\n",
        "  os.environ[\"WANDB_MODE\"] = \"online\"\n",
        "  try:\n",
        "    SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "    wandb.agent(SWEEP_ID, function=main, count=1)\n",
        "  except Exception as e:\n",
        "    error_message = traceback.format_exc()\n",
        "    print(\"final error:\\n\", error_message)\n",
        "    with open('_error_log.txt', 'a') as f:\n",
        "      f.write(error_message + '\\n')\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cxnsmGC7yLGX",
        "outputId": "d741f797-69d5-4b9f-e52e-324ac0a07c36"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 62doxxa7\n",
            "Sweep URL: https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lvob1skl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH_SIZE: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgerritgr\u001b[0m (\u001b[33mnextaid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/colab/AliaMoleculeDesk3/wandb/run-20231012_111528-lvob1skl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/runs/lvob1skl' target=\"_blank\">winter-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3/sweeps/62doxxa7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nextaid/AliaMoleculeDesk3/runs/lvob1skl' target=\"_blank\">https://wandb.ai/nextaid/AliaMoleculeDesk3/runs/lvob1skl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set  BATCH_SIZE = 256\n",
            "try to read  dataset.pickle\n",
            "train base model\n",
            "try to read  deg.pickle\n",
            "from 0 to 101\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/419 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "100%|██████████| 419/419 [00:16<00:00, 25.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000000 is: 0.1623 with mean loss 0.1623 with start loss 0.0000 with runtime 16.5761\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000001 is: 0.1151 with mean loss 0.1309 with start loss 0.0000 with runtime 13.4754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000002 is: 0.0881 with mean loss 0.1134 with start loss 0.0000 with runtime 13.5445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.82it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000003 is: 0.0852 with mean loss 0.1072 with start loss 0.0000 with runtime 13.6023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000004 is: 0.0787 with mean loss 0.1013 with start loss 0.0000 with runtime 13.5078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000005 is: 0.0739 with mean loss 0.0967 with start loss 0.0000 with runtime 13.4978\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000006 is: 0.0727 with mean loss 0.0936 with start loss 0.0000 with runtime 13.4566\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000007 is: 0.0722 with mean loss 0.0912 with start loss 0.0000 with runtime 13.5055\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000008 is: 0.0717 with mean loss 0.0892 with start loss 0.0000 with runtime 13.5534\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000009 is: 0.0713 with mean loss 0.0875 with start loss 0.0000 with runtime 13.5754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000010 is: 0.0710 with mean loss 0.0861 with start loss 0.0000 with runtime 13.5277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000011 is: 0.0705 with mean loss 0.0849 with start loss 0.0000 with runtime 13.5506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000012 is: 0.0701 with mean loss 0.0838 with start loss 0.0000 with runtime 13.5365\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000013 is: 0.0696 with mean loss 0.0828 with start loss 0.0000 with runtime 13.5688\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000014 is: 0.0696 with mean loss 0.0820 with start loss 0.0000 with runtime 13.5718\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000015 is: 0.0694 with mean loss 0.0812 with start loss 0.0000 with runtime 13.5961\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000016 is: 0.0693 with mean loss 0.0806 with start loss 0.0000 with runtime 13.5788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000017 is: 0.0692 with mean loss 0.0799 with start loss 0.0000 with runtime 13.5518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000018 is: 0.0690 with mean loss 0.0794 with start loss 0.0000 with runtime 13.5642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000019 is: 0.0691 with mean loss 0.0789 with start loss 0.0000 with runtime 13.5644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss in epoch 0000020 is: 0.0688 with mean loss 0.0784 with start loss 0.0000 with runtime 13.6081\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000021 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68440], x=[21495, 11], batch=[21495], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68936], x=[21635, 11], batch=[21635], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21602, 11], batch=[21602], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68920], x=[21630, 11], batch=[21630], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.58it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68556], x=[21528, 11], batch=[21528], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68588], x=[21534, 11], batch=[21534], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 40], x=[15, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69252], x=[21725, 11], batch=[21725], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68372], x=[21475, 11], batch=[21475], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69336], x=[21748, 11], batch=[21748], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68508], x=[21512, 11], batch=[21512], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68100], x=[21400, 11], batch=[21400], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68688], x=[21565, 11], batch=[21565], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69128], x=[21691, 11], batch=[21691], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69272], x=[21731, 11], batch=[21731], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21526, 11], batch=[21526], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68984], x=[21647, 11], batch=[21647], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69252], x=[21723, 11], batch=[21723], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68916], x=[21630, 11], batch=[21630], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68816], x=[21600, 11], batch=[21600], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69228], x=[21718, 11], batch=[21718], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 256.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000021 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68888], x=[21623, 11], batch=[21623], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67984], x=[21365, 11], batch=[21365], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69068], x=[21673, 11], batch=[21673], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69100], x=[21681, 11], batch=[21681], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68968], x=[21645, 11], batch=[21645], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68500], x=[21512, 11], batch=[21512], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68832], x=[21606, 11], batch=[21606], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68952], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68396], x=[21482, 11], batch=[21482], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68476], x=[21506, 11], batch=[21506], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69012], x=[21657, 11], batch=[21657], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68628], x=[21547, 11], batch=[21547], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68352], x=[21468, 11], batch=[21468], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68404], x=[21485, 11], batch=[21485], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69084], x=[21677, 11], batch=[21677], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69028], x=[21661, 11], batch=[21661], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68884], x=[21622, 11], batch=[21622], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68972], x=[21645, 11], batch=[21645], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68388], x=[21480, 11], batch=[21480], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000021_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 260.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frac correct graphs:  0.2497 with wild inference 0.0954\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CC1OCC2(O)CC1C2', 2), ('CCCCCC(O)CC', 6), ('CCC(O)(O)C1C2CC21', 10), ('CC1C2C34CC3C(O)C124', 13), ('CCC1(O)OC1C(C)O', 16), ('CCCC(CC)COC', 20), ('COCC(O)C(O)OC', 30), ('OC1(O)C2C3CC21CO3', 32), ('CCC(O)OCOCO', 38), ('CCC1(O)C(C)OC1O', 42), ('CCCCC(O)OC', 46), ('CCC1(C2CC2)CC1C', 47), ('OC1OC23CC2CC13', 48), ('CC12CCCC1CC2', 49), ('COCC12CC3(O)C1C32', 53), ('OC12CCCC13CC23O', 54), ('CCC1(CC)CC(C)C1', 55), ('C1C2OC3C4CC13CC24', 61), ('CCC12C(C)C1C1CC12', 67), ('CCCC1CC2CC12', 73)]\n",
            "[('CCC(O)CC1(C)CC1', 17), ('CCC12CC1CCC2C', 30), ('CCC(C)C1C(C)C1C', 37), ('CCCCCOC(C)O', 46), ('CCC(C)(C)CC(C)O', 58), ('CCC1CC(C)C1CC', 83), ('CC1C2CCCC1CC2', 85), ('CCC(CCO)C(C)O', 87), ('CC1CCC(C)C2CC12', 91), ('CCC(CC)CC(C)C', 93), ('CCCCC(O)CC', 95), ('CCCC(C)CC(C)C', 101), ('OC1CCCCC(O)C1', 109), ('CC12CCCC1CC2O', 125), ('CC1(C)CC(O)C1CO', 128), ('CCCC1CCC(C)C1', 136), ('CCC(C)C(C)CCO', 152), ('CC1CC2(CO)C(O)C12', 162), ('CCCCC1CCC1O', 164), ('CCC1CC1(CC)CC', 171)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000021 is: 0.0689 with mean loss 0.0780 with start loss 0.0000 with runtime 13.5968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000022 is: 0.0687 with mean loss 0.0776 with start loss 0.0000 with runtime 13.5172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000023 is: 0.0686 with mean loss 0.0773 with start loss 0.0000 with runtime 13.5575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000024 is: 0.0685 with mean loss 0.0769 with start loss 0.0000 with runtime 13.5544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000025 is: 0.0684 with mean loss 0.0766 with start loss 0.0000 with runtime 13.5457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000026 is: 0.0682 with mean loss 0.0763 with start loss 0.0000 with runtime 13.5182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000027 is: 0.0681 with mean loss 0.0760 with start loss 0.0000 with runtime 13.4957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000028 is: 0.0680 with mean loss 0.0757 with start loss 0.0000 with runtime 13.4508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000029 is: 0.0677 with mean loss 0.0755 with start loss 0.0000 with runtime 13.5319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000030 is: 0.0676 with mean loss 0.0752 with start loss 0.0000 with runtime 13.5656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000031 is: 0.0674 with mean loss 0.0750 with start loss 0.0000 with runtime 13.4816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000032 is: 0.0674 with mean loss 0.0748 with start loss 0.0000 with runtime 13.5326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000033 is: 0.0673 with mean loss 0.0745 with start loss 0.0000 with runtime 13.4853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000034 is: 0.0673 with mean loss 0.0743 with start loss 0.0000 with runtime 13.7100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000035 is: 0.0672 with mean loss 0.0741 with start loss 0.0000 with runtime 13.4806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000036 is: 0.0671 with mean loss 0.0740 with start loss 0.0000 with runtime 13.5521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000037 is: 0.0671 with mean loss 0.0738 with start loss 0.0000 with runtime 13.4700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000038 is: 0.0669 with mean loss 0.0736 with start loss 0.0000 with runtime 13.5427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000039 is: 0.0670 with mean loss 0.0734 with start loss 0.0000 with runtime 13.5675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000040 is: 0.0669 with mean loss 0.0733 with start loss 0.0000 with runtime 13.6104\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000041 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21604, 11], batch=[21604], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68780], x=[21590, 11], batch=[21590], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68664], x=[21558, 11], batch=[21558], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69400], x=[21767, 11], batch=[21767], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68552], x=[21527, 11], batch=[21527], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69140], x=[21693, 11], batch=[21693], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68280], x=[21449, 11], batch=[21449], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69188], x=[21706, 11], batch=[21706], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69288], x=[21735, 11], batch=[21735], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68660], x=[21558, 11], batch=[21558], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69016], x=[21658, 11], batch=[21658], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68920], x=[21630, 11], batch=[21630], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68364], x=[21473, 11], batch=[21473], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68780], x=[21591, 11], batch=[21591], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68672], x=[21561, 11], batch=[21561], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68964], x=[21644, 11], batch=[21644], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68732], x=[21579, 11], batch=[21579], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69232], x=[21719, 11], batch=[21719], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67948], x=[21357, 11], batch=[21357], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69292], x=[21736, 11], batch=[21736], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 259.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000041 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69320], x=[21744, 11], batch=[21744], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68840], x=[21608, 11], batch=[21608], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69464], x=[21785, 11], batch=[21785], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69480], x=[21790, 11], batch=[21790], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68708], x=[21572, 11], batch=[21572], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67880], x=[21334, 11], batch=[21334], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 24], x=[10, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69020], x=[21659, 11], batch=[21659], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68832], x=[21607, 11], batch=[21607], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68956], x=[21641, 11], batch=[21641], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21525, 11], batch=[21525], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68820], x=[21602, 11], batch=[21602], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69576], x=[21817, 11], batch=[21817], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68984], x=[21650, 11], batch=[21650], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69080], x=[21676, 11], batch=[21676], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68424], x=[21492, 11], batch=[21492], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69204], x=[21712, 11], batch=[21712], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 67864], x=[21333, 11], batch=[21333], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68928], x=[21633, 11], batch=[21633], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69092], x=[21677, 11], batch=[21677], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68688], x=[21565, 11], batch=[21565], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000041_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:37<00:00, 263.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frac correct graphs:  0.2467 with wild inference 0.0681\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CCC1CC2CC2(O)C1', 5), ('OCCCC(O)N1CC1', 12), ('O=CC(CO)C1CC1O', 15), ('CC(CCC=O)C1CN1', 16), ('C1CC23CCC24CC4N13', 17), ('C1CC23C4C1OCN2C43', 21), ('CNC(N)COCCN', 22), ('O=C1CCCNCCN1', 24), ('C1C2C3C4NC5(CC135)C24', 28), ('OC1CC2C1C1CC21O', 36), ('N=CNC1CN=C(N)C1', 41), ('CC(C)C(CN)C(C)N', 46), ('C1C2CC3CC3NC1N2', 49), ('CC12CNC1CC2CO', 52), ('CNC(=N)N(C)C=O', 57), ('O=C1CC12C1CONC12', 62), ('COC(CN)OCN', 63), ('CC1CCC(C)(N)C1O', 64), ('CCCN(CN)CCC', 66), ('CCOC12CC1CC2C', 67)]\n",
            "[('NCCC(CN)NCN', 0), ('NCCC(N)C(N)CN', 5), ('O=C1CC1CCCCO', 28), ('CCCCCC(N)CN', 45), ('NCCCC(N)NCN', 50), ('CC(C(=O)O)C(N)CO', 66), ('OCC1CCCOCO1', 74), ('NCNCCC(O)CN', 83), ('CC(C)CCC(C)CO', 127), ('CCCC(O)NCCN', 153), ('NCC(N)CCCCO', 164), ('NCC(N)C12CC1C2N', 216), ('NCNCCCCCO', 248), ('NC(N)NCNC(N)N', 267), ('CCCCNCC(C)C', 279), ('CCCCNC1NC1N', 295), ('CCNC(N)C(N)CN', 303), ('NCCCC1NC1(N)N', 304), ('CC1NC(N)C(N)C1N', 340), ('CCCCC(C)CCC', 341)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000041 is: 0.0668 with mean loss 0.0731 with start loss 0.0000 with runtime 13.6314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000042 is: 0.0669 with mean loss 0.0730 with start loss 0.0000 with runtime 13.5165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000043 is: 0.0667 with mean loss 0.0728 with start loss 0.0000 with runtime 13.4981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000044 is: 0.0666 with mean loss 0.0727 with start loss 0.0000 with runtime 13.5666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000045 is: 0.0666 with mean loss 0.0726 with start loss 0.0000 with runtime 13.4841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000046 is: 0.0666 with mean loss 0.0725 with start loss 0.0000 with runtime 13.4414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000047 is: 0.0665 with mean loss 0.0723 with start loss 0.0000 with runtime 13.6948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000048 is: 0.0664 with mean loss 0.0722 with start loss 0.0000 with runtime 13.5552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000049 is: 0.0666 with mean loss 0.0721 with start loss 0.0000 with runtime 13.5629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000050 is: 0.0664 with mean loss 0.0720 with start loss 0.0000 with runtime 13.5428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000051 is: 0.0663 with mean loss 0.0719 with start loss 0.0000 with runtime 13.5355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000052 is: 0.0662 with mean loss 0.0718 with start loss 0.0000 with runtime 13.4051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000053 is: 0.0663 with mean loss 0.0717 with start loss 0.0000 with runtime 13.4613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000054 is: 0.0662 with mean loss 0.0716 with start loss 0.0000 with runtime 13.4377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000055 is: 0.0662 with mean loss 0.0715 with start loss 0.0000 with runtime 13.4995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000056 is: 0.0661 with mean loss 0.0714 with start loss 0.0000 with runtime 13.5046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000057 is: 0.0662 with mean loss 0.0713 with start loss 0.0000 with runtime 13.4930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000058 is: 0.0660 with mean loss 0.0712 with start loss 0.0000 with runtime 13.4623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000059 is: 0.0661 with mean loss 0.0711 with start loss 0.0000 with runtime 13.6171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000060 is: 0.0660 with mean loss 0.0710 with start loss 0.0000 with runtime 13.4497\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000061 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68188], x=[21425, 11], batch=[21425], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69612], x=[21826, 11], batch=[21826], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68628], x=[21548, 11], batch=[21548], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69324], x=[21746, 11], batch=[21746], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68616], x=[21544, 11], batch=[21544], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68188], x=[21422, 11], batch=[21422], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68740], x=[21581, 11], batch=[21581], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68424], x=[21490, 11], batch=[21490], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68960], x=[21643, 11], batch=[21643], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69104], x=[21681, 11], batch=[21681], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68748], x=[21582, 11], batch=[21582], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68884], x=[21622, 11], batch=[21622], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69104], x=[21683, 11], batch=[21683], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68868], x=[21617, 11], batch=[21617], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68952], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68532], x=[21520, 11], batch=[21520], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68508], x=[21514, 11], batch=[21514], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69068], x=[21674, 11], batch=[21674], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68808], x=[21599, 11], batch=[21599], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68548], x=[21523, 11], batch=[21523], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wFalse_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 255.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "try to read  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000061 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68864], x=[21613, 11], batch=[21613], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68360], x=[21472, 11], batch=[21472], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69656], x=[21840, 11], batch=[21840], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69256], x=[21726, 11], batch=[21726], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68268], x=[21446, 11], batch=[21446], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68320], x=[21461, 11], batch=[21461], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68956], x=[21640, 11], batch=[21640], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 60], x=[21, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68220], x=[21430, 11], batch=[21430], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68460], x=[21501, 11], batch=[21501], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 48.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69564], x=[21812, 11], batch=[21812], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68760], x=[21587, 11], batch=[21587], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69024], x=[21660, 11], batch=[21660], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68656], x=[21557, 11], batch=[21557], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68848], x=[21610, 11], batch=[21610], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69200], x=[21710, 11], batch=[21710], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69380], x=[21762, 11], batch=[21762], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69464], x=[21784, 11], batch=[21784], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68856], x=[21614, 11], batch=[21614], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69368], x=[21758, 11], batch=[21758], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 47.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69192], x=[21708, 11], batch=[21708], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:20<00:00, 47.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "try to write  aliamolEllisDisc_model_epoch_00000061_010000_wTrue_generated.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 250.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frac correct graphs:  0.5467 with wild inference 0.8979\n",
            "Number of rows must be a positive integer, not 0\n",
            "Number of rows must be a positive integer, not 0\n",
            "[('CCC1C2(N)CC12CC', 5), ('CC1CC23CCC2CC13', 6), ('CCC(C)(O)CC1CC1', 9), ('CC1C(N)CCC1CN', 10), ('CC1(O)C2C3C4CC21C43', 16), ('C1COC(C2CC2)C1', 19), ('CCC1CCC1CCO', 22), ('CCC1CC2(O)OCC12', 23), ('CCCCCCC1CC1', 25), ('CCCOCC(C)=O', 26), ('CC1C(C)C23CCC12C3', 30), ('C1CC23CNC(C2)N1C3', 31), ('C1OC2CC3C1C31CC21', 32), ('NC1(O)CCCCCC1', 33), ('C=CC1(CC)C(N)C1O', 34), ('C=C1CC1C(C)O', 35), ('CCCCC(C)C1CC1', 38), ('O=CC(O)C1OC1CO', 39), ('C1CCC2C3CC23CC1', 40), ('C1COC2CCC2CN1', 41)]\n",
            "[('OC12CC3COC3C1C2', 1), ('C1CC2CC2C1', 2), ('OC1C2CCC3C(C2)C13', 3), ('CC1CC2(CC2)C12CC2', 4), ('O=C1C2C(O)CC3CC132', 5), ('C1CC2CC3CC23C1', 6), ('C1CC23CC1C21CC3C1', 7), ('C1CC23C4CC1C2C3C4', 8), ('CC1C2CCC34C1C3C24', 12), ('CC12CC1C1(C)C3C2C31', 13), ('CC1CC2CCC3C1C23', 14), ('OC12C3CCC4C(C41)C32', 15), ('CC1CC1C1C(C)C1C', 16), ('C1CC2C3CC2(C1)C3', 17), ('CCC1C2CC2C12CC2', 18), ('C1CC2CCC3CC23C1', 19), ('CC1CC2CC(C)C2C1', 20), ('CCC1CCC2CC1C2', 21), ('CC1CCC2CC(C)C12', 22), ('OC1CC1C1CC2CC21', 23)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000061 is: 0.0660 with mean loss 0.0710 with start loss 0.0000 with runtime 13.5305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000062 is: 0.0660 with mean loss 0.0709 with start loss 0.0000 with runtime 13.4906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000063 is: 0.0659 with mean loss 0.0708 with start loss 0.0000 with runtime 13.4991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000064 is: 0.0658 with mean loss 0.0707 with start loss 0.0000 with runtime 13.5918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000065 is: 0.0659 with mean loss 0.0707 with start loss 0.0000 with runtime 13.4753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000066 is: 0.0658 with mean loss 0.0706 with start loss 0.0000 with runtime 13.5339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000067 is: 0.0658 with mean loss 0.0705 with start loss 0.0000 with runtime 13.4637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000068 is: 0.0658 with mean loss 0.0704 with start loss 0.0000 with runtime 13.4013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000069 is: 0.0658 with mean loss 0.0704 with start loss 0.0000 with runtime 13.4740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000070 is: 0.0658 with mean loss 0.0703 with start loss 0.0000 with runtime 13.4499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000071 is: 0.0658 with mean loss 0.0703 with start loss 0.0000 with runtime 13.6288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000072 is: 0.0657 with mean loss 0.0702 with start loss 0.0000 with runtime 13.3921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000073 is: 0.0658 with mean loss 0.0701 with start loss 0.0000 with runtime 13.5722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000074 is: 0.0657 with mean loss 0.0701 with start loss 0.0000 with runtime 13.5794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000075 is: 0.0657 with mean loss 0.0700 with start loss 0.0000 with runtime 13.4999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000076 is: 0.0658 with mean loss 0.0700 with start loss 0.0000 with runtime 13.6954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 30.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000077 is: 0.0657 with mean loss 0.0699 with start loss 0.0000 with runtime 13.5954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000078 is: 0.0658 with mean loss 0.0699 with start loss 0.0000 with runtime 13.3849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000079 is: 0.0658 with mean loss 0.0698 with start loss 0.0000 with runtime 13.4105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 419/419 [00:13<00:00, 31.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch 0000080 is: 0.0658 with mean loss 0.0698 with start loss 0.0000 with runtime 13.4848\n",
            "save\n",
            "try to read  aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle\n",
            "An error occurred: [Errno 2] No such file or directory: 'aliamolEllisDisc_model_epoch_00000081_010000_wFalse_generated.pickle'\n",
            "try to read  dataset.pickle\n",
            "try to read  deg.pickle\n",
            "read checkpoint of epoch 00000081 from disc.\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68848], x=[21611, 11], batch=[21611], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 84], x=[28, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 69832], x=[21889, 11], batch=[21889], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 40.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68860], x=[21614, 11], batch=[21614], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated graphs  [Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 112], x=[36, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11]), Data(edge_index=[2, 144], x=[45, 11])]\n",
            "generate samples batched\n",
            "load g DataBatch(edge_index=[2, 68600], x=[21542, 11], batch=[21542], ptr=[501]) tensor([  0,   0,   0,  ..., 499, 499, 499], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 65/1000 [00:01<00:22, 41.52it/s]"
          ]
        }
      ],
      "source": [
        "start_with_wandb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UhC4DWeyaRX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjI30ZSDxcbM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMC91LXh4+fE+N4DGDPUgrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}